{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0865aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import requests\n",
    "import operator\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# sqlite-vec expects the standard library sqlite3 module.\n",
    "# Older versions of this notebook replaced sqlite3 with sqlean via sys.modules; undo that if present.\n",
    "if sys.modules.get(\"sqlite3\") is sys.modules.get(\"sqlean\"):\n",
    "    del sys.modules[\"sqlite3\"]\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Annotated, List, TypedDict, Optional, Dict, Any, Tuple\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import SQLiteVec\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from prompts import DECOMPOSER_SYSTEM, GENERATOR_SYSTEM, CRITIC_SYSTEM, SUMMARIZER_SYSTEM, REFLECTOR_SYSTEM\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97779ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNames(str, Enum):\n",
    "    \"\"\"Enum for node names to avoid string literals.\"\"\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    DECOMPOSE = \"decompose\"\n",
    "    GENERATE = \"generate\"\n",
    "    SYNTAX_CHECK = \"syntax_check\"\n",
    "    CRITIC = \"critic\"\n",
    "    SUMMARIZE = \"summarize\"\n",
    "    REFLECT = \"reflect\"\n",
    "    PLAN_AUDIT = \"plan_audit\"\n",
    "\n",
    "\n",
    "class Scores(int, Enum):\n",
    "    AVERAGE_SCORE_THRESHOLD = 8.5\n",
    "    REQUIREMENT_COVERAGE_THRESHOLD = 9.0\n",
    "\n",
    "\n",
    "class CritiqueError(BaseModel):\n",
    "    \"\"\"Model for a single critique error.\"\"\"\n",
    "    type: str = Field(description=\"Type of error\")\n",
    "    description: str = Field(description=\"Detailed description of the error\")\n",
    "\n",
    "\n",
    "class CritiqueResponse(BaseModel):\n",
    "    \"\"\"Structured output from the CRITIC node.\"\"\"\n",
    "    requirement_coverage: float = Field(ge=0, le=10, description=\"Does it capture all classes and relationships from the text?\")\n",
    "    design_best_practices: float = Field(ge=0, le=10, description=\"Are relationships correct? (e.g., composition vs association)\")\n",
    "    structural_integrity: float = Field(ge=0, le=10, description=\"Are there redundant classes or missing attributes?\")\n",
    "    is_valid: bool = Field(description=f\"True only if total average score is > {Scores.AVERAGE_SCORE_THRESHOLD} AND 'requirement_coverage' is >= {Scores.REQUIREMENT_COVERAGE_THRESHOLD}\")\n",
    "    errors: List[CritiqueError] = Field(default_factory=list, description=\"List of errors found\")\n",
    "    warnings: List[str] = Field(default_factory=list, description=\"List of warnings\")\n",
    "    missing_concepts: List[str] = Field(default_factory=list, description=\"Concepts from requirements not in diagram\")\n",
    "    reasoning: str = Field(description=\"Brief explanation for the scores provided.\")\n",
    "\n",
    "    @property\n",
    "    def weighted_score(self) -> float:\n",
    "        return (self.requirement_coverage * 0.5) + \\\n",
    "               (self.design_best_practices * 0.3) + \\\n",
    "               (self.structural_integrity * 0.2)\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def compute_validity(self) -> 'CritiqueResponse':\n",
    "        self.is_valid = (self.weighted_score > Scores.AVERAGE_SCORE_THRESHOLD) and (self.requirement_coverage >= Scores.REQUIREMENT_COVERAGE_THRESHOLD)\n",
    "        return self\n",
    "\n",
    "\n",
    "class SummaryResponse(BaseModel):\n",
    "    \"\"\"Structured output from the SUMMARIZER node.\"\"\"\n",
    "    is_complete: bool = Field(description=\"Whether all issues are resolved\")\n",
    "    fixed: List[str] = Field(default_factory=list, description=\"Issues that were fixed\")\n",
    "    unresolved: List[str] = Field(default_factory=list, description=\"Issues still present\")\n",
    "    message: str = Field(description=\"Brief status summary\")\n",
    "\n",
    "\n",
    "class PlanAudit(BaseModel):\n",
    "    is_valid: bool = Field(description=\"True if the plan is logically sound and covers all requirements.\")\n",
    "    critique: List[str] = Field(default_factory=list, description=\"List of specific logical flaws (e.g., 'Missing relationship between User and Account').\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Actionable steps to fix the plan.\")\n",
    "\n",
    "\n",
    "class SystemConfig(BaseModel):\n",
    "    \"\"\"System configuration for UML generation.\"\"\"\n",
    "    lmstudio_base_url: str = Field(default=\"http://localhost:1234/v1\", description=\"LMStudio API endpoint\")\n",
    "    model_name: str = Field(default=\"mistralai/devstral-small-2-2512\", description=\"Model to use\")\n",
    "    embedder_model: str = Field(default=\"BAAI/bge-large-en-v1.5\", description=\"Embedder model for semantic search\")\n",
    "    db_path: str = Field(default=\"./../data/uml_knowledge.db\", description=\"Path to SQLite database\")\n",
    "    shots_json_path: str = Field(default=\"./../data/complete_shots.json\", description=\"Path to few-shot examples\")\n",
    "    plantuml_host: str = Field(default=\"http://localhost:8080\", description=\"PlantUML server host\")\n",
    "    max_iterations: int = Field(default=6, ge=1, description=\"Maximum workflow iterations\")\n",
    "    max_tokens_decompose: int = Field(default=1024, description=\"Max tokens for decompose step\")\n",
    "    max_tokens_generate: int = Field(default=2048, description=\"Max tokens for generate step\")\n",
    "    max_tokens_critique: int = Field(default=2048, description=\"Max tokens for critique step\")\n",
    "    max_tokens_summarize: int = Field(default=1024, description=\"Max tokens for summarize step\")\n",
    "    max_tokens_reflect: int = Field(default=2048, description=\"Max tokens for reflect step\")\n",
    "    max_tokens_compare: int = Field(default=1024, description=\"Max tokens for compare step\")\n",
    "    temperature: float = Field(default=0.15, ge=0.0, le=2.0, description=\"Base temperature for LLM\")\n",
    "    num_few_shots: int = Field(default=3, ge=0, description=\"Number of few-shot examples\")\n",
    "    request_timeout: int = Field(default=5, ge=1, description=\"Timeout for PlantUML server requests\")\n",
    "    llm_timeout: int = Field(default=120, ge=1, description=\"Timeout for LLM operations\")\n",
    "\n",
    "\n",
    "class PlantUMLResult(BaseModel):\n",
    "    \"\"\"Result from PlantUML validation.\"\"\"\n",
    "    is_valid: bool = Field(description=\"Whether the PlantUML syntax is valid\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if validation failed\")\n",
    "    url: Optional[str] = Field(default=None, description=\"URL to view the diagram\")\n",
    "    svg_url: Optional[str] = Field(default=None, description=\"URL to view the diagram as SVG\")\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Shared state for the LangGraph workflow.\n",
    "    \"\"\"\n",
    "    requirements: str\n",
    "    plan: Optional[str]\n",
    "    examples: List[Dict[str, str]]\n",
    "    current_diagram: Optional[str]\n",
    "    best_diagram: Optional[str]  \n",
    "    history: Annotated[List[Dict[str, Any]], operator.add]\n",
    "    summary: Optional[str]\n",
    "    syntax_valid: bool\n",
    "    logic_valid: bool\n",
    "    error_message: Optional[str]\n",
    "    plan_valid: bool \n",
    "    best_score: float\n",
    "    best_code: str\n",
    "    current_validation: Optional[CritiqueResponse]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b32b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm(config: Optional[SystemConfig] = None) -> ChatOpenAI:\n",
    "    \"\"\"\n",
    "    Create a ChatOpenAI instance configured for LMStudio.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Configured ChatOpenAI instance\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(f\"Connecting to LMStudio at {cfg.lmstudio_base_url}\")\n",
    "    logger.info(f\"Using model: {cfg.model_name} (temp={cfg.temperature})\")\n",
    "    \n",
    "    return ChatOpenAI(\n",
    "        base_url=cfg.lmstudio_base_url,\n",
    "        api_key=\"lm-studio\",  \n",
    "        model=cfg.model_name,\n",
    "        temperature=cfg.temperature,\n",
    "        timeout=cfg.llm_timeout \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56dcf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantUMLTool:\n",
    "    \"\"\"\n",
    "    Tool for validating and rendering PlantUML diagrams.\n",
    "    \n",
    "    This class interfaces with a PlantUML server to check syntax\n",
    "    and generate diagram URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host: str = \"http://localhost:8080\"):\n",
    "        \"\"\"\n",
    "        Initialize PlantUML tool.\n",
    "        \n",
    "        Args:\n",
    "            host: PlantUML server host URL\n",
    "        \"\"\"\n",
    "        self.host = host\n",
    "        logger.info(f\"PlantUML tool initialized with host: {host}\")\n",
    "\n",
    "    def extract_plantuml(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract PlantUML code from markdown blocks or raw text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text containing PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            Extracted PlantUML code or empty string\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Try to extract from ```plantuml ... ```\n",
    "        fence_match = re.search(r\"```\\s*plantuml\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if fence_match:\n",
    "            return fence_match.group(1).strip()\n",
    "        \n",
    "        # Try to extract from @startuml ... @enduml\n",
    "        tag_match = re.search(r\"@startuml.*?@enduml\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if tag_match:\n",
    "            return tag_match.group(0).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def _encode_plantuml(self, plantuml_code: str) -> str:\n",
    "        \"\"\"\n",
    "        Encode PlantUML code for URL.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: Raw PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            URL-safe encoded string\n",
    "        \"\"\"\n",
    "        code = plantuml_code.strip()\n",
    "        \n",
    "        if not code.startswith(\"@startuml\"): \n",
    "            code = f\"@startuml\\n{code}\"\n",
    "        if not code.endswith(\"@enduml\"): \n",
    "            code = f\"{code}\\n@enduml\"\n",
    "        \n",
    "        compressed = zlib.compress(code.encode('utf-8'))[2:-4]\n",
    "        encoded = base64.b64encode(compressed).translate(\n",
    "            bytes.maketrans(\n",
    "                b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\",\n",
    "                b\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_\"\n",
    "            )\n",
    "        ).decode('utf-8')\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "    def get_diagram_url(self, plantuml_code: str, format: str = \"png\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a viewable URL for the PlantUML diagram.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "            format: Output format (png, svg, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            URL to view the diagram\n",
    "        \"\"\"\n",
    "        diagram_code = self.extract_plantuml(plantuml_code)\n",
    "        encoded = self._encode_plantuml(diagram_code)\n",
    "        return f\"{self.host}/{format}/{encoded}\"\n",
    "        \n",
    "    def check_syntax(self, plantuml_code: str, timeout: int = 5) -> PlantUMLResult:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax with detailed error extraction.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML code to validate\n",
    "            timeout: Request timeout in seconds\n",
    "            \n",
    "        Returns:\n",
    "            PlantUMLResult with validation status and detailed error if applicable.\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating PlantUML syntax\")\n",
    "        \n",
    "        try:\n",
    "            diagram_code = self.extract_plantuml(plantuml_code)\n",
    "            encoded = self._encode_plantuml(diagram_code)\n",
    "            \n",
    "            url_png = f\"{self.host}/png/{encoded}\"\n",
    "            response = requests.get(url_png, timeout=timeout)\n",
    "            \n",
    "            if response.status_code == 200 and response.content[:4] == b'\\x89PNG':\n",
    "                logger.info(\"Syntax validation passed (PNG rendered)\")\n",
    "                return PlantUMLResult(\n",
    "                    is_valid=True,\n",
    "                    url=url_png,\n",
    "                    svg_url=f\"{self.host}/svg/{encoded}\"\n",
    "                )\n",
    "            \n",
    "            logger.warning(\"PNG rendering failed. Fetching detailed syntax error...\")\n",
    "            url_txt = f\"{self.host}/txt/{encoded}\"\n",
    "            error_response = requests.get(url_txt, timeout=timeout)\n",
    "            \n",
    "            detailed_error = error_response.text.strip() if error_response.status_code == 200 else \"Unknown server error\"\n",
    "            \n",
    "            error_msg = f\"PlantUML Syntax Error:\\n{detailed_error[:1000]}\"\n",
    "            logger.error(f\"Syntax error detected: {error_msg}\")\n",
    "            \n",
    "            return PlantUMLResult(\n",
    "                is_valid=False,\n",
    "                error=error_msg\n",
    "            )\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"PlantUML Server Connection Error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected error during syntax check: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d633d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Manages long-term memory for UML diagram generation using LangChain's SQLiteVec.\n",
    "    \n",
    "    Supports semantic search to find similar past solutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedder: SentenceTransformer,\n",
    "        db_path: str = \"./../data/uml_knowledge.db\",\n",
    "        embedding_dims: int = 1024\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize memory manager with LangChain SQLiteVec.\n",
    "        \n",
    "        Args:\n",
    "            embedder: SentenceTransformer model for semantic search\n",
    "            db_path: Path to the SQLite database file\n",
    "            embedding_dims: Dimensions of the embeddings \n",
    "        \"\"\"\n",
    "        self.embedder = embedder\n",
    "        self.db_path = db_path\n",
    "        self.embedding_dims = embedding_dims\n",
    "        \n",
    "\n",
    "        self.embedding_function = HuggingFaceEmbeddings(\n",
    "            model_name=embedder.model_name if hasattr(embedder, 'model_name') else \"BAAI/bge-large-en-v1.5\",\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Create directory and connection\n",
    "        os.makedirs(os.path.dirname(self.db_path) if os.path.dirname(self.db_path) else \".\", exist_ok=True)\n",
    "        \n",
    "        # Create connection using SQLiteVec's method\n",
    "        self.connection = SQLiteVec.create_connection(db_file=self.db_path)\n",
    "        \n",
    "        # Initialize vector store with connection\n",
    "        self.vector_store = SQLiteVec(\n",
    "            table=\"uml_memories\",\n",
    "            connection=self.connection,\n",
    "            embedding=self.embedding_function\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"MemoryManager initialized with LangChain SQLiteVec at {db_path} (dims={embedding_dims})\")\n",
    "\n",
    "    def save_diagram(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        diagram: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Save a validated diagram to SQLite long-term memory.\n",
    "                \n",
    "        Args:\n",
    "            requirements: Original requirements text\n",
    "            diagram: PlantUML diagram code\n",
    "            metadata: Optional metadata\n",
    "            \n",
    "        Returns:\n",
    "            ID of the stored record\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        full_metadata = metadata or {}\n",
    "        full_metadata.update({\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "        \n",
    "\n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=full_metadata\n",
    "        )\n",
    "        \n",
    "        ids = self.vector_store.add_documents([doc])\n",
    "        \n",
    "        logger.info(\"Diagram saved to SQLite memory using LangChain SQLiteVec\")\n",
    "        return ids[0] if ids else 0\n",
    "    \n",
    "    def retrieve_similar_diagrams(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        limit: int = 2\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve similar diagrams from SQLite memory using vector search.\n",
    "        \n",
    "        Args:\n",
    "            requirements: Requirements text to search for\n",
    "            limit: Maximum number of results\n",
    "            \n",
    "        Returns:\n",
    "            List of similar diagram records\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.vector_store.similarity_search(requirements, k=limit)\n",
    "            \n",
    "            diagrams = []\n",
    "            for doc in results:\n",
    "                diagrams.append({\n",
    "                    \"requirements\": doc.page_content,\n",
    "                    \"diagram\": doc.metadata.get(\"diagram\", \"\"),\n",
    "                    \"timestamp\": doc.metadata.get(\"timestamp\", \"\"),\n",
    "                    \"metadata\": {k: v for k, v in doc.metadata.items() \n",
    "                                if k not in [\"diagram\", \"timestamp\"]}\n",
    "                })\n",
    "                \n",
    "            logger.info(f\"Retrieved {len(diagrams)} similar diagrams from SQLite\")\n",
    "            return diagrams\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Memory retrieval failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        try:\n",
    "            # Close existing connection\n",
    "            if hasattr(self, 'connection'):\n",
    "                self.connection.close()\n",
    "            \n",
    "            # Remove database file\n",
    "            if os.path.exists(self.db_path):\n",
    "                os.remove(self.db_path)\n",
    "            \n",
    "            # Recreate connection and vector store\n",
    "            self.connection = SQLiteVec.create_connection(db_file=self.db_path)\n",
    "            self.vector_store = SQLiteVec(\n",
    "                table=\"uml_memories\",\n",
    "                connection=self.connection,\n",
    "                embedding=self.embedding_function\n",
    "            )\n",
    "\n",
    "            logger.info(\"Memory cleared and reinitialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to clear memory: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "156ecfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_memory_from_shots(\n",
    "    memory_manager: MemoryManager,\n",
    "    shots_json_path: str = \"./../data/complete_shots.json\",\n",
    "    force_reseed: bool = False\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Seed the memory database with few-shot examples from JSON file.\n",
    "    Skips seeding if database already contains data (unless force_reseed=True).\n",
    "    \n",
    "    Args:\n",
    "        memory_manager: MemoryManager instance to seed\n",
    "        shots_json_path: Path to the complete_shots.json file\n",
    "        force_reseed: If True, clears existing data and reseeds\n",
    "        \n",
    "    Returns:\n",
    "        Number of shots seeded (0 if skipped)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"CHECKING MEMORY SEEDING STATUS\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    # Check if database already has data\n",
    "    try:\n",
    "        existing_docs = memory_manager.vector_store.similarity_search(\"test\", k=1)\n",
    "        if existing_docs and not force_reseed:\n",
    "            logger.info(f\"Database already contains data ({len(existing_docs)} docs found)\")\n",
    "            logger.info(\"Skipping seeding operation. Set force_reseed=True to override.\")\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Database appears empty or uninitialized: {e}\")\n",
    "    \n",
    "    if force_reseed:\n",
    "        logger.warning(\"Force reseed enabled - clearing existing memory\")\n",
    "        memory_manager.clear_memory()\n",
    "    \n",
    "\n",
    "    if not os.path.exists(shots_json_path):\n",
    "        logger.error(f\"Shots file not found at {shots_json_path}\")\n",
    "        return 0\n",
    "    \n",
    "    logger.info(f\"Loading shots from {shots_json_path}\")\n",
    "    with open(shots_json_path, 'r', encoding='utf-8') as f:\n",
    "        shots = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Found {len(shots)} shots to seed\")\n",
    "    \n",
    "    # Prepare documents\n",
    "    documents = []\n",
    "    for shot in shots:\n",
    "        requirements = shot[\"requirements\"]\n",
    "        diagram = shot[\"solution_plantuml\"]\n",
    "        \n",
    "        metadata = {\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"plan\": shot.get(\"subgoal_decomposition\"),\n",
    "            \"reasoning\": shot.get(\"chain_of_thought\"),\n",
    "            \"is_static\": True,\n",
    "            \"title\": shot.get(\"title\", \"Untitled\")\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"  Processing: {metadata['title']}\")\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    if documents:\n",
    "        memory_manager.vector_store.add_documents(documents)\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"âœ“ Successfully seeded {len(documents)} shots to memory\")\n",
    "        logger.info(\"=\"*60)\n",
    "        return len(documents)\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMLNodes:\n",
    "    \"\"\"\n",
    "    Collection of agent nodes for the UML generation workflow.\n",
    "    \n",
    "    Each method represents a node in the LangGraph workflow and\n",
    "    follows the pattern of taking AgentState and returning a dict\n",
    "    with state updates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: ChatOpenAI,\n",
    "        plantuml_tool: PlantUMLTool,\n",
    "        memory_manager: Optional['MemoryManager'] = None,\n",
    "        config: Optional[SystemConfig] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize UML nodes with required dependencies.\n",
    "        \n",
    "        Args:\n",
    "            llm: LangChain ChatOpenAI instance\n",
    "            plantuml_tool: Tool for PlantUML validation\n",
    "            memory_manager: long-term memory manager\n",
    "            config: Optional system configuration\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.plantuml_tool = plantuml_tool\n",
    "        self.memory_manager = memory_manager\n",
    "        self.config = config or SystemConfig()\n",
    "        logger.info(\"UMLNodes initialized\")\n",
    "\n",
    "    def _safe_invoke(self, runnable: Any, input_data: Any, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Invoke a runnable (LLM or chain) with retry logic.\n",
    "        \"\"\"\n",
    "        max_retries = 3\n",
    "        last_exception = None\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return runnable.invoke(input_data, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logger.warning(f\"LLM call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 * (attempt + 1))\n",
    "        \n",
    "        logger.error(f\"Max retries reached for LLM call: {last_exception}\")\n",
    "        raise last_exception\n",
    "\n",
    "    def retrieve(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant few-shot examples based on requirements.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'examples' key containing formatted shots\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.RETRIEVE.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            memories = self.memory_manager.retrieve_similar_diagrams(\n",
    "                state[\"requirements\"],\n",
    "                limit=self.config.num_few_shots\n",
    "            )\n",
    "            \n",
    "            formatted_shots = []\n",
    "            for mem in memories:\n",
    "                formatted_shots.append(\n",
    "                    HumanMessage(content=f\"Requirements:\\n{mem['requirements']}\")\n",
    "                )\n",
    "                \n",
    "                meta = mem.get(\"metadata\", {})\n",
    "                plan = meta.get(\"plan\", \"No plan available.\")\n",
    "                reasoning = meta.get(\"reasoning\", \"No reasoning available.\")\n",
    "                \n",
    "                assistant_content = (\n",
    "                    f\"1. DESIGN PLAN:\\n{plan}\\n\\n\"\n",
    "                    f\"2. DESIGN REASONING:\\n{reasoning}\\n\\n\"\n",
    "                    f\"3. PLANTUML DIAGRAM:\\n```plantuml\\n{mem['diagram']}\\n```\"\n",
    "                )\n",
    "                \n",
    "                formatted_shots.append(\n",
    "                    AIMessage(content=assistant_content)\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"Retrieved {len(memories)} relevant examples from unified memory\")\n",
    "            return {\"examples\": formatted_shots}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Retrieval failed: {e}\")\n",
    "            return {\"examples\": []}\n",
    "\n",
    "    def decompose(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Decompose requirements into structural building blocks.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'plan' key containing decomposition\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.DECOMPOSE.upper()} ---\")\n",
    "\n",
    "        feedback = state.get(\"audit_feedback\", [])\n",
    "        feedback_str = \"\\n\".join([f\"- {f}\" for f in feedback]) if feedback else \"None\"\n",
    "\n",
    "        system_prompt = DECOMPOSER_SYSTEM\n",
    "        if feedback:\n",
    "            system_prompt += f\"\\n\\nIMPORTANT: Your previous plan was rejected. Fix these issues:\\n{feedback_str}\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"REQUIREMENTS:\\n{state['requirements']}\")\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_decompose\n",
    "            )\n",
    "            logger.info(\"Decomposition completed\")\n",
    "            return {\"plan\": response.content}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Decomposition failed: {e}\")\n",
    "            return {\"plan\": f\"Error: {str(e)}\"}\n",
    "\n",
    "    def logic_auditor(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Audits the structural plan for logical consistency and requirement coverage.\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.PLAN_AUDIT.upper()} ---\")\n",
    "        \n",
    "        plan = state.get(\"plan\")\n",
    "        requirements = state.get(\"requirements\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Senior Software Architect auditing a UML Class Diagram plan.\n",
    "        \n",
    "        REQUIREMENTS:\n",
    "        {requirements}\n",
    "        \n",
    "        PROPOSED PLAN (JSON):\n",
    "        {plan}\n",
    "        \n",
    "        YOUR TASK:\n",
    "        1. Check for 'Island Classes' (classes with no relationships).\n",
    "        2. Ensure all entities mentioned in the requirements exist in the plan.\n",
    "        3. Check for relationship directionality (e.g., should 'User' own 'Order'?).\n",
    "        4. Verify that attributes have appropriate types.\n",
    "        \n",
    "        If the plan is flawed, be specific about what is missing.\n",
    "        \"\"\"\n",
    "        \n",
    "        audit_result = self.llm.with_structured_output(PlanAudit).invoke([\n",
    "            SystemMessage(content=\"You are a Senior Software Architect auditing a UML Class Diagram plan.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"plan_valid\": audit_result.is_valid,\n",
    "            \"audit_feedback\": audit_result.critique + audit_result.suggestions,\n",
    "            \"iterations\": state[\"iterations\"] + (0 if audit_result.is_valid else 1)\n",
    "        }\n",
    "\n",
    "    def generate(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate PlantUML diagram using chain-of-thought reasoning.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.GENERATE.upper()} ---\")\n",
    "        \n",
    "        messages = [SystemMessage(content=GENERATOR_SYSTEM)]\n",
    "        \n",
    "        # Add few-shot examples if available\n",
    "        if state.get(\"examples\"):\n",
    "            messages.extend(state[\"examples\"])\n",
    "            logger.debug(f\"Added {len(state['examples'])} example messages\")\n",
    "            \n",
    "        user_content = f\"\"\"\n",
    "        # ORIGINAL REQUIREMENTS\n",
    "        {state['requirements']}\n",
    "\n",
    "        # DESIGN PLAN\n",
    "        {state['plan']}\n",
    "\n",
    "        # TASK\n",
    "        Follow the examples above exactly. Output your response in three parts:\n",
    "        1. DESIGN PLAN: (Briefly refine the plan for implementation)\n",
    "        2. DESIGN REASONING: (Explain your choice of relationships and cardinality)\n",
    "        3. PLANTUML DIAGRAM: (The code block)\n",
    "        \"\"\"\n",
    "        \n",
    "        messages.append(HumanMessage(content=user_content))\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_generate\n",
    "            )\n",
    "            diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "            \n",
    "            logger.info(f\"Generation completed (iteration {state['iterations'] + 1})\")\n",
    "            return {\n",
    "                \"current_diagram\": diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": f\"Error: {str(e)}\",\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "    def syntax_check(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax through server.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'syntax_valid' and optional 'error_message'\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SYNTAX_CHECK.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            result = self.plantuml_tool.check_syntax(\n",
    "                state[\"current_diagram\"],\n",
    "                timeout=self.config.request_timeout\n",
    "            )\n",
    "            \n",
    "            if result.is_valid:\n",
    "                logger.info(f\"Syntax valid. View at: {result.url}\")\n",
    "            else:\n",
    "                logger.warning(f\"Syntax error: {result.error}\")\n",
    "            \n",
    "            return {\n",
    "                \"syntax_valid\": result.is_valid,\n",
    "                \"error_message\": result.error if not result.is_valid else None,\n",
    "                \"iterations\": state[\"iterations\"] + (0 if result.is_valid else 1)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Syntax check failed: {e}\")\n",
    "            return {\n",
    "                \"syntax_valid\": False,\n",
    "                \"error_message\": f\"Syntax check error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def _validate_diagram(self, requirements: str, diagram: str) -> CritiqueResponse:\n",
    "        \"\"\"\n",
    "        Helper method to validate a diagram and return the structured response.\n",
    "        Used by both critic node and reflect node (for rollback decision).\n",
    "        \"\"\"\n",
    "        plantuml_only = self.plantuml_tool.extract_plantuml(diagram)\n",
    "        user_msg = f\"\"\"\n",
    "        # REQUIREMENTS\n",
    "        {requirements}\n",
    "\n",
    "        # DIAGRAM\n",
    "        {plantuml_only}\n",
    "\n",
    "        Audit the diagram thoroughly and provide the scoring report.\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=CRITIC_SYSTEM),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "        \n",
    "        structured_llm = self.llm.with_structured_output(CritiqueResponse)\n",
    "        return self._safe_invoke(structured_llm, messages)\n",
    "\n",
    "    def critic(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform logical validation of the UML diagram.\n",
    "                \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'logic_valid' and 'history' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.CRITIC.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            critique_response = self._validate_diagram(state['requirements'], state[\"current_diagram\"])\n",
    "            \n",
    "            weighted = critique_response.weighted_score\n",
    "            \n",
    "            critique = {\n",
    "                \"is_valid\": critique_response.is_valid,\n",
    "                \"requirement_coverage\": critique_response.requirement_coverage,\n",
    "                \"design_best_practices\": critique_response.design_best_practices,\n",
    "                \"structural_integrity\": critique_response.structural_integrity,\n",
    "                \"weighted_score\": weighted,\n",
    "                \"errors\": [{\"type\": err.type, \"description\": err.description} \n",
    "                          for err in critique_response.errors],\n",
    "                \"warnings\": critique_response.warnings,\n",
    "                \"missing_concepts\": critique_response.missing_concepts,\n",
    "                \"reasoning\": critique_response.reasoning\n",
    "            }\n",
    "            \n",
    "            is_valid = critique_response.is_valid\n",
    "            logger.info(f\"Logic validation: {'PASSED' if is_valid else 'FAILED'} (Weighted Score: {weighted:.2f})\")\n",
    "            logger.info(f\"  Requirements Coverage: {critique_response.requirement_coverage:.2f}/10\")\n",
    "            logger.info(f\"  Design Best Practices: {critique_response.design_best_practices:.2f}/10\")\n",
    "            logger.info(f\"  Structural Integrity: {critique_response.structural_integrity:.2f}/10\")\n",
    "            \n",
    "            if not is_valid and critique_response.errors:\n",
    "                logger.info(f\"Found {len(critique_response.errors)} errors\")\n",
    "            \n",
    "            updates = {\n",
    "                \"logic_valid\": is_valid,\n",
    "                \"history\": [critique]  + state.get(\"history\", []),\n",
    "                \"current_validation\": critique_response\n",
    "            }\n",
    "            \n",
    "            if is_valid and not state.get(\"best_diagram\"):\n",
    "                logger.info(f\"Storing first valid diagram as best\")\n",
    "                updates[\"best_diagram\"] = state[\"current_diagram\"]\n",
    "            \n",
    "            return updates\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critic failed: {e}\")\n",
    "            return {\n",
    "                \"logic_valid\": False,\n",
    "                \"history\": [{\n",
    "                    \"is_valid\": False,\n",
    "                    \"requirement_coverage\": 0.0,\n",
    "                    \"design_best_practices\": 0.0,\n",
    "                    \"structural_integrity\": 0.0,\n",
    "                    \"weighted_score\": 0.0,\n",
    "                    \"errors\": [{\"type\": \"system\", \"description\": str(e)}],\n",
    "                    \"warnings\": [],\n",
    "                    \"missing_concepts\": [],\n",
    "                    \"reasoning\": \"System error during critique.\"\n",
    "                }]\n",
    "            }\n",
    "\n",
    "    def summarize_memory(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Summarize progress by comparing current and previous critiques.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'summary' key containing JSON string\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SUMMARIZE.upper()} ---\")\n",
    "        \n",
    "        if not state.get(\"history\"):\n",
    "            logger.info(\"No history to summarize\")\n",
    "            return {\"summary\": json.dumps({\"is_complete\": False, \"message\": \"No history\"})}\n",
    "        \n",
    "        current_critique = state[\"history\"][-1]\n",
    "        \n",
    "        # Only look at the last 2 previous critiques to save tokens\n",
    "        # sending the full history causes context overflow in later iterations\n",
    "        previous_critiques = state[\"history\"][-3:-1] if len(state[\"history\"]) > 1 else []\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        CURRENT CRITIQUE (Issues in the latest diagram):\n",
    "        {json.dumps(current_critique)}\n",
    "        \n",
    "        PREVIOUS CRITIQUES (Recent history):\n",
    "        {json.dumps(previous_critiques)}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SUMMARIZER_SYSTEM),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            structured_llm = self.llm.with_structured_output(SummaryResponse)\n",
    "            summary_response: SummaryResponse = self._safe_invoke(structured_llm, messages)\n",
    "            \n",
    "            summary = {\n",
    "                \"is_complete\": summary_response.is_complete,\n",
    "                \"fixed\": summary_response.fixed,\n",
    "                \"unresolved\": summary_response.unresolved,\n",
    "                \"message\": summary_response.message\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Summary: {summary_response.message}\")\n",
    "            return {\"summary\": json.dumps(summary)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Summarization failed: {e}\")\n",
    "            return {\"summary\": json.dumps({\n",
    "                \"is_complete\": False,\n",
    "                \"fixed\": [],\n",
    "                \"unresolved\": [],\n",
    "                \"message\": f\"Error: {str(e)}\"\n",
    "            })}\n",
    "\n",
    "    def reflect(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fix diagram based on memory summary and error history.\n",
    "        Implements internal retry loop with dynamic temperature to escape local optima.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.REFLECT.upper()} ---\")\n",
    "\n",
    "        last_critique = state[\"history\"][-1]\n",
    "        prev_score = last_critique.get(\"weighted_score\", 0)\n",
    "        old_diagram = state['current_diagram']\n",
    "        best_score = state.get(\"best_score\", prev_score)\n",
    "        best_diagram = state.get(\"best_diagram\") or old_diagram\n",
    "        validation_cache = state.get(\"validation_cache\", {})\n",
    "        tone_instruction = \"\"\n",
    "        summary_json: Dict[str, Any] = {}\n",
    "        unresolved_issues: List[str] = []\n",
    "        raw_summary = state.get(\"summary\")\n",
    "        if raw_summary:\n",
    "            try:\n",
    "                summary_json = json.loads(raw_summary) if isinstance(raw_summary, str) else (raw_summary if isinstance(raw_summary, dict) else {})\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse state['summary'] as JSON; using empty summary. Error: {e}\")\n",
    "                summary_json = {}\n",
    "        unresolved_raw = summary_json.get(\"unresolved\") or []\n",
    "        if isinstance(unresolved_raw, list):\n",
    "            unresolved_issues = [str(x) for x in unresolved_raw]\n",
    "        else:\n",
    "            unresolved_issues = [str(unresolved_raw)]\n",
    "        \n",
    "        error_items = last_critique.get(\"errors\", []) or []\n",
    "        error_descriptions: List[str] = []\n",
    "        if isinstance(error_items, list):\n",
    "            for err in error_items:\n",
    "                if isinstance(err, dict):\n",
    "                    error_descriptions.append(str(err.get(\"description\") or err.get(\"type\") or \"\"))\n",
    "                else:\n",
    "                    error_descriptions.append(str(err))\n",
    "        \n",
    "        focus_issues = [x for x in (error_descriptions or unresolved_issues) if x]\n",
    "        focus_issues = focus_issues[:3]\n",
    "        \n",
    "        if prev_score < 7.0:\n",
    "            tone_instruction = (\n",
    "                \"The design is fundamentally wrong. You MUST:\\n\"\n",
    "                f\"1. Re-examine these missing concepts: {last_critique.get('missing_concepts')}\\n\"\n",
    "                \"2. Question your class boundaries\\n\"\n",
    "                \"3. Verify every relationship direction\\n\"\n",
    "            )\n",
    "        elif prev_score < 8.0:\n",
    "            tone_instruction = (\n",
    "                \"You're close but need targeted fixes:\\n\"\n",
    "                f\"1. Focus ONLY on: {focus_issues}\\n\"\n",
    "                \"2. Don't touch working parts\\n\"\n",
    "            )\n",
    "\n",
    "        \n",
    "        summary_text = (\n",
    "            f\"Message: {summary_json.get('message', '')}\\n\"\n",
    "            f\"Focus Issues: {', '.join(focus_issues)}\"\n",
    "        )\n",
    "\n",
    "        base_user_msg = f\"\"\"\n",
    "        {tone_instruction}\n",
    "        \n",
    "        [QUALITY SCORE]: {prev_score}/10\n",
    "        [ERRORS TO FIX]:\n",
    "        {summary_text}\n",
    "        \n",
    "        [MISSING CONCEPTS]: {last_critique.get('missing_concepts', [])}\n",
    "        \n",
    "        [CURRENT CODE]:\n",
    "        {old_diagram}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=REFLECTOR_SYSTEM),\n",
    "            HumanMessage(content=base_user_msg)\n",
    "        ]\n",
    "\n",
    "        \n",
    "        max_retries = 2 \n",
    "        current_temp = self.config.temperature\n",
    "        \n",
    "        def _diagram_key(diagram: str) -> str:\n",
    "            return hashlib.sha256(diagram.encode(\"utf-8\")).hexdigest()\n",
    "        \n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                logger.info(f\"Reflection attempt {attempt+1}/{max_retries+1} (temp={current_temp:.2f})\")\n",
    "                \n",
    "                response = self._safe_invoke(\n",
    "                    self.llm,\n",
    "                    messages,\n",
    "                    max_tokens=self.config.max_tokens_reflect\n",
    "                )\n",
    "                new_diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "\n",
    "\n",
    "                if new_diagram.strip() == old_diagram.strip():\n",
    "                    logger.warning(\"Generated identical diagram.\")\n",
    "                    if attempt < max_retries:\n",
    "                        messages.append(HumanMessage(content=\"You returned the exact same diagram. You MUST change it to fix the errors. Try again.\"))\n",
    "                        current_temp = min(1.0, current_temp + 0.2)\n",
    "                        continue\n",
    "                    else:\n",
    "                        break \n",
    "\n",
    "                new_key = _diagram_key(new_diagram)\n",
    "                if new_key in validation_cache:\n",
    "                    new_validation = validation_cache[new_key]\n",
    "                else:\n",
    "                    new_validation = self._validate_diagram(state['requirements'], new_diagram)\n",
    "                    validation_cache[new_key] = new_validation\n",
    "                new_score = new_validation.weighted_score\n",
    "                \n",
    "                logger.info(f\"Attempt {attempt+1} Score: {new_score:.2f} (Previous: {prev_score:.2f})\")\n",
    "\n",
    "                if new_score >= prev_score:\n",
    "                    if new_score > best_score:\n",
    "                        best_score = new_score\n",
    "                        best_diagram = new_diagram\n",
    "                    logger.info(f\"Improvement found! ({new_score:.2f} >= {prev_score:.2f})\")\n",
    "                    return {\n",
    "                        \"current_diagram\": new_diagram,\n",
    "                        \"best_diagram\": best_diagram,\n",
    "                        \"best_score\": best_score,\n",
    "                        \"validation_cache\": validation_cache,\n",
    "                        \"iterations\": state[\"iterations\"] + 1,\n",
    "                    }\n",
    "                \n",
    "\n",
    "                logger.warning(f\"Score dropped to {new_score:.2f}. Retrying...\")\n",
    "                \n",
    "                if attempt < max_retries:\n",
    "                    messages.append(HumanMessage(content=f\"\"\"\n",
    "                    Your previous attempt resulted in a LOWER score ({new_score:.2f} < {prev_score:.2f}).\n",
    "                    The changes you made introduced new issues.\n",
    "                    Undo those bad changes and try a different approach to fix the original errors.\n",
    "                    \"\"\"))\n",
    "                    current_temp = min(1.0, current_temp + 0.1)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Reflection attempt {attempt+1} failed: {e}\")\n",
    "        \n",
    "        logger.warning(\"All reflection attempts failed to improve score. Rolling back to best diagram.\")\n",
    "        \n",
    "\n",
    "        recent_history = state.get(\"history\", [])[-4:]\n",
    "        if len(recent_history) >= 3:\n",
    "             last_scores = [h.get(\"weighted_score\", 0) for h in recent_history[-2:]]\n",
    "             if len(set(last_scores)) == 1:\n",
    "                 logger.warning(\"Score plateau detected. Stopping.\")\n",
    "                 return {\n",
    "                     \"current_diagram\": best_diagram,\n",
    "                     \"best_diagram\": best_diagram,\n",
    "                     \"best_score\": best_score,\n",
    "                     \"validation_cache\": validation_cache,\n",
    "                     \"iterations\": self.config.max_iterations \n",
    "                 }\n",
    "\n",
    "        return {\n",
    "            \"current_diagram\": best_diagram,\n",
    "            \"best_diagram\": best_diagram,\n",
    "            \"best_score\": best_score,\n",
    "            \"validation_cache\": validation_cache,\n",
    "            \"iterations\": state[\"iterations\"] + 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12124ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uml_graph(\n",
    "    nodes: UMLNodes, \n",
    "    config: Optional[SystemConfig] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Create the LangGraph workflow for UML diagram generation.\n",
    "    \n",
    "    Args:\n",
    "        nodes: UMLNodes instance with all agent methods\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Compiled LangGraph workflow\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"Creating UML generation workflow\")\n",
    "    \n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(NodeNames.RETRIEVE, nodes.retrieve)\n",
    "    workflow.add_node(NodeNames.PLAN_AUDIT, nodes.logic_auditor)\n",
    "    workflow.add_node(NodeNames.DECOMPOSE, nodes.decompose)\n",
    "    workflow.add_node(NodeNames.GENERATE, nodes.generate)\n",
    "    workflow.add_node(NodeNames.SYNTAX_CHECK, nodes.syntax_check)\n",
    "    workflow.add_node(NodeNames.CRITIC, nodes.critic)\n",
    "    workflow.add_node(NodeNames.SUMMARIZE, nodes.summarize_memory)\n",
    "    workflow.add_node(NodeNames.REFLECT, nodes.reflect)\n",
    "    \n",
    "    logger.debug(\"Added 7 nodes to workflow\")\n",
    "\n",
    "    # Define edges\n",
    "    workflow.add_edge(START, NodeNames.RETRIEVE)\n",
    "    workflow.add_edge(NodeNames.RETRIEVE, NodeNames.DECOMPOSE)\n",
    "    workflow.add_edge(NodeNames.DECOMPOSE, NodeNames.PLAN_AUDIT)\n",
    "\n",
    "    def route_after_plan_audit(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on plan audit results.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"plan_valid\"]:\n",
    "            logger.debug(\"Routing: plan_audit -> generate\")\n",
    "            return NodeNames.GENERATE\n",
    "            \n",
    "        logger.debug(\"Routing: plan_audit -> decompose\")\n",
    "        return NodeNames.DECOMPOSE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.PLAN_AUDIT, \n",
    "        route_after_plan_audit,\n",
    "        {\n",
    "            NodeNames.DECOMPOSE: NodeNames.DECOMPOSE,\n",
    "            NodeNames.GENERATE: NodeNames.GENERATE\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(NodeNames.GENERATE, NodeNames.SYNTAX_CHECK)\n",
    "\n",
    "    def route_after_syntax_check(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on syntax validation results and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"syntax_valid\"]:\n",
    "            logger.debug(\"Routing: syntax_check -> critic\")\n",
    "            return NodeNames.CRITIC\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached during syntax check\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: syntax_check -> reflect\")\n",
    "        return NodeNames.REFLECT\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.SYNTAX_CHECK, \n",
    "        route_after_syntax_check,\n",
    "        {\n",
    "            NodeNames.CRITIC: NodeNames.CRITIC,\n",
    "            NodeNames.REFLECT: NodeNames.REFLECT,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def is_logic_valid(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on logic validation and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name or END\n",
    "        \"\"\"\n",
    "        if state[\"logic_valid\"]:\n",
    "            logger.info(\"Diagram validated successfully\")\n",
    "            return END\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: critic -> summarize\")\n",
    "        return NodeNames.SUMMARIZE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.CRITIC, \n",
    "        is_logic_valid,\n",
    "        {\n",
    "            END: END,\n",
    "            NodeNames.SUMMARIZE: NodeNames.SUMMARIZE\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(NodeNames.SUMMARIZE, NodeNames.REFLECT)\n",
    "\n",
    "    def route_after_reflect(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route after reflection based on iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached after reflection\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: reflect -> syntax_check\")\n",
    "        return NodeNames.SYNTAX_CHECK\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.REFLECT, \n",
    "        route_after_reflect,\n",
    "        {\n",
    "            NodeNames.SYNTAX_CHECK: NodeNames.SYNTAX_CHECK,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Workflow graph created successfully\")\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def create_initial_state(requirements: str) -> AgentState:\n",
    "    \"\"\"\n",
    "    Create an initial state for the workflow.\n",
    "    \n",
    "    Args:\n",
    "        requirements: Software requirements text\n",
    "        \n",
    "    Returns:\n",
    "        Initial AgentState dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"requirements\": requirements,\n",
    "        \"plan\": None,\n",
    "        \"examples\": [],\n",
    "        \"current_diagram\": None,\n",
    "        \"best_diagram\": None,\n",
    "        \"history\": [],\n",
    "        \"summary\": None,\n",
    "        \"syntax_valid\": False,\n",
    "        \"logic_valid\": False,\n",
    "        \"iterations\": 0,\n",
    "        \"error_message\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "549e0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 19:04:35,930 - __main__ - INFO - Loading test exercises from ./../data/test_exercises.json\n",
      "2026-01-14 19:04:35,931 - __main__ - INFO - Loaded 8 test exercises\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 test exercises\n"
     ]
    }
   ],
   "source": [
    "def load_test_exercises(json_path: str = \"./../data/test_exercises.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load test exercises from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to test exercises JSON\n",
    "        \n",
    "    Returns:\n",
    "        List of exercise dictionaries\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        json.JSONDecodeError: If JSON is invalid\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading test exercises from {json_path}\")\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Test exercises file not found: {json_path}\")\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        exercises = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Loaded {len(exercises)} test exercises\")\n",
    "    return exercises\n",
    "\n",
    "try:\n",
    "    test_exercises = load_test_exercises()\n",
    "    print(f\"Loaded {len(test_exercises)} test exercises\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load test exercises: {e}\")\n",
    "    test_exercises = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e53188a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 19:04:35,940 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:35,940 - __main__ - INFO - INITIALIZING UML GENERATION SYSTEM\n",
      "2026-01-14 19:04:35,941 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:35,941 - __main__ - INFO - Creating LLM connection...\n",
      "2026-01-14 19:04:35,942 - __main__ - INFO - Connecting to LMStudio at http://localhost:1234/v1\n",
      "2026-01-14 19:04:35,942 - __main__ - INFO - Using model: mistralai/devstral-small-2-2512 (temp=0.15)\n",
      "2026-01-14 19:04:35,948 - __main__ - INFO - Initializing PlantUML tool...\n",
      "2026-01-14 19:04:35,949 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n",
      "2026-01-14 19:04:35,949 - __main__ - INFO - Initializing long-term memory with BAAI/bge-large-en-v1.5...\n",
      "2026-01-14 19:04:35,964 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2026-01-14 19:04:35,964 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8969eeba-3928-4ea2-bc85-0d3937985803)')' thrown while requesting HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/./modules.json\n",
      "2026-01-14 19:04:45,996 - huggingface_hub.utils._http - WARNING - '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8969eeba-3928-4ea2-bc85-0d3937985803)')' thrown while requesting HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "2026-01-14 19:04:45,998 - huggingface_hub.utils._http - WARNING - Retrying in 1s [Retry 1/5].\n",
      "2026-01-14 19:04:54,738 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2026-01-14 19:04:57,331 - __main__ - INFO - MemoryManager initialized with LangChain SQLiteVec at ./../data/uml_knowledge.db (dims=1024)\n",
      "2026-01-14 19:04:57,331 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:57,331 - __main__ - INFO - CHECKING MEMORY SEEDING STATUS\n",
      "2026-01-14 19:04:57,331 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:57,414 - __main__ - WARNING - Force reseed enabled - clearing existing memory\n",
      "2026-01-14 19:04:57,503 - __main__ - INFO - Memory cleared and reinitialized\n",
      "2026-01-14 19:04:57,503 - __main__ - INFO - Loading shots from ./../data/complete_shots.json\n",
      "2026-01-14 19:04:57,504 - __main__ - INFO - Found 20 shots to seed\n",
      "2026-01-14 19:04:57,504 - __main__ - INFO -   Processing: Project Management System\n",
      "2026-01-14 19:04:57,504 - __main__ - INFO -   Processing: Hollywood Approach\n",
      "2026-01-14 19:04:57,504 - __main__ - INFO -   Processing: Word Processor\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Patient Record and Scheduling\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Movie-Shop\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Flights\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Bank System\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Veterinary Clinic\n",
      "2026-01-14 19:04:57,505 - __main__ - INFO -   Processing: Auto Repair\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Restaurant\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Deliveries\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Furniture Factory Management\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Industrial Factory Operations\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Bycicle Rental\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Car Park Access System\n",
      "2026-01-14 19:04:57,506 - __main__ - INFO -   Processing: Banking Organizational Structure\n",
      "2026-01-14 19:04:57,507 - __main__ - INFO -   Processing: Prepaid Cell Phone (Decorator Pattern)\n",
      "2026-01-14 19:04:57,507 - __main__ - INFO -   Processing: Library Management System\n",
      "2026-01-14 19:04:57,507 - __main__ - INFO -   Processing: MyDoctor Appointment Management\n",
      "2026-01-14 19:04:57,507 - __main__ - INFO -   Processing: Online Shopping System\n",
      "2026-01-14 19:04:59,748 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:59,748 - __main__ - INFO - âœ“ Successfully seeded 20 shots to memory\n",
      "2026-01-14 19:04:59,748 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:59,748 - __main__ - INFO - Long-term memory (SQLite + sqlite-vec) enabled\n",
      "2026-01-14 19:04:59,749 - __main__ - INFO - Seeded 20 few-shot examples into memory\n",
      "2026-01-14 19:04:59,749 - __main__ - INFO - Building LangGraph workflow...\n",
      "2026-01-14 19:04:59,749 - __main__ - INFO - UMLNodes initialized\n",
      "2026-01-14 19:04:59,749 - __main__ - INFO - Creating UML generation workflow\n",
      "2026-01-14 19:04:59,757 - __main__ - INFO - Workflow graph created successfully\n",
      "2026-01-14 19:04:59,767 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:04:59,767 - __main__ - INFO - SYSTEM INITIALIZED SUCCESSFULLY\n",
      "2026-01-14 19:04:59,767 - __main__ - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready for diagram generation\n",
      "Long-term memory: ENABLED\n"
     ]
    }
   ],
   "source": [
    "def initialize_system(\n",
    "    config: Optional[SystemConfig] = None,\n",
    "    enable_long_term_memory: bool = True\n",
    ") -> Tuple[UMLNodes, Any, SystemConfig, Optional[MemoryManager]]:\n",
    "    \"\"\"\n",
    "    Initialize all system components.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        enable_long_term_memory: Whether to enable long-term memory\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (nodes, compiled_workflow, config, memory_manager)\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"INITIALIZING UML GENERATION SYSTEM\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating LLM connection...\")\n",
    "        llm = create_llm(cfg)\n",
    "        \n",
    "        logger.info(\"Initializing PlantUML tool...\")\n",
    "        puml_tool = PlantUMLTool(cfg.plantuml_host)\n",
    "        \n",
    "        memory_mgr = None\n",
    "        if enable_long_term_memory:\n",
    "            logger.info(f\"Initializing long-term memory with {cfg.embedder_model}...\")\n",
    "\n",
    "            dims = 1024 if \"large\" in cfg.embedder_model.lower() else 384\n",
    "            \n",
    "            memory_mgr = MemoryManager(\n",
    "                embedder=SentenceTransformer(cfg.embedder_model),\n",
    "                db_path=cfg.db_path,\n",
    "                embedding_dims=dims\n",
    "            )\n",
    "\n",
    "            seeded_count = seed_memory_from_shots(\n",
    "                memory_manager=memory_mgr,\n",
    "                shots_json_path=cfg.shots_json_path,\n",
    "                force_reseed=True \n",
    "            )\n",
    "\n",
    "            logger.info(\"Long-term memory (SQLite + sqlite-vec) enabled\")\n",
    "\n",
    "            if seeded_count > 0:\n",
    "                logger.info(f\"Seeded {seeded_count} few-shot examples into memory\")\n",
    "        else:\n",
    "            logger.info(\"Long-term memory disabled\")\n",
    "        \n",
    "\n",
    "        logger.info(\"Building LangGraph workflow...\")\n",
    "        nodes = UMLNodes(llm, puml_tool, memory_mgr, cfg)\n",
    "        app = create_uml_graph(nodes, cfg)\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"SYSTEM INITIALIZED SUCCESSFULLY\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        return nodes, app, cfg, memory_mgr\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"System initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "nodes, app, config, memory_manager = initialize_system(enable_long_term_memory=True)\n",
    "print(\"\\nSystem ready for diagram generation\")\n",
    "print(f\"Long-term memory: {'ENABLED' if memory_manager else 'DISABLED'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9633429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 19:05:02,981 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:05:02,982 - __main__ - INFO - RUNNING: Exercise 1\n",
      "2026-01-14 19:05:02,982 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:05:02,983 - __main__ - INFO - Requirements preview: An e-commerce platform manages products, customers, and orders.\n",
      "Each product has a unique SKU, name, description, price, and stock quantity.\n",
      "Products ...\n",
      "2026-01-14 19:05:02,985 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "2026-01-14 19:05:03,142 - __main__ - INFO - Retrieved 3 similar diagrams from SQLite\n",
      "2026-01-14 19:05:03,142 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-14 19:05:03,143 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-14 19:06:25,359 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:06:25,377 - __main__ - INFO - Decomposition completed\n",
      "2026-01-14 19:06:25,382 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n",
      "2026-01-14 19:06:36,028 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:06:36,077 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-14 19:07:49,579 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:07:49,587 - __main__ - INFO - Generation completed (iteration 1)\n",
      "2026-01-14 19:07:49,589 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-14 19:07:49,590 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-14 19:07:49,785 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-14 19:07:49,786 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/TLEzJWCn3Dxp554NVgGEh3U12aC7HA7io2HM6v6V8t643iJA4_24F0c-QvjBIrdEFx4_svzzbuaWKdPM26KX9Rc8GMT5yaD8cLvo8vSKZL-nvS5XPMfCAfgMJF2Ljur6STGrAkF0zXWKrCjz1a-6kaREFU4Ae_ZSrPi1EqBiXe96Zn471SU4p90Euv203eojotF4MuYwSgMrQLjMhxIEc58Zjme_FHjhZxsKMdTHRmk5NhlcNdas_ZuQXyDmG9aJRtnsR58Wi5SkP4yZ1VjWSq8t0Bx-eKJAx0qjzWaisSjr6CQOyReOeFWNq3dqctsr6_qMQHrg2YY2Jw3wLStr7bj3_BAUeW1loTWS0aL4gZBLqFd8CGtC5FlTjBEWQu_gIObTlSuJ-O0M-gRw5IMnkxp9nKHEft9oFgaeQnZ14nYVn6Of_qGPhspcqnJbJ0u3EQYreF0GYCMEoqQkuGW2YxqjD3AySJyyo2tuRafXsajvkXlav-kxdFVPEDvvwQVSVYEVqGQ_IayKXBX4h_cF_0K=\n",
      "2026-01-14 19:07:49,787 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-14 19:08:12,347 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:08:12,361 - __main__ - INFO - Logic validation: FAILED (Weighted Score: 8.70)\n",
      "2026-01-14 19:08:12,361 - __main__ - INFO -   Requirements Coverage: 8.00/10\n",
      "2026-01-14 19:08:12,361 - __main__ - INFO -   Design Best Practices: 9.00/10\n",
      "2026-01-14 19:08:12,361 - __main__ - INFO -   Structural Integrity: 10.00/10\n",
      "2026-01-14 19:08:12,361 - __main__ - INFO - Found 2 errors\n",
      "2026-01-14 19:08:12,362 - __main__ - INFO - --- NODE: SUMMARIZE ---\n",
      "2026-01-14 19:08:23,782 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:08:23,791 - __main__ - INFO - Summary: No previous critiques available for comparison. Current issues include encapsulation, associations, design best practices, and missing concepts.\n",
      "2026-01-14 19:08:23,792 - __main__ - INFO - --- NODE: REFLECT ---\n",
      "2026-01-14 19:08:23,792 - __main__ - INFO - Reflection attempt 1/3 (temp=0.15)\n",
      "2026-01-14 19:08:59,782 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:09:26,847 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:09:26,854 - __main__ - INFO - Attempt 1 Score: 7.90 (Previous: 8.70)\n",
      "2026-01-14 19:09:26,855 - __main__ - WARNING - Score dropped to 7.90. Retrying...\n",
      "2026-01-14 19:09:26,856 - __main__ - INFO - Reflection attempt 2/3 (temp=0.25)\n",
      "2026-01-14 19:09:57,628 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:10:32,665 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:10:32,671 - __main__ - INFO - Attempt 2 Score: 7.90 (Previous: 8.70)\n",
      "2026-01-14 19:10:32,672 - __main__ - WARNING - Score dropped to 7.90. Retrying...\n",
      "2026-01-14 19:10:32,672 - __main__ - INFO - Reflection attempt 3/3 (temp=0.35)\n",
      "2026-01-14 19:11:09,487 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:11:35,490 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:11:35,495 - __main__ - INFO - Attempt 3 Score: 7.90 (Previous: 8.70)\n",
      "2026-01-14 19:11:35,496 - __main__ - WARNING - Score dropped to 7.90. Retrying...\n",
      "2026-01-14 19:11:35,496 - __main__ - WARNING - All reflection attempts failed to improve score. Rolling back to old diagram.\n",
      "2026-01-14 19:11:35,499 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-14 19:11:35,500 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-14 19:11:35,628 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-14 19:11:35,629 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/TLEzJWCn3Dxp554NVgGEh3U12aC7HA7io2HM6v6V8t643iJA4_24F0c-QvjBIrdEFx4_svzzbuaWKdPM26KX9Rc8GMT5yaD8cLvo8vSKZL-nvS5XPMfCAfgMJF2Ljur6STGrAkF0zXWKrCjz1a-6kaREFU4Ae_ZSrPi1EqBiXe96Zn471SU4p90Euv203eojotF4MuYwSgMrQLjMhxIEc58Zjme_FHjhZxsKMdTHRmk5NhlcNdas_ZuQXyDmG9aJRtnsR58Wi5SkP4yZ1VjWSq8t0Bx-eKJAx0qjzWaisSjr6CQOyReOeFWNq3dqctsr6_qMQHrg2YY2Jw3wLStr7bj3_BAUeW1loTWS0aL4gZBLqFd8CGtC5FlTjBEWQu_gIObTlSuJ-O0M-gRw5IMnkxp9nKHEft9oFgaeQnZ14nYVn6Of_qGPhspcqnJbJ0u3EQYreF0GYCMEoqQkuGW2YxqjD3AySJyyo2tuRafXsajvkXlav-kxdFVPEDvvwQVSVYEVqGQ_IayKXBX4h_cF_0K=\n",
      "2026-01-14 19:11:35,629 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-14 19:13:35,634 - openai._base_client - INFO - Retrying request to /chat/completions in 0.471748 seconds\n",
      "2026-01-14 19:13:51,320 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:13:51,333 - __main__ - INFO - Logic validation: FAILED (Weighted Score: 8.70)\n",
      "2026-01-14 19:13:51,334 - __main__ - INFO -   Requirements Coverage: 8.00/10\n",
      "2026-01-14 19:13:51,334 - __main__ - INFO -   Design Best Practices: 9.00/10\n",
      "2026-01-14 19:13:51,334 - __main__ - INFO -   Structural Integrity: 10.00/10\n",
      "2026-01-14 19:13:51,335 - __main__ - INFO - Found 4 errors\n",
      "2026-01-14 19:13:51,337 - __main__ - INFO - --- NODE: SUMMARIZE ---\n",
      "2026-01-14 19:14:02,117 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:14:02,120 - __main__ - INFO - Summary: No progress has been made since the previous critique.\n",
      "2026-01-14 19:14:02,121 - __main__ - INFO - --- NODE: REFLECT ---\n",
      "2026-01-14 19:14:02,122 - __main__ - INFO - Reflection attempt 1/3 (temp=0.15)\n",
      "2026-01-14 19:14:30,457 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:15:19,503 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:15:19,514 - __main__ - INFO - Attempt 1 Score: 8.15 (Previous: 8.70)\n",
      "2026-01-14 19:15:19,514 - __main__ - WARNING - Score dropped to 8.15. Retrying...\n",
      "2026-01-14 19:15:19,514 - __main__ - INFO - Reflection attempt 2/3 (temp=0.25)\n",
      "2026-01-14 19:15:48,583 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:16:14,256 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:16:14,262 - __main__ - INFO - Attempt 2 Score: 7.90 (Previous: 8.70)\n",
      "2026-01-14 19:16:14,262 - __main__ - WARNING - Score dropped to 7.90. Retrying...\n",
      "2026-01-14 19:16:14,263 - __main__ - INFO - Reflection attempt 3/3 (temp=0.35)\n",
      "2026-01-14 19:16:44,213 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:17:12,553 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:17:12,560 - __main__ - INFO - Attempt 3 Score: 7.90 (Previous: 8.70)\n",
      "2026-01-14 19:17:12,561 - __main__ - WARNING - Score dropped to 7.90. Retrying...\n",
      "2026-01-14 19:17:12,561 - __main__ - WARNING - All reflection attempts failed to improve score. Rolling back to old diagram.\n",
      "2026-01-14 19:17:12,561 - __main__ - WARNING - Score plateau detected. Stopping.\n",
      "2026-01-14 19:17:12,562 - __main__ - WARNING - Max iterations (6) reached after reflection\n",
      "2026-01-14 19:17:12,563 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:17:12,564 - __main__ - INFO - WORKFLOW COMPLETED\n",
      "2026-01-14 19:17:12,564 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:17:12,564 - __main__ - INFO - Iterations: 6\n",
      "2026-01-14 19:17:12,564 - __main__ - INFO - Syntax Valid: True\n",
      "2026-01-14 19:17:12,564 - __main__ - INFO - Logic Valid: False\n",
      "2026-01-14 19:17:12,570 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "Iterations: 6\n",
      "Syntax Valid: True\n",
      "Logic Valid: False\n",
      "\n",
      "Diagram URL: http://localhost:8080/png/TLEzJWCn3Dxp554NVgGEh3U12aC7HA7io2HM6v6V8t643iJA4_24F0c-QvjBIrdEFx4_svzzbuaWKdPM26KX9Rc8GMT5yaD8cLvo8vSKZL-nvS5XPMfCAfgMJF2Ljur6STGrAkF0zXWKrCjz1a-6kaREFU4Ae_ZSrPi1EqBiXe96Zn471SU4p90Euv203eojotF4MuYwSgMrQLjMhxIEc58Zjme_FHjhZxsKMdTHRmk5NhlcNdas_ZuQXyDmG9aJRtnsR58Wi5SkP4yZ1VjWSq8t0Bx-eKJAx0qjzWaisSjr6CQOyReOeFWNq3dqctsr6_qMQHrg2YY2Jw3wLStr7bj3_BAUeW1loTWS0aL4gZBLqFd8CGtC5FlTjBEWQu_gIObTlSuJ-O0M-gRw5IMnkxp9nKHEft9oFgaeQnZ14nYVn6Of_qGPhspcqnJbJ0u3EQYreF0GYCMEoqQkuGW2YxqjD3AySJyyo2tuRafXsajvkXlav-kxdFVPEDvvwQVSVYEVqGQ_IayKXBX4h_cF_0K=\n",
      "\n",
      "Generated Diagram:\n",
      "@startuml\n",
      "\n",
      "class Product {\n",
      "  sku: String\n",
      "  name: String\n",
      "  description: String\n",
      "  price: Decimal\n",
      "  stockQuantity: Integer\n",
      "}\n",
      "\n",
      "class Category {\n",
      "  id: Integer\n",
      "  name: String\n",
      "}\n",
      "\n",
      "class Customer {\n",
      "  email: String\n",
      "  password: String\n",
      "  shippingAddress: Address\n",
      "  billingAddress: Address\n",
      "}\n",
      "\n",
      "class Order {\n",
      "  orderDate: DateTime\n",
      "  status: Enum\n",
      "  totalAmount: Decimal\n",
      "}\n",
      "\n",
      "class OrderItem {\n",
      "  quantity: Integer\n",
      "  unitPrice: Decimal\n",
      "}\n",
      "\n",
      "class ShoppingCart {\n",
      "}\n",
      "\n",
      "class Payment {\n",
      "  paymentMethod: String\n",
      "  transactionId: String\n",
      "  paymentStatus: Enum\n",
      "}\n",
      "\n",
      "class Address {\n",
      "  street: String\n",
      "  city: String\n",
      "  state: String\n",
      "  zipCode: String\n",
      "  country: String\n",
      "}\n",
      "\n",
      "' Relationships\n",
      "Product \"1\" -- \"*\" OrderItem : contains\n",
      "Order \"1\" -- \"*\" OrderItem : includes\n",
      "Customer \"1\" -- \"*\" Order : places\n",
      "Order \"1\" -- \"1\" Payment : has\n",
      "Customer \"1\" -- \"1\" ShoppingCart : owns\n",
      "\n",
      "' Many-to-Many (Product â†” Category)\n",
      "Product \"*\" -- \"*\" Category : belongs_to\n",
      "\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "def run_single_test(\n",
    "    app: Any,\n",
    "    requirements: str,\n",
    "    exercise_name: str = \"Test Exercise\"\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    Run the workflow on a single exercise.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        requirements: Software requirements text\n",
    "        exercise_name: Name for logging purposes\n",
    "        \n",
    "    Returns:\n",
    "        Final workflow state\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"RUNNING: {exercise_name}\")\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"Requirements preview: {requirements[:150]}...\")\n",
    "    \n",
    "    initial_state = create_initial_state(requirements)\n",
    "    \n",
    "    try:\n",
    "        final_output = app.invoke(initial_state, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"WORKFLOW COMPLETED\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Iterations: {final_output['iterations']}\")\n",
    "        logger.info(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "        logger.info(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "        \n",
    "        if final_output.get('best_diagram') and not final_output['logic_valid']:\n",
    "            if final_output['best_diagram'] != final_output['current_diagram']:\n",
    "                logger.info(\"Using BEST diagram instead of final (prevented regression)\")\n",
    "                final_output['current_diagram'] = final_output['best_diagram']\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Workflow execution failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Select and run a test exercise\n",
    "test_idx = 0\n",
    "requirements = test_exercises[test_idx][\"requirements\"]\n",
    "\n",
    "final_output = run_single_test(\n",
    "    app, \n",
    "    requirements, \n",
    "    f\"Exercise {test_idx + 1}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Iterations: {final_output['iterations']}\")\n",
    "print(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "print(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "\n",
    "if final_output['current_diagram']:\n",
    "    puml_tool = PlantUMLTool(config.plantuml_host)\n",
    "    diagram_url = puml_tool.get_diagram_url(final_output['current_diagram'])\n",
    "    print(f\"\\nDiagram URL: {diagram_url}\")\n",
    "    \n",
    "    print(\"\\nGenerated Diagram:\")\n",
    "    print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e84c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@startuml\n",
      "\n",
      "class Book {\n",
      "  isbn: String\n",
      "  title: String\n",
      "  author: String\n",
      "  publisher: String\n",
      "  publicationYear: Integer\n",
      "  availabilityStatus: Boolean\n",
      "}\n",
      "\n",
      "class Member {\n",
      "  membershipId: String\n",
      "  name: String\n",
      "  address: String\n",
      "  phoneNumber: String\n",
      "  registrationDate: Date\n",
      "}\n",
      "\n",
      "class Student {\n",
      "  studentId: String\n",
      "  programOfStudy: String\n",
      "}\n",
      "\n",
      "class FacultyMember {\n",
      "  employeeId: String\n",
      "  department: String\n",
      "}\n",
      "\n",
      "class Loan {\n",
      "  checkoutDate: Date\n",
      "  dueDate: Date\n",
      "  returnDate: Date\n",
      "}\n",
      "\n",
      "class Fine {\n",
      "  fineAmount: Decimal\n",
      "  paymentStatus: Boolean\n",
      "}\n",
      "\n",
      "class Reservation {\n",
      "  reservationDate: Date\n",
      "}\n",
      "\n",
      "Member <|-- Student\n",
      "Member <|-- FacultyMember\n",
      "\n",
      "Member \"1\" -- \"*\" Loan : borrows\n",
      "Book \"1\" -- \"*\" Loan : is borrowed via\n",
      "\n",
      "Member \"1\" -- \"*\" Reservation : makes\n",
      "Book \"1\" -- \"*\" Reservation : is reserved by\n",
      "\n",
      "Loan \"1\" -- \"0..1\" Fine : has\n",
      "\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b3e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics(BaseModel):\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    precision: float = Field(ge=0.0, le=1.0, description=\"Precision score\")\n",
    "    recall: float = Field(ge=0.0, le=1.0, description=\"Recall score\")\n",
    "    f1: float = Field(ge=0.0, le=1.0, description=\"F1 score\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"P={self.precision:.2f}, R={self.recall:.2f}, F1={self.f1:.2f}\"\n",
    "\n",
    "\n",
    "class PlantUMLParser:\n",
    "    \"\"\"\n",
    "    Parser for extracting structured information from PlantUML diagrams.\n",
    "    \n",
    "    Extracts classes, attributes, and relationships from PlantUML code\n",
    "    for evaluation purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plantuml_code: str):\n",
    "        \"\"\"\n",
    "        Initialize parser with PlantUML code.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "        \"\"\"\n",
    "        self.plantuml_code = plantuml_code\n",
    "        self.classes: Dict[str, Dict[str, List[str]]] = {}\n",
    "        self.relationships: List[Dict[str, Any]] = []\n",
    "        self.parse()\n",
    "    \n",
    "    def parse(self) -> None:\n",
    "        \"\"\"Parse the PlantUML code.\"\"\"\n",
    "        try:\n",
    "            self._extract_classes()\n",
    "            self._extract_relationships()\n",
    "            logger.debug(f\"Parsed {len(self.classes)} classes and {len(self.relationships)} relationships\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Parsing failed: {e}\")\n",
    "    \n",
    "    def _extract_classes(self) -> None:\n",
    "        \"\"\"Extract class definitions and their attributes.\"\"\"\n",
    "        class_pattern = r'class\\s+(\\w+)\\s*\\{([^}]*)\\}'\n",
    "        matches = re.finditer(class_pattern, self.plantuml_code, re.MULTILINE | re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            class_name = match.group(1)\n",
    "            class_body = match.group(2)\n",
    "            \n",
    "            attributes = []\n",
    "            for line in class_body.strip().split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('--'):\n",
    "                    attributes.append(line)\n",
    "            \n",
    "            self.classes[class_name] = {'attributes': attributes}\n",
    "    \n",
    "    def _extract_relationships(self) -> None:\n",
    "        \"\"\"Extract relationships between classes with cardinalities.\"\"\"\n",
    "        patterns = [\n",
    "            # Generalization (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<\\|--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--|>\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            \n",
    "            # Composition (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*\\*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\*\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            \n",
    "            # Aggregation (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*o--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--o\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            \n",
    "            # Directed Association (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*-->\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            \n",
    "            # Simple Association (no arrow)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, rel_type in patterns:\n",
    "            for match in re.finditer(pattern, self.plantuml_code):\n",
    "                source = match.group(1)\n",
    "                target = match.group(4)\n",
    "                \n",
    "                # Skip if source or target is None or empty\n",
    "                if not source or not target:\n",
    "                    continue\n",
    "                \n",
    "                self.relationships.append({\n",
    "                    'type': rel_type,\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'cardinality_source': match.group(2) if match.lastindex >= 2 else None,\n",
    "                    'cardinality_target': match.group(3) if match.lastindex >= 3 else None\n",
    "                })\n",
    "\n",
    "\n",
    "class DiagramEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for comparing generated diagrams against gold standards.\n",
    "    \n",
    "    Computes precision, recall, and F1 scores for classes, attributes,\n",
    "    and relationships.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gold_plantuml: str, pred_plantuml: str):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with gold and predicted diagrams.\n",
    "        \n",
    "        Args:\n",
    "            gold_plantuml: Gold standard PlantUML code\n",
    "            pred_plantuml: Predicted PlantUML code\n",
    "        \"\"\"\n",
    "        self.gold_parser = PlantUMLParser(gold_plantuml)\n",
    "        self.pred_parser = PlantUMLParser(pred_plantuml)\n",
    "    \n",
    "    def _normalize_attr(self, attr_str: str) -> str:\n",
    "        \"\"\"Normalize attribute strings for comparison.\"\"\"\n",
    "        return attr_str.split(':')[0].strip().lower()\n",
    "    \n",
    "    def _normalize_rel_type(self, rel_type: str) -> str:\n",
    "        \"\"\"Normalize relationship types.\"\"\"\n",
    "        mapping = {\n",
    "            '<|--': 'INHERITANCE',\n",
    "            '--|>': 'INHERITANCE',\n",
    "            '*--': 'COMPOSITION',\n",
    "            '--*': 'COMPOSITION',\n",
    "            'o--': 'AGGREGATION',\n",
    "            '--o': 'AGGREGATION',\n",
    "            '--': 'ASSOCIATION',\n",
    "            '<--': 'ASSOCIATION',\n",
    "            '-->': 'ASSOCIATION'\n",
    "        }\n",
    "        return mapping.get(rel_type, 'ASSOCIATION')\n",
    "    \n",
    "    def _calculate_metrics(\n",
    "        self, \n",
    "        gold_set: set, \n",
    "        pred_set: set\n",
    "    ) -> EvaluationMetrics:\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1 scores.\n",
    "        \n",
    "        Args:\n",
    "            gold_set: Set of gold standard elements\n",
    "            pred_set: Set of predicted elements\n",
    "            \n",
    "        Returns:\n",
    "            EvaluationMetrics object\n",
    "        \"\"\"\n",
    "        tp = len(gold_set.intersection(pred_set))\n",
    "        fp = len(pred_set - gold_set)\n",
    "        fn = len(gold_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return EvaluationMetrics(\n",
    "            precision=round(precision, 2),\n",
    "            recall=round(recall, 2),\n",
    "            f1=round(f1, 2)\n",
    "        )\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, EvaluationMetrics]:\n",
    "        \"\"\"\n",
    "        Get all evaluation metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with metrics for classes, attributes, and relationships\n",
    "        \"\"\"\n",
    "        # Classes \n",
    "        gold_classes = {c.lower() for c in self.gold_parser.classes.keys()}\n",
    "        pred_classes = {c.lower() for c in self.pred_parser.classes.keys()}\n",
    "        \n",
    "        # Attributes \n",
    "        gold_attrs = set()\n",
    "        for cls, info in self.gold_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                gold_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        pred_attrs = set()\n",
    "        for cls, info in self.pred_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                pred_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        # Relationships (type + direction only)\n",
    "        gold_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        # Cardinalities \n",
    "        gold_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            \"classes\": self._calculate_metrics(gold_classes, pred_classes),\n",
    "            \"attributes\": self._calculate_metrics(gold_attrs, pred_attrs),\n",
    "            \"relationships\": self._calculate_metrics(gold_rels, pred_rels),\n",
    "            \"cardinalities\": self._calculate_metrics(gold_rels_card, pred_rels_card)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "def evaluate_diagram(\n",
    "    gold_standard: str,\n",
    "    generated_diagram: str\n",
    ") -> Dict[str, EvaluationMetrics]:\n",
    "    \"\"\"\n",
    "    Evaluate a generated diagram against gold standard.\n",
    "    \n",
    "    Args:\n",
    "        gold_standard: Gold standard PlantUML code\n",
    "        generated_diagram: Generated PlantUML code\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    evaluator = DiagramEvaluator(gold_standard, generated_diagram)\n",
    "    return evaluator.get_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "389c5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS\n",
      "============================================================\n",
      "\n",
      "Classes:       P=0.86, R=0.86, F1=0.86\n",
      "Attributes:    P=0.90, R=0.86, F1=0.88\n",
      "Relationships: P=0.86, R=0.86, F1=0.86\n",
      "Cardinalities: P=0.29, R=0.29, F1=0.29\n",
      "\n",
      "============================================================\n",
      "OVERALL F1 SCORE: 0.75\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "gold_standard = test_exercises[test_idx][\"solution_plantuml\"]\n",
    "generated_diagram = final_output[\"current_diagram\"]\n",
    "\n",
    "metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nClasses:       {metrics['classes']}\")\n",
    "print(f\"Attributes:    {metrics['attributes']}\")\n",
    "print(f\"Relationships: {metrics['relationships']}\")\n",
    "print(f\"Cardinalities: {metrics['cardinalities']}\")\n",
    "\n",
    "weighted_avg_f1 = (\n",
    "    metrics['classes'].f1 * 0.3 + \n",
    "    metrics['attributes'].f1 * 0.2 + \n",
    "    metrics['relationships'].f1 * 0.3 +\n",
    "    metrics['cardinalities'].f1 * 0.2\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL F1 SCORE: {weighted_avg_f1:.2f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42196e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 18:59:52,725 - __main__ - INFO - ============================================================\n",
      "2026-01-14 18:59:52,726 - __main__ - INFO - BATCH EVALUATION: 3 exercises\n",
      "2026-01-14 18:59:52,726 - __main__ - INFO - ============================================================\n",
      "2026-01-14 18:59:52,726 - __main__ - INFO - \n",
      "--- Exercise 1/3 ---\n",
      "2026-01-14 18:59:52,727 - __main__ - INFO - ============================================================\n",
      "2026-01-14 18:59:52,727 - __main__ - INFO - RUNNING: Exercise 1\n",
      "2026-01-14 18:59:52,727 - __main__ - INFO - ============================================================\n",
      "2026-01-14 18:59:52,727 - __main__ - INFO - Requirements preview: An e-commerce platform manages products, customers, and orders.\n",
      "Each product has a unique SKU, name, description, price, and stock quantity.\n",
      "Products ...\n",
      "2026-01-14 18:59:52,731 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "2026-01-14 18:59:55,601 - __main__ - INFO - Retrieved 3 similar diagrams from SQLite\n",
      "2026-01-14 18:59:55,604 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-14 18:59:55,606 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-14 19:00:29,071 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:00:29,081 - __main__ - INFO - Decomposition completed\n",
      "2026-01-14 19:00:29,083 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n",
      "2026-01-14 19:00:38,360 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:00:38,373 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-14 19:01:47,480 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:01:47,485 - __main__ - INFO - Generation completed (iteration 1)\n",
      "2026-01-14 19:01:47,488 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-14 19:01:47,489 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-14 19:01:47,678 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-14 19:01:47,679 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/TLEnRiCW4Dtv2kIbKgGCNJqbIZfug9estQiBq1W53XSEHL7LV-_PQHpSfelXZiTxVWzO9898sJiXb8EKv2O6dHN9Jo5bEkHQRYbQt7E5u4rHQfDKj1tPW4MtYrOnQcsKzU1w3Whgy9m1oTAfbWsIsPielYvwA-16YAT1S29nXMGcyIOE4EF1kbAG4SSGTT5AhUqwdYwrZYQbOcLddRknC2ezHVqZ4_hPcl-DlV3trNepc07AlEy1i-UI0e5R-f2HhfQdP0qPFn1-_8b0oeoMDjF0njtRDWmcLdmyJ33sDt3o1gd1zn0zzEaFzDsv_MYe3MKM504Jg1xNw4bi0tvR6cADE_bYtC3QXvZ4vJPKzvMSpsKrgmfRjLG12ImcSGxk7vH5vJ9V5p4Uv6yWWpe7wXQ4XqaKjGn75loboCEDO6hPGk5XDegEbwwME-C2xjCR1I4M1ZK_XMy=\n",
      "2026-01-14 19:01:47,680 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-14 19:02:18,858 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:02:18,867 - __main__ - INFO - Logic validation: FAILED (Weighted Score: 7.90)\n",
      "2026-01-14 19:02:18,867 - __main__ - INFO -   Requirements Coverage: 8.00/10\n",
      "2026-01-14 19:02:18,867 - __main__ - INFO -   Design Best Practices: 7.00/10\n",
      "2026-01-14 19:02:18,868 - __main__ - INFO -   Structural Integrity: 9.00/10\n",
      "2026-01-14 19:02:18,868 - __main__ - INFO - Found 8 errors\n",
      "2026-01-14 19:02:18,868 - __main__ - INFO - --- NODE: SUMMARIZE ---\n",
      "2026-01-14 19:02:31,264 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:02:31,275 - __main__ - INFO - Summary: This is the first critique, so there are no previous issues to compare against. All current errors must be addressed.\n",
      "2026-01-14 19:02:31,276 - __main__ - INFO - --- NODE: REFLECT ---\n",
      "2026-01-14 19:02:31,277 - __main__ - ERROR - Workflow execution failed: cannot access local variable 'summary_json' where it is not associated with a value\n",
      "2026-01-14 19:02:31,277 - __main__ - ERROR - âœ— Exercise 1 failed: cannot access local variable 'summary_json' where it is not associated with a value\n",
      "2026-01-14 19:02:31,277 - __main__ - INFO - \n",
      "--- Exercise 2/3 ---\n",
      "2026-01-14 19:02:31,277 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:02:31,277 - __main__ - INFO - RUNNING: Exercise 2\n",
      "2026-01-14 19:02:31,278 - __main__ - INFO - ============================================================\n",
      "2026-01-14 19:02:31,278 - __main__ - INFO - Requirements preview: A university manages students, courses, and instructors.\n",
      "Each student has a student ID, name, email, date of birth, and major.\n",
      "Instructors have an emp...\n",
      "2026-01-14 19:02:31,278 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "2026-01-14 19:02:34,042 - __main__ - INFO - Retrieved 3 similar diagrams from SQLite\n",
      "2026-01-14 19:02:34,043 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-14 19:02:34,043 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-14 19:03:03,748 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-14 19:03:03,754 - __main__ - INFO - Decomposition completed\n",
      "2026-01-14 19:03:03,756 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Example: Run on first 3 exercises (uncomment to execute)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m df_results = \u001b[43mevaluate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_exercises\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpuml_tool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_exercises\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mevaluate_batch\u001b[39m\u001b[34m(app, test_exercises, puml_tool, max_exercises)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Run workflow\u001b[39;00m\n\u001b[32m     64\u001b[39m     requirements = exercise[\u001b[33m\"\u001b[39m\u001b[33mrequirements\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     final_output = \u001b[43mrun_single_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExercise \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m     68\u001b[39m     gold_standard = exercise[\u001b[33m\"\u001b[39m\u001b[33msolution_plantuml\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_single_test\u001b[39m\u001b[34m(app, requirements, exercise_name)\u001b[39m\n\u001b[32m     22\u001b[39m initial_state = create_initial_state(requirements)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     final_output = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     28\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mWORKFLOW COMPLETED\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mUMLNodes.logic_auditor\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    139\u001b[39m requirements = state.get(\u001b[33m\"\u001b[39m\u001b[33mrequirements\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    141\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[33mYou are a Senior Software Architect auditing a UML Class Diagram plan.\u001b[39m\n\u001b[32m    143\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33mIf the plan is flawed, be specific about what is missing.\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m audit_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPlanAudit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a Senior Software Architect auditing a UML Class Diagram plan.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    165\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mplan_valid\u001b[39m\u001b[33m\"\u001b[39m: audit_result.is_valid,\n\u001b[32m    166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maudit_feedback\u001b[39m\u001b[33m\"\u001b[39m: audit_result.critique + audit_result.suggestions,\n\u001b[32m    167\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33miterations\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33miterations\u001b[39m\u001b[33m\"\u001b[39m] + (\u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m audit_result.is_valid \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m)\n\u001b[32m    168\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3149\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3149\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3150\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3151\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1354\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1351\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1353\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m     )\n\u001b[32m   1358\u001b[39m     response = raw_response.parse()\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:184\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    179\u001b[39m         response_format=response_format,\n\u001b[32m    180\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    181\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Magistrale/LLM/A4Design/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class BatchResult(BaseModel):\n",
    "    \"\"\"Result from a single exercise in batch evaluation.\"\"\"\n",
    "    exercise_num: int = Field(description=\"Exercise number\")\n",
    "    success: bool = Field(description=\"Whether the exercise was successful\")\n",
    "    iterations: int = Field(default=0, ge=0, description=\"Number of iterations used\")\n",
    "    syntax_valid: bool = Field(default=False, description=\"Whether syntax validation passed\")\n",
    "    logic_valid: bool = Field(default=False, description=\"Whether logic validation passed\")\n",
    "    metrics: Optional[Dict[str, EvaluationMetrics]] = Field(default=None, description=\"Evaluation metrics\")\n",
    "    diagram_url: Optional[str] = Field(default=None, description=\"URL to view the diagram\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if failed\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for DataFrame creation.\"\"\"\n",
    "        if self.metrics:\n",
    "            return {\n",
    "                \"exercise\": self.exercise_num,\n",
    "                \"success\": self.success,\n",
    "                \"iterations\": self.iterations,\n",
    "                \"syntax_valid\": self.syntax_valid,\n",
    "                \"logic_valid\": self.logic_valid,\n",
    "                \"class_f1\": self.metrics['classes'].f1,\n",
    "                \"attr_f1\": self.metrics['attributes'].f1,\n",
    "                \"rel_f1\": self.metrics['relationships'].f1,\n",
    "                \"card_f1\": self.metrics['cardinalities'].f1,\n",
    "                \"diagram_url\": self.diagram_url\n",
    "            }\n",
    "        return {\n",
    "            \"exercise\": self.exercise_num,\n",
    "            \"success\": self.success,\n",
    "            \"error\": self.error\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_batch(\n",
    "    app: Any,\n",
    "    test_exercises: List[Dict[str, Any]],\n",
    "    puml_tool: PlantUMLTool,\n",
    "    max_exercises: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run batch evaluation on multiple exercises.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        test_exercises: List of exercise dictionaries\n",
    "        puml_tool: PlantUML tool for URL generation\n",
    "        max_exercises: Optional limit on number of exercises\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with evaluation results\n",
    "    \"\"\"\n",
    "    exercises_to_test = test_exercises[:max_exercises] if max_exercises else test_exercises\n",
    "    results = []\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"BATCH EVALUATION: {len(exercises_to_test)} exercises\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    for i, exercise in enumerate(exercises_to_test):\n",
    "        logger.info(f\"\\n--- Exercise {i+1}/{len(exercises_to_test)} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Run workflow\n",
    "            requirements = exercise[\"requirements\"]\n",
    "            final_output = run_single_test(app, requirements, f\"Exercise {i+1}\")\n",
    "            \n",
    "            # Evaluate\n",
    "            gold_standard = exercise[\"solution_plantuml\"]\n",
    "            generated_diagram = final_output[\"current_diagram\"]\n",
    "            metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "            \n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=True,\n",
    "                iterations=final_output[\"iterations\"],\n",
    "                syntax_valid=final_output[\"syntax_valid\"],\n",
    "                logic_valid=final_output[\"logic_valid\"],\n",
    "                metrics=metrics,\n",
    "                diagram_url=puml_tool.get_diagram_url(generated_diagram)\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Exercise {i+1}: F1 = Classes:{metrics['classes'].f1:.2f} | \"\n",
    "                       f\"Attrs:{metrics['attributes'].f1:.2f} | Rels:{metrics['relationships'].f1:.2f} | \"\n",
    "                       f\"Cards:{metrics['cardinalities'].f1:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âœ— Exercise {i+1} failed: {e}\")\n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=False,\n",
    "                error=str(e)\n",
    "            )\n",
    "        \n",
    "        results.append(result.to_dict())\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    logger.info(\"\\n\" + \"=\"*60)\n",
    "    logger.info(\"BATCH EVALUATION COMPLETE\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example: Run on first 3 exercises (uncomment to execute)\n",
    "df_results = evaluate_batch(app, test_exercises, puml_tool, max_exercises=3)\n",
    "# \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "successful = df_results[df_results['success'] == True]\n",
    "if not successful.empty:\n",
    "    print(successful[['exercise', 'class_f1', 'attr_f1', 'rel_f1']].to_string(index=False))\n",
    "    avg_f1 = successful[['class_f1', 'attr_f1', 'rel_f1']].mean().mean()\n",
    "    print(f\"\\nAverage F1: {avg_f1:.2f}\")\n",
    "else:\n",
    "    print(\"No successful evaluations\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
