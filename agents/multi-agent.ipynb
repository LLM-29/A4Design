{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0865aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import requests\n",
    "import operator\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Annotated, List, TypedDict, Optional, Dict, Any, Tuple\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97779ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNames(str, Enum):\n",
    "    \"\"\"Enum for node names to avoid string literals.\"\"\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    DECOMPOSE = \"decompose\"\n",
    "    GENERATE = \"generate\"\n",
    "    SYNTAX_CHECK = \"syntax_check\"\n",
    "    CRITIC = \"critic\"\n",
    "    SUMMARIZE = \"summarize\"\n",
    "    REFLECT = \"reflect\"\n",
    "    PLAN_AUDIT = \"plan_audit\"\n",
    "\n",
    "\n",
    "class CritiqueError(BaseModel):\n",
    "    \"\"\"Model for a single critique error.\"\"\"\n",
    "    type: str = Field(description=\"Type of error\")\n",
    "    description: str = Field(description=\"Detailed description of the error\")\n",
    "\n",
    "\n",
    "class CritiqueResponse(BaseModel):\n",
    "    \"\"\"Structured output from the CRITIC node.\"\"\"\n",
    "    requirement_coverage: float = Field(..., ge=0, le=10, description=\"Does it capture all classes and relationships from the text?\")\n",
    "    design_best_practices: float = Field(..., ge=0, le=10, description=\"Are relationships correct? (e.g., composition vs association)\")\n",
    "    structural_integrity: float = Field(..., ge=0, le=10, description=\"Are there redundant classes or missing attributes?\")\n",
    "    \n",
    "    is_valid: bool = Field(description=\"True only if total average score is > 8.5 AND 'requirement_coverage' is >= 9.0\")\n",
    "    \n",
    "    errors: List[CritiqueError] = Field(default_factory=list, description=\"List of errors found\")\n",
    "    warnings: List[str] = Field(default_factory=list, description=\"List of warnings\")\n",
    "    missing_concepts: List[str] = Field(default_factory=list, description=\"Concepts from requirements not in diagram\")\n",
    "    reasoning: str = Field(description=\"Brief explanation for the scores provided.\")\n",
    "\n",
    "    @property\n",
    "    def weighted_score(self) -> float:\n",
    "        return (self.requirement_coverage * 0.5) + \\\n",
    "               (self.design_best_practices * 0.3) + \\\n",
    "               (self.structural_integrity * 0.2)\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def compute_validity(self) -> 'CritiqueResponse':\n",
    "        self.is_valid = (self.weighted_score > 8.5) and (self.requirement_coverage >= 9.0)\n",
    "        return self\n",
    "\n",
    "\n",
    "class SummaryResponse(BaseModel):\n",
    "    \"\"\"Structured output from the SUMMARIZER node.\"\"\"\n",
    "    is_complete: bool = Field(description=\"Whether all issues are resolved\")\n",
    "    fixed: List[str] = Field(default_factory=list, description=\"Issues that were fixed\")\n",
    "    unresolved: List[str] = Field(default_factory=list, description=\"Issues still present\")\n",
    "    message: str = Field(description=\"Brief status summary\")\n",
    "\n",
    "\n",
    "class ComparisonResponse(BaseModel):\n",
    "    \"\"\"Structured output from the COMPARATOR (in REFLECT node).\"\"\"\n",
    "    is_better: bool = Field(description=\"Whether the new diagram is better than the old\")\n",
    "    reasoning: str = Field(description=\"Explanation of the decision\")\n",
    "    recommendation: str = Field(description=\"Either 'keep_new' or 'rollback_to_old'\")\n",
    "\n",
    "\n",
    "class PlanAudit(BaseModel):\n",
    "    is_valid: bool = Field(description=\"True if the plan is logically sound and covers all requirements.\")\n",
    "    critique: List[str] = Field(default_factory=list, description=\"List of specific logical flaws (e.g., 'Missing relationship between User and Account').\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Actionable steps to fix the plan.\")\n",
    "\n",
    "\n",
    "class PromptConstants:\n",
    "    DECOMPOSER_SYSTEM = \"\"\"\n",
    "    # ROLE\n",
    "    You are a Software Architect specializing in domain modeling and structural analysis.\n",
    "\n",
    "    # TASK\n",
    "    Extract the core structural building blocks from the provided requirements. \n",
    "\n",
    "    # EXTRACTION RULES\n",
    "    - **Classes**: Main entities only (e.g., User, Order).\n",
    "    - **Attributes**: Data fields with types (e.g., name: String).\n",
    "    - **Relationships**: Direct interactions (Inheritance, Association, Composition).\n",
    "\n",
    "    # CONSTRAINTS\n",
    "    - Extract ONLY what is EXPLICITLY mentioned. \n",
    "    - Do NOT infer methods or operations.\n",
    "    - Do NOT create classes that represent alone the whole system.\n",
    "    \"\"\"\n",
    "    \n",
    "    GENERATOR_SYSTEM = \"\"\"\n",
    "    # ROLE\n",
    "    You are a Senior UML Designer and PlantUML Syntax Expert.\n",
    "\n",
    "    # TASK\n",
    "    Transform the design plan into a syntactically perfect PlantUML Class Diagram.\n",
    "\n",
    "    # STRUCTURAL RULES\n",
    "    - **Inheritance**: Use `<|--` or '--|>' for \"is-a\" relationships.\n",
    "    - **Composition**: Use `*--` or '--*' for ownership/lifecycle dependency.\n",
    "    - **Cardinality**: Must be quoted on both ends (e.g., \"1\" -- \"*\").\n",
    "    - **Attributes**: Use standard `class Name { attr: Type }` syntax.\n",
    "\n",
    "    # RELATIONSHIP RULES\n",
    "    - **Uniqueness**: Between any two classes, there must be exactly ZERO or ONE relationship line. \n",
    "    - **No Duplicates**: Never use two lines to connect the same two classes (e.g., do NOT have both `A --> B` and `A *-- B`). \n",
    "    - **Selection**: If the requirements imply both an association and a composition, choose ONLY the strongest one (composition > association).\n",
    "    - **Directionality**: For bidirectional relationships, use a single line without arrows or with arrows on both ends, not two separate lines.\n",
    "\n",
    "    # CONSTRAINTS\n",
    "    - STRICTLY NO METHODS (no parentheses `()`).\n",
    "    - Use ONLY classes and attributes from the design plan.\n",
    "    - If a class has no attributes, define it as `class Name`.\n",
    "    - Output ONLY the code block starting with `@startuml` and ending with `@enduml`.\n",
    "    \"\"\"\n",
    "    \n",
    "    CRITIC_SYSTEM = \"\"\"\n",
    "    # ROLE\n",
    "    You are a Meticulous UML Quality Auditor.\n",
    "\n",
    "    # SCORING REQUIREMENTS\n",
    "    1. **Requirement Coverage**: Do all nouns/verbs from requirements exist in the diagram?\n",
    "    2. **Design Best Practices**: Are notations correct (no methods, quoted cardinality)?\n",
    "    3. **Structural Integrity**: Are there redundant \"double lines\" between classes?\n",
    "\n",
    "    # TASK\n",
    "    Assign a score of 0-10 for each category. Provide specific errors for anything below a 10.\n",
    "    Note: A 'weighted_score' will be calculated automatically. You do not need to perform the math, \n",
    "    but be aware that 'is_valid' will only trigger if Coverage >= 9.0 and the total weighted average > 8.5.\n",
    "    \"\"\"\n",
    "    \n",
    "    SUMMARIZER_SYSTEM = \"\"\"\n",
    "    Your task is to compare the current critique with previous ones and identify progress.\n",
    "    \n",
    "    Analyze what has been fixed and what remains unresolved.\n",
    "    Set is_complete=true only if no errors remain.\n",
    "    \n",
    "    Return your response in the specified structured format.\n",
    "    \"\"\"\n",
    "    \n",
    "    REFLECTOR_SYSTEM = \"\"\"\n",
    "    # ROLE\n",
    "    You are a Senior Software Engineer specializing in code refactoring and error correction.\n",
    "\n",
    "    # TASK\n",
    "    Fix the current PlantUML diagram by addressing the \"UNRESOLVED\" issues provided in the summary.\n",
    "\n",
    "    # STRATEGY\n",
    "    - **Minimal Intervention**: Only modify elements identified as broken or missing.\n",
    "    - **Preservation**: Do NOT reorganize or rename classes that are already correct.\n",
    "    - **Strict Adherence**: Ensure the fix does not introduce new syntax errors.\n",
    "\n",
    "    ## STRUCTURAL CORRECTION\n",
    "    - **Consolidation**: If the critique identifies redundant or \"double\" relationships between two classes, consolidate them into a single line. \n",
    "    - **Priority**: When consolidating, prioritize the more specific relationship (e.g., use Composition `*--` over simple Association `-->`).\n",
    "    - **Cardinality**: Ensure that when you merge two lines into one, the cardinality from both is correctly reflected on the single remaining line.\n",
    "\n",
    "    # OUTPUT\n",
    "    Provide the FULL corrected PlantUML diagram code block.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    lmstudio_base_url: str = \"http://localhost:1234/v1\"\n",
    "    # model_name: str = \"qwen2.5-coder-14b-instruct\"\n",
    "    model_name: str = \"mistralai/devstral-small-2-2512\"\n",
    "    embedder_model: str = \"all-MiniLM-L6-v2\"\n",
    "    shots_json_path: str = \"./../data/complete_shots.json\"\n",
    "    plantuml_host: str = \"http://localhost:8080\"\n",
    "    max_iterations: int = 6\n",
    "    max_tokens_decompose: int = 1024\n",
    "    max_tokens_generate: int = 2048\n",
    "    max_tokens_critique: int = 2048\n",
    "    max_tokens_summarize: int = 1024\n",
    "    max_tokens_reflect: int = 2048\n",
    "    max_tokens_compare: int = 1024\n",
    "    temperature_base: float = 0.15\n",
    "    temperature_reflect: float = 0.15\n",
    "    num_few_shots: int = 3\n",
    "    request_timeout: int = 5  # For PlantUML server\n",
    "    llm_timeout: int = 120  # 2 minutes for LLM operations\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Shared state for the LangGraph workflow.\n",
    "    \"\"\"\n",
    "    requirements: str\n",
    "    plan: Optional[str]\n",
    "    examples: List[Dict[str, str]]\n",
    "    current_diagram: Optional[str]\n",
    "    best_diagram: Optional[str]  \n",
    "    history: Annotated[List[Dict[str, Any]], operator.add]\n",
    "    summary: Optional[str]\n",
    "    syntax_valid: bool\n",
    "    logic_valid: bool\n",
    "    error_message: Optional[str]\n",
    "    plan_valid: bool \n",
    "    best_score: float\n",
    "    best_code: str\n",
    "    current_validation: Optional[CritiqueResponse]\n",
    "    iterations: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b32b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm(config: Optional[SystemConfig] = None, temperature: Optional[float] = None) -> ChatOpenAI:\n",
    "    \"\"\"\n",
    "    Create a ChatOpenAI instance configured for LMStudio.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        temperature: Optional temperature override\n",
    "        \n",
    "    Returns:\n",
    "        Configured ChatOpenAI instance\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    temp = temperature if temperature is not None else cfg.temperature_base\n",
    "    logger.info(f\"Connecting to LMStudio at {cfg.lmstudio_base_url}\")\n",
    "    logger.info(f\"Using model: {cfg.model_name} (temp={temp})\")\n",
    "    \n",
    "    return ChatOpenAI(\n",
    "        base_url=cfg.lmstudio_base_url,\n",
    "        api_key=\"lm-studio\",  \n",
    "        model=cfg.model_name,\n",
    "        temperature=temp,\n",
    "        timeout=cfg.llm_timeout \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56dcf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlantUMLResult:\n",
    "    \"\"\"Result from PlantUML validation.\"\"\"\n",
    "    is_valid: bool\n",
    "    error: Optional[str] = None\n",
    "    url: Optional[str] = None\n",
    "    svg_url: Optional[str] = None\n",
    "\n",
    "\n",
    "class PlantUMLTool:\n",
    "    \"\"\"\n",
    "    Tool for validating and rendering PlantUML diagrams.\n",
    "    \n",
    "    This class interfaces with a PlantUML server to check syntax\n",
    "    and generate diagram URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host: str = \"http://localhost:8080\"):\n",
    "        \"\"\"\n",
    "        Initialize PlantUML tool.\n",
    "        \n",
    "        Args:\n",
    "            host: PlantUML server host URL\n",
    "        \"\"\"\n",
    "        self.host = host\n",
    "        logger.info(f\"PlantUML tool initialized with host: {host}\")\n",
    "\n",
    "    def extract_plantuml(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract PlantUML code from markdown blocks or raw text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text containing PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            Extracted PlantUML code or empty string\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Try to extract from ```plantuml ... ```\n",
    "        fence_match = re.search(r\"```\\s*plantuml\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if fence_match:\n",
    "            return fence_match.group(1).strip()\n",
    "        \n",
    "        # Try to extract from @startuml ... @enduml\n",
    "        tag_match = re.search(r\"@startuml.*?@enduml\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if tag_match:\n",
    "            return tag_match.group(0).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def _encode_plantuml(self, plantuml_code: str) -> str:\n",
    "        \"\"\"\n",
    "        Encode PlantUML code for URL.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: Raw PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            URL-safe encoded string\n",
    "        \"\"\"\n",
    "        code = plantuml_code.strip()\n",
    "        \n",
    "        if not code.startswith(\"@startuml\"): \n",
    "            code = f\"@startuml\\n{code}\"\n",
    "        if not code.endswith(\"@enduml\"): \n",
    "            code = f\"{code}\\n@enduml\"\n",
    "        \n",
    "        compressed = zlib.compress(code.encode('utf-8'))[2:-4]\n",
    "        encoded = base64.b64encode(compressed).translate(\n",
    "            bytes.maketrans(\n",
    "                b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\",\n",
    "                b\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_\"\n",
    "            )\n",
    "        ).decode('utf-8')\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "    def get_diagram_url(self, plantuml_code: str, format: str = \"png\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a viewable URL for the PlantUML diagram.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "            format: Output format (png, svg, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            URL to view the diagram\n",
    "        \"\"\"\n",
    "        diagram_code = self.extract_plantuml(plantuml_code)\n",
    "        encoded = self._encode_plantuml(diagram_code)\n",
    "        return f\"{self.host}/{format}/{encoded}\"\n",
    "        \n",
    "    \n",
    "    def check_syntax(self, plantuml_code: str, timeout: int = 5) -> PlantUMLResult:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax with detailed error extraction.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML code to validate\n",
    "            timeout: Request timeout in seconds\n",
    "            \n",
    "        Returns:\n",
    "            PlantUMLResult with validation status and detailed error if applicable.\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating PlantUML syntax\")\n",
    "        \n",
    "        try:\n",
    "            diagram_code = self.extract_plantuml(plantuml_code)\n",
    "            encoded = self._encode_plantuml(diagram_code)\n",
    "            \n",
    "            url_png = f\"{self.host}/png/{encoded}\"\n",
    "            response = requests.get(url_png, timeout=timeout)\n",
    "            \n",
    "            if response.status_code == 200 and response.content[:4] == b'\\x89PNG':\n",
    "                logger.info(\"Syntax validation passed (PNG rendered)\")\n",
    "                return PlantUMLResult(\n",
    "                    is_valid=True,\n",
    "                    url=url_png,\n",
    "                    svg_url=f\"{self.host}/svg/{encoded}\"\n",
    "                )\n",
    "            \n",
    "            logger.warning(\"PNG rendering failed. Fetching detailed syntax error...\")\n",
    "            url_txt = f\"{self.host}/txt/{encoded}\"\n",
    "            error_response = requests.get(url_txt, timeout=timeout)\n",
    "            \n",
    "            detailed_error = error_response.text.strip() if error_response.status_code == 200 else \"Unknown server error\"\n",
    "            \n",
    "            error_msg = f\"PlantUML Syntax Error:\\n{detailed_error[:1000]}\"\n",
    "            logger.error(f\"Syntax error detected: {error_msg}\")\n",
    "            \n",
    "            return PlantUMLResult(\n",
    "                is_valid=False,\n",
    "                error=error_msg\n",
    "            )\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"PlantUML Server Connection Error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected error during syntax check: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d633d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Manages long-term memory for UML diagram generation.\n",
    "    \n",
    "    Supports semantic search to find similar past solutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedder: SentenceTransformer,\n",
    "        store: Optional[InMemoryStore] = None,\n",
    "        shots_json_path: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize memory manager.\n",
    "        \n",
    "        Args:\n",
    "            embedder: SentenceTransformer model for semantic search\n",
    "            store: Optional InMemoryStore instance (creates new if None)\n",
    "        \"\"\"\n",
    "        self.embedder = embedder\n",
    "        self._count = 0  # Track number of stored diagrams\n",
    "        \n",
    "        # Create embedding function wrapper for InMemoryStore\n",
    "        def embed_func(texts: List[str]) -> List[List[float]]:\n",
    "            embeddings = self.embedder.encode(texts, convert_to_tensor=False)\n",
    "            return embeddings.tolist()\n",
    "        \n",
    "        # Initialize store with embedding function\n",
    "        self.store = store or InMemoryStore(\n",
    "            index={\n",
    "                \"embed\": embed_func,\n",
    "                \"dims\": 384  # all-MiniLM-L6-v2 embedding dimensions\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        logger.info(\"MemoryManager initialized with InMemoryStore\")\n",
    "\n",
    "        if shots_json_path:\n",
    "            self._load_initial_shots(shots_json_path)\n",
    "    \n",
    "\n",
    "    def _load_initial_shots(self, json_path: str):\n",
    "        \"\"\"Internal method to load static examples into the memory store.\"\"\"\n",
    "        if not os.path.exists(json_path):\n",
    "            logger.warning(f\"Shots file not found at '{json_path}'.\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                shots = json.load(f)\n",
    "            \n",
    "            for shot in shots:\n",
    "                metadata = {\n",
    "                    \"plan\": shot.get(\"subgoal_decomposition\"),\n",
    "                    \"reasoning\": shot.get(\"chain_of_thought\"),\n",
    "                    \"is_static\": True,\n",
    "                    \"title\": shot.get(\"title\")\n",
    "                }\n",
    "                self.save_diagram(\n",
    "                    requirements=shot[\"requirements\"],\n",
    "                    diagram=shot[\"solution_plantuml\"],\n",
    "                    metadata=metadata\n",
    "                )\n",
    "            logger.info(f\"âœ“ Pre-loaded {len(shots)} static shots into MemoryManager\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load initial shots: {e}\")\n",
    "\n",
    "    def save_diagram(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        diagram: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Save a validated diagram to long-term memory.\n",
    "                \n",
    "        Args:\n",
    "            requirements: Original requirements text\n",
    "            diagram: PlantUML diagram code\n",
    "            metadata: Optional metadata (iterations, validation status, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Key of the stored memory\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        key = f\"diagram_{timestamp}\"\n",
    "        \n",
    "        memory_data = {\n",
    "            \"requirements\": requirements,\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        \n",
    "\n",
    "        self.store.put(\n",
    "            namespace=(\"uml_memory\", \"validated\"),\n",
    "            key=key,\n",
    "            value=memory_data\n",
    "        )\n",
    "        \n",
    "        self._count += 1\n",
    "        logger.info(f\"Diagram saved to long-term memory: {key}\")\n",
    "        return key\n",
    "    \n",
    "    def retrieve_similar_diagrams(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        limit: int = 2\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve similar diagrams from long-term memory.\n",
    "        \n",
    "        Args:\n",
    "            requirements: Requirements to search for\n",
    "            limit: Maximum number of results\n",
    "            \n",
    "        Returns:\n",
    "            List of similar diagram memories\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self._count == 0:\n",
    "                logger.info(\"No diagrams in memory yet\")\n",
    "                return []\n",
    "            \n",
    "            results = self.store.search(\n",
    "                (\"uml_memory\", \"validated\"),\n",
    "                query=requirements,\n",
    "                limit=limit\n",
    "            )\n",
    "            \n",
    "            diagrams = [item.value for item in results]\n",
    "            logger.info(f\"Retrieved {len(diagrams)} similar diagrams from memory\")\n",
    "            return diagrams\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Memory retrieval failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        \"\"\"\n",
    "        Clear all memories from the store.\n",
    "        \n",
    "        WARNING: This is irreversible!\n",
    "        \"\"\"\n",
    "        logger.warning(\"Clearing all memories from long-term storage\")\n",
    "        def embed_func(texts: List[str]) -> List[List[float]]:\n",
    "            embeddings = self.embedder.encode(texts, convert_to_tensor=False)\n",
    "            return embeddings.tolist()\n",
    "        \n",
    "        self.store = InMemoryStore(\n",
    "            index={\n",
    "                \"embed\": embed_func,\n",
    "                \"dims\": 384\n",
    "            }\n",
    "        )\n",
    "        self._count = 0\n",
    "        logger.info(\"Memory cleared\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMLNodes:\n",
    "    \"\"\"\n",
    "    Collection of agent nodes for the UML generation workflow.\n",
    "    \n",
    "    Each method represents a node in the LangGraph workflow and\n",
    "    follows the pattern of taking AgentState and returning a dict\n",
    "    with state updates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: ChatOpenAI,\n",
    "        plantuml_tool: PlantUMLTool,\n",
    "        memory_manager: Optional['MemoryManager'] = None,\n",
    "        config: Optional[SystemConfig] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize UML nodes with required dependencies.\n",
    "        \n",
    "        Args:\n",
    "            llm: LangChain ChatOpenAI instance\n",
    "            plantuml_tool: Tool for PlantUML validation\n",
    "            memory_manager: long-term memory manager\n",
    "            config: Optional system configuration\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.plantuml_tool = plantuml_tool\n",
    "        self.memory_manager = memory_manager\n",
    "        self.config = config or SystemConfig()\n",
    "        logger.info(\"UMLNodes initialized\")\n",
    "\n",
    "    def _safe_invoke(self, runnable: Any, input_data: Any, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Invoke a runnable (LLM or chain) with retry logic.\n",
    "        \"\"\"\n",
    "        max_retries = 3\n",
    "        last_exception = None\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return runnable.invoke(input_data, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logger.warning(f\"LLM call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 * (attempt + 1))\n",
    "        \n",
    "        logger.error(f\"Max retries reached for LLM call: {last_exception}\")\n",
    "        raise last_exception\n",
    "\n",
    "    def retrieve(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant few-shot examples based on requirements.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'examples' key containing formatted shots\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.RETRIEVE.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            memories = self.memory_manager.retrieve_similar_diagrams(\n",
    "                state[\"requirements\"],\n",
    "                limit=self.config.num_few_shots\n",
    "            )\n",
    "            \n",
    "            formatted_shots = []\n",
    "            for mem in memories:\n",
    "                formatted_shots.append(\n",
    "                    HumanMessage(content=f\"Requirements:\\n{mem['requirements']}\")\n",
    "                )\n",
    "                \n",
    "                meta = mem.get(\"metadata\", {})\n",
    "                plan = meta.get(\"plan\", \"No plan available.\")\n",
    "                reasoning = meta.get(\"reasoning\", \"No reasoning available.\")\n",
    "                \n",
    "                assistant_content = (\n",
    "                    f\"1. DESIGN PLAN:\\n{plan}\\n\\n\"\n",
    "                    f\"2. DESIGN REASONING:\\n{reasoning}\\n\\n\"\n",
    "                    f\"3. PLANTUML DIAGRAM:\\n```plantuml\\n{mem['diagram']}\\n```\"\n",
    "                )\n",
    "                \n",
    "                formatted_shots.append(\n",
    "                    AIMessage(content=assistant_content)\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"Retrieved {len(memories)} relevant examples from unified memory\")\n",
    "            return {\"examples\": formatted_shots}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Retrieval failed: {e}\")\n",
    "            return {\"examples\": []}\n",
    "\n",
    "    def decompose(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Decompose requirements into structural building blocks.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'plan' key containing decomposition\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.DECOMPOSE.upper()} ---\")\n",
    "\n",
    "        feedback = state.get(\"audit_feedback\", [])\n",
    "        feedback_str = \"\\n\".join([f\"- {f}\" for f in feedback]) if feedback else \"None\"\n",
    "\n",
    "        system_prompt = PromptConstants.DECOMPOSER_SYSTEM\n",
    "        if feedback:\n",
    "            system_prompt += f\"\\n\\nIMPORTANT: Your previous plan was rejected. Fix these issues:\\n{feedback_str}\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"REQUIREMENTS:\\n{state['requirements']}\")\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_decompose\n",
    "            )\n",
    "            logger.info(\"Decomposition completed\")\n",
    "            return {\"plan\": response.content}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Decomposition failed: {e}\")\n",
    "            return {\"plan\": f\"Error: {str(e)}\"}\n",
    "\n",
    "    def logic_auditor(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Audits the structural plan for logical consistency and requirement coverage.\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.PLAN_AUDIT.upper()} ---\")\n",
    "        \n",
    "        plan = state.get(\"plan\")\n",
    "        requirements = state.get(\"requirements\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Senior Software Architect auditing a UML Class Diagram plan.\n",
    "        \n",
    "        REQUIREMENTS:\n",
    "        {requirements}\n",
    "        \n",
    "        PROPOSED PLAN (JSON):\n",
    "        {plan}\n",
    "        \n",
    "        YOUR TASK:\n",
    "        1. Check for 'Island Classes' (classes with no relationships).\n",
    "        2. Ensure all entities mentioned in the requirements exist in the plan.\n",
    "        3. Check for relationship directionality (e.g., should 'User' own 'Order'?).\n",
    "        4. Verify that attributes have appropriate types.\n",
    "        \n",
    "        If the plan is flawed, be specific about what is missing.\n",
    "        \"\"\"\n",
    "        \n",
    "        audit_result = self.llm.with_structured_output(PlanAudit).invoke([\n",
    "            SystemMessage(content=\"You are a Senior Software Architect auditing a UML Class Diagram plan.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"plan_valid\": audit_result.is_valid,\n",
    "            \"audit_feedback\": audit_result.critique + audit_result.suggestions,\n",
    "            \"iterations\": state[\"iterations\"] + (0 if audit_result.is_valid else 1)\n",
    "        }\n",
    "\n",
    "    def generate(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate PlantUML diagram using chain-of-thought reasoning.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.GENERATE.upper()} ---\")\n",
    "        \n",
    "        messages = [SystemMessage(content=PromptConstants.GENERATOR_SYSTEM)]\n",
    "        \n",
    "        # Add few-shot examples if available\n",
    "        if state.get(\"examples\"):\n",
    "            messages.extend(state[\"examples\"])\n",
    "            logger.debug(f\"Added {len(state['examples'])} example messages\")\n",
    "            \n",
    "        user_content = f\"\"\"\n",
    "        # ORIGINAL REQUIREMENTS\n",
    "        {state['requirements']}\n",
    "\n",
    "        # DESIGN PLAN\n",
    "        {state['plan']}\n",
    "\n",
    "        # TASK\n",
    "        Follow the examples above exactly. Output your response in three parts:\n",
    "        1. DESIGN PLAN: (Briefly refine the plan for implementation)\n",
    "        2. DESIGN REASONING: (Explain your choice of relationships and cardinality)\n",
    "        3. PLANTUML DIAGRAM: (The code block)\n",
    "        \"\"\"\n",
    "        \n",
    "        messages.append(HumanMessage(content=user_content))\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_generate\n",
    "            )\n",
    "            diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "            \n",
    "            logger.info(f\"Generation completed (iteration {state['iterations'] + 1})\")\n",
    "            return {\n",
    "                \"current_diagram\": diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": f\"Error: {str(e)}\",\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "    def syntax_check(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax through server.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'syntax_valid' and optional 'error_message'\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SYNTAX_CHECK.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            result = self.plantuml_tool.check_syntax(\n",
    "                state[\"current_diagram\"],\n",
    "                timeout=self.config.request_timeout\n",
    "            )\n",
    "            \n",
    "            if result.is_valid:\n",
    "                logger.info(f\"Syntax valid. View at: {result.url}\")\n",
    "            else:\n",
    "                logger.warning(f\"Syntax error: {result.error}\")\n",
    "            \n",
    "            return {\n",
    "                \"syntax_valid\": result.is_valid,\n",
    "                \"error_message\": result.error if not result.is_valid else None,\n",
    "                \"iterations\": state[\"iterations\"] + (0 if result.is_valid else 1)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Syntax check failed: {e}\")\n",
    "            return {\n",
    "                \"syntax_valid\": False,\n",
    "                \"error_message\": f\"Syntax check error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def _validate_diagram(self, requirements: str, diagram: str) -> CritiqueResponse:\n",
    "        \"\"\"\n",
    "        Helper method to validate a diagram and return the structured response.\n",
    "        Used by both critic node and reflect node (for rollback decision).\n",
    "        \"\"\"\n",
    "        plantuml_only = self.plantuml_tool.extract_plantuml(diagram)\n",
    "        user_msg = f\"\"\"\n",
    "        # REQUIREMENTS\n",
    "        {requirements}\n",
    "\n",
    "        # DIAGRAM\n",
    "        {plantuml_only}\n",
    "\n",
    "        Audit the diagram thoroughly and provide the scoring report.\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=PromptConstants.CRITIC_SYSTEM),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "        \n",
    "        structured_llm = self.llm.with_structured_output(CritiqueResponse)\n",
    "        return self._safe_invoke(structured_llm, messages)\n",
    "\n",
    "    def critic(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform logical validation of the UML diagram.\n",
    "                \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'logic_valid' and 'history' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.CRITIC.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            critique_response = self._validate_diagram(state['requirements'], state[\"current_diagram\"])\n",
    "            \n",
    "            weighted = critique_response.weighted_score\n",
    "            \n",
    "            critique = {\n",
    "                \"is_valid\": critique_response.is_valid,\n",
    "                \"requirement_coverage\": critique_response.requirement_coverage,\n",
    "                \"design_best_practices\": critique_response.design_best_practices,\n",
    "                \"structural_integrity\": critique_response.structural_integrity,\n",
    "                \"weighted_score\": weighted,\n",
    "                \"errors\": [{\"type\": err.type, \"description\": err.description} \n",
    "                          for err in critique_response.errors],\n",
    "                \"warnings\": critique_response.warnings,\n",
    "                \"missing_concepts\": critique_response.missing_concepts,\n",
    "                \"reasoning\": critique_response.reasoning\n",
    "            }\n",
    "            \n",
    "            is_valid = critique_response.is_valid\n",
    "            logger.info(f\"Logic validation: {'PASSED' if is_valid else 'FAILED'} (Weighted Score: {weighted:.2f})\")\n",
    "            logger.info(f\"  Requirements Coverage: {critique_response.requirement_coverage:.2f}/10\")\n",
    "            logger.info(f\"  Design Best Practices: {critique_response.design_best_practices:.2f}/10\")\n",
    "            logger.info(f\"  Structural Integrity: {critique_response.structural_integrity:.2f}/10\")\n",
    "            \n",
    "            if not is_valid and critique_response.errors:\n",
    "                logger.info(f\"Found {len(critique_response.errors)} errors\")\n",
    "            \n",
    "            updates = {\n",
    "                \"logic_valid\": is_valid,\n",
    "                \"history\": [critique]  + state.get(\"history\", []),\n",
    "                \"current_validation\": critique_response\n",
    "            }\n",
    "            \n",
    "            if is_valid and not state.get(\"best_diagram\"):\n",
    "                logger.info(f\"Storing first valid diagram as best\")\n",
    "                updates[\"best_diagram\"] = state[\"current_diagram\"]\n",
    "            \n",
    "            return updates\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critic failed: {e}\")\n",
    "            return {\n",
    "                \"logic_valid\": False,\n",
    "                \"history\": [{\n",
    "                    \"is_valid\": False,\n",
    "                    \"requirement_coverage\": 0.0,\n",
    "                    \"design_best_practices\": 0.0,\n",
    "                    \"structural_integrity\": 0.0,\n",
    "                    \"weighted_score\": 0.0,\n",
    "                    \"errors\": [{\"type\": \"system\", \"description\": str(e)}],\n",
    "                    \"warnings\": [],\n",
    "                    \"missing_concepts\": [],\n",
    "                    \"reasoning\": \"System error during critique.\"\n",
    "                }]\n",
    "            }\n",
    "\n",
    "    def summarize_memory(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Summarize progress by comparing current and previous critiques.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'summary' key containing JSON string\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SUMMARIZE.upper()} ---\")\n",
    "        \n",
    "        if not state.get(\"history\"):\n",
    "            logger.info(\"No history to summarize\")\n",
    "            return {\"summary\": json.dumps({\"is_complete\": False, \"message\": \"No history\"})}\n",
    "        \n",
    "        current_critique = state[\"history\"][-1]\n",
    "        \n",
    "        # Only look at the last 2 previous critiques to save tokens\n",
    "        # sending the full history causes context overflow in later iterations\n",
    "        previous_critiques = state[\"history\"][-3:-1] if len(state[\"history\"]) > 1 else []\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        CURRENT CRITIQUE (Issues in the latest diagram):\n",
    "        {json.dumps(current_critique)}\n",
    "        \n",
    "        PREVIOUS CRITIQUES (Recent history):\n",
    "        {json.dumps(previous_critiques)}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=PromptConstants.SUMMARIZER_SYSTEM),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            structured_llm = self.llm.with_structured_output(SummaryResponse)\n",
    "            summary_response: SummaryResponse = self._safe_invoke(structured_llm, messages)\n",
    "            \n",
    "            summary = {\n",
    "                \"is_complete\": summary_response.is_complete,\n",
    "                \"fixed\": summary_response.fixed,\n",
    "                \"unresolved\": summary_response.unresolved,\n",
    "                \"message\": summary_response.message\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Summary: {summary_response.message}\")\n",
    "            return {\"summary\": json.dumps(summary)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Summarization failed: {e}\")\n",
    "            return {\"summary\": json.dumps({\n",
    "                \"is_complete\": False,\n",
    "                \"fixed\": [],\n",
    "                \"unresolved\": [],\n",
    "                \"message\": f\"Error: {str(e)}\"\n",
    "            })}\n",
    "\n",
    "    def reflect(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fix diagram based on memory summary and error history.\n",
    "        Implements internal retry loop with dynamic temperature to escape local optima.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.REFLECT.upper()} ---\")\n",
    "\n",
    "        last_critique = state[\"history\"][-1]\n",
    "        prev_score = last_critique.get(\"weighted_score\", 0)\n",
    "        old_diagram = state['current_diagram']\n",
    "        \n",
    "        if prev_score < 6.0:\n",
    "            tone_instruction = \"The current diagram is fundamentally flawed. Re-evaluate the core entities.\"\n",
    "        else:\n",
    "            tone_instruction = \"The diagram is nearly correct. Focus ONLY on the specific errors listed below.\"\n",
    "\n",
    "        summary_json = json.loads(state[\"summary\"])\n",
    "        summary_text = (\n",
    "            f\"Message: {summary_json.get('message', '')}\\n\"\n",
    "            f\"Unresolved Issues: {', '.join(summary_json.get('unresolved', []))}\"\n",
    "        )\n",
    "\n",
    "        base_user_msg = f\"\"\"\n",
    "        {tone_instruction}\n",
    "        \n",
    "        [QUALITY SCORE]: {prev_score}/10\n",
    "        [ERRORS TO FIX]:\n",
    "        {summary_text}\n",
    "        \n",
    "        [MISSING CONCEPTS]: {last_critique.get('missing_concepts', [])}\n",
    "        \n",
    "        [CURRENT CODE]:\n",
    "        {old_diagram}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=PromptConstants.REFLECTOR_SYSTEM),\n",
    "            HumanMessage(content=base_user_msg)\n",
    "        ]\n",
    "\n",
    "        \n",
    "        max_retries = 2 \n",
    "        current_temp = self.config.temperature_reflect\n",
    "        \n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                logger.info(f\"Reflection attempt {attempt+1}/{max_retries+1} (temp={current_temp:.2f})\")\n",
    "                \n",
    "                llm_reflect = create_llm(self.config, temperature=current_temp)\n",
    "                \n",
    "                response = self._safe_invoke(\n",
    "                    llm_reflect,\n",
    "                    messages,\n",
    "                    max_tokens=self.config.max_tokens_reflect\n",
    "                )\n",
    "                new_diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "\n",
    "\n",
    "                if new_diagram.strip() == old_diagram.strip():\n",
    "                    logger.warning(\"Generated identical diagram.\")\n",
    "                    if attempt < max_retries:\n",
    "                        messages.append(HumanMessage(content=\"You returned the exact same diagram. You MUST change it to fix the errors. Try again.\"))\n",
    "                        current_temp = min(1.0, current_temp + 0.2)\n",
    "                        continue\n",
    "                    else:\n",
    "                        break \n",
    "\n",
    "                new_validation = self._validate_diagram(state['requirements'], new_diagram)\n",
    "                new_score = new_validation.weighted_score\n",
    "                \n",
    "                logger.info(f\"Attempt {attempt+1} Score: {new_score:.2f} (Previous: {prev_score:.2f})\")\n",
    "\n",
    "                if new_score >= prev_score:\n",
    "                    logger.info(f\"Improvement found! ({new_score:.2f} >= {prev_score:.2f})\")\n",
    "                    return {\n",
    "                        \"current_diagram\": new_diagram,\n",
    "                        \"iterations\": state[\"iterations\"] + 1,\n",
    "                    }\n",
    "                \n",
    "\n",
    "                logger.warning(f\"Score dropped to {new_score:.2f}. Retrying...\")\n",
    "                \n",
    "                if attempt < max_retries:\n",
    "                    messages.append(HumanMessage(content=f\"\"\"\n",
    "                    Your previous attempt resulted in a LOWER score ({new_score:.2f} < {prev_score:.2f}).\n",
    "                    The changes you made introduced new issues.\n",
    "                    Undo those bad changes and try a different approach to fix the original errors.\n",
    "                    \"\"\"))\n",
    "                    current_temp = min(1.0, current_temp + 0.1)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Reflection attempt {attempt+1} failed: {e}\")\n",
    "        \n",
    "        logger.warning(\"All reflection attempts failed to improve score. Rolling back to old diagram.\")\n",
    "        \n",
    "\n",
    "        recent_history = state.get(\"history\", [])[-3:]\n",
    "        if len(recent_history) >= 2:\n",
    "             last_scores = [h.get(\"weighted_score\", 0) for h in recent_history[-2:]]\n",
    "             if len(set(last_scores)) == 1:\n",
    "                 logger.warning(\"Score plateau detected. Stopping.\")\n",
    "                 return {\n",
    "                     \"current_diagram\": old_diagram,\n",
    "                     \"iterations\": self.config.max_iterations \n",
    "                 }\n",
    "\n",
    "        return {\n",
    "            \"current_diagram\": old_diagram,\n",
    "            \"iterations\": state[\"iterations\"] + 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12124ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uml_graph(\n",
    "    nodes: UMLNodes, \n",
    "    config: Optional[SystemConfig] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Create the LangGraph workflow for UML diagram generation.\n",
    "    \n",
    "    Args:\n",
    "        nodes: UMLNodes instance with all agent methods\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Compiled LangGraph workflow\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"Creating UML generation workflow\")\n",
    "    \n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(NodeNames.RETRIEVE, nodes.retrieve)\n",
    "    workflow.add_node(NodeNames.PLAN_AUDIT, nodes.logic_auditor)\n",
    "    workflow.add_node(NodeNames.DECOMPOSE, nodes.decompose)\n",
    "    workflow.add_node(NodeNames.GENERATE, nodes.generate)\n",
    "    workflow.add_node(NodeNames.SYNTAX_CHECK, nodes.syntax_check)\n",
    "    workflow.add_node(NodeNames.CRITIC, nodes.critic)\n",
    "    workflow.add_node(NodeNames.SUMMARIZE, nodes.summarize_memory)\n",
    "    workflow.add_node(NodeNames.REFLECT, nodes.reflect)\n",
    "    \n",
    "    logger.debug(\"Added 7 nodes to workflow\")\n",
    "\n",
    "    # Define edges\n",
    "    workflow.add_edge(START, NodeNames.RETRIEVE)\n",
    "    workflow.add_edge(NodeNames.RETRIEVE, NodeNames.DECOMPOSE)\n",
    "    workflow.add_edge(NodeNames.DECOMPOSE, NodeNames.PLAN_AUDIT)\n",
    "\n",
    "    def route_after_plan_audit(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on plan audit results.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"plan_valid\"]:\n",
    "            logger.debug(\"Routing: plan_audit -> generate\")\n",
    "            return NodeNames.GENERATE\n",
    "            \n",
    "        logger.debug(\"Routing: plan_audit -> decompose\")\n",
    "        return NodeNames.DECOMPOSE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.PLAN_AUDIT, \n",
    "        route_after_plan_audit,\n",
    "        {\n",
    "            NodeNames.DECOMPOSE: NodeNames.DECOMPOSE,\n",
    "            NodeNames.GENERATE: NodeNames.GENERATE\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(NodeNames.GENERATE, NodeNames.SYNTAX_CHECK)\n",
    "\n",
    "    def route_after_syntax_check(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on syntax validation results and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"syntax_valid\"]:\n",
    "            logger.debug(\"Routing: syntax_check -> critic\")\n",
    "            return NodeNames.CRITIC\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached during syntax check\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: syntax_check -> reflect\")\n",
    "        return NodeNames.REFLECT\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.SYNTAX_CHECK, \n",
    "        route_after_syntax_check,\n",
    "        {\n",
    "            NodeNames.CRITIC: NodeNames.CRITIC,\n",
    "            NodeNames.REFLECT: NodeNames.REFLECT,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def is_logic_valid(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on logic validation and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name or END\n",
    "        \"\"\"\n",
    "        if state[\"logic_valid\"]:\n",
    "            logger.info(\"Diagram validated successfully\")\n",
    "            return END\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: critic -> summarize\")\n",
    "        return NodeNames.SUMMARIZE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.CRITIC, \n",
    "        is_logic_valid,\n",
    "        {\n",
    "            END: END,\n",
    "            NodeNames.SUMMARIZE: NodeNames.SUMMARIZE\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(NodeNames.SUMMARIZE, NodeNames.REFLECT)\n",
    "    workflow.add_edge(NodeNames.REFLECT, NodeNames.SYNTAX_CHECK)\n",
    "    \n",
    "    logger.info(\"Workflow graph created successfully\")\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def create_initial_state(requirements: str) -> AgentState:\n",
    "    \"\"\"\n",
    "    Create an initial state for the workflow.\n",
    "    \n",
    "    Args:\n",
    "        requirements: Software requirements text\n",
    "        \n",
    "    Returns:\n",
    "        Initial AgentState dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"requirements\": requirements,\n",
    "        \"plan\": None,\n",
    "        \"examples\": [],\n",
    "        \"current_diagram\": None,\n",
    "        \"best_diagram\": None,\n",
    "        \"history\": [],\n",
    "        \"summary\": None,\n",
    "        \"syntax_valid\": False,\n",
    "        \"logic_valid\": False,\n",
    "        \"iterations\": 0,\n",
    "        \"error_message\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "549e0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:35:51,001 - __main__ - INFO - Loading test exercises from ./../data/test_exercises.json\n",
      "2026-01-04 22:35:51,007 - __main__ - INFO - Loaded 8 test exercises\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 test exercises\n"
     ]
    }
   ],
   "source": [
    "def load_test_exercises(json_path: str = \"./../data/test_exercises.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load test exercises from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to test exercises JSON\n",
    "        \n",
    "    Returns:\n",
    "        List of exercise dictionaries\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        json.JSONDecodeError: If JSON is invalid\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading test exercises from {json_path}\")\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Test exercises file not found: {json_path}\")\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        exercises = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Loaded {len(exercises)} test exercises\")\n",
    "    return exercises\n",
    "\n",
    "try:\n",
    "    test_exercises = load_test_exercises()\n",
    "    print(f\"Loaded {len(test_exercises)} test exercises\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load test exercises: {e}\")\n",
    "    test_exercises = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53188a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:35:51,016 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:35:51,017 - __main__ - INFO - INITIALIZING UML GENERATION SYSTEM\n",
      "2026-01-04 22:35:51,017 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:35:51,017 - __main__ - INFO - Creating LLM connection...\n",
      "2026-01-04 22:35:51,018 - __main__ - INFO - Connecting to LMStudio at http://localhost:1234/v1\n",
      "2026-01-04 22:35:51,019 - __main__ - INFO - Using model: mistralai/devstral-small-2-2512 (temp=0.15)\n",
      "2026-01-04 22:35:51,032 - __main__ - INFO - Initializing PlantUML tool...\n",
      "2026-01-04 22:35:51,032 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n",
      "2026-01-04 22:35:51,032 - __main__ - INFO - Initializing long-term memory...\n",
      "2026-01-04 22:35:51,049 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2026-01-04 22:35:51,049 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2026-01-04 22:35:51,366 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:51,406 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:51,565 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:51,624 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:51,785 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:51,822 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:51,998 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:52,037 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:52,202 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:52,239 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:52,410 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:52,458 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:52,629 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-04 22:35:52,790 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:52,831 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2612.61it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "2026-01-04 22:35:53,199 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:53,240 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:53,403 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-04 22:35:53,569 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:54,004 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-04 22:35:54,049 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:54,221 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:35:55,719 - __main__ - INFO - MemoryManager initialized with InMemoryStore\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.75it/s]\n",
      "2026-01-04 22:35:55,915 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.721053\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 100.75it/s]\n",
      "2026-01-04 22:35:55,928 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.916047\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 92.34it/s]\n",
      "2026-01-04 22:35:55,941 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.928670\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 75.15it/s]\n",
      "2026-01-04 22:35:55,958 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.941910\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 86.72it/s]\n",
      "2026-01-04 22:35:55,971 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.958317\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 82.74it/s]\n",
      "2026-01-04 22:35:55,984 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.971262\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 99.05it/s]\n",
      "2026-01-04 22:35:55,996 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.984964\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 93.29it/s]\n",
      "2026-01-04 22:35:56,011 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:55.996308\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 82.86it/s]\n",
      "2026-01-04 22:35:56,024 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.011448\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 99.43it/s]\n",
      "2026-01-04 22:35:56,036 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.024959\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 84.03it/s]\n",
      "2026-01-04 22:35:56,050 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.037054\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 89.74it/s]\n",
      "2026-01-04 22:35:56,062 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.050411\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 87.66it/s]\n",
      "2026-01-04 22:35:56,075 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.062986\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 84.21it/s]\n",
      "2026-01-04 22:35:56,088 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.075848\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 80.14it/s]\n",
      "2026-01-04 22:35:56,102 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.089106\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 86.57it/s]\n",
      "2026-01-04 22:35:56,116 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.103132\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 84.47it/s]\n",
      "2026-01-04 22:35:56,130 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.116795\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 77.80it/s]\n",
      "2026-01-04 22:35:56,144 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.130367\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 75.73it/s]\n",
      "2026-01-04 22:35:56,159 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.144792\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 78.83it/s]\n",
      "2026-01-04 22:35:56,173 - __main__ - INFO - Diagram saved to long-term memory: diagram_2026-01-04T22:35:56.159736\n",
      "2026-01-04 22:35:56,174 - __main__ - INFO - âœ“ Pre-loaded 20 static shots into MemoryManager\n",
      "2026-01-04 22:35:56,174 - __main__ - INFO - Long-term memory enabled\n",
      "2026-01-04 22:35:56,174 - __main__ - INFO - Building LangGraph workflow...\n",
      "2026-01-04 22:35:56,174 - __main__ - INFO - UMLNodes initialized\n",
      "2026-01-04 22:35:56,174 - __main__ - INFO - Creating UML generation workflow\n",
      "2026-01-04 22:35:56,184 - __main__ - INFO - Workflow graph created successfully\n",
      "2026-01-04 22:35:56,194 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:35:56,194 - __main__ - INFO - âœ“ SYSTEM INITIALIZED SUCCESSFULLY\n",
      "2026-01-04 22:35:56,194 - __main__ - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready for diagram generation\n",
      "Long-term memory: ENABLED\n",
      "Temperature strategy: Base=0.15, Reflect=0.15\n"
     ]
    }
   ],
   "source": [
    "def initialize_system(\n",
    "    config: Optional[SystemConfig] = None,\n",
    "    enable_long_term_memory: bool = True\n",
    ") -> Tuple[UMLNodes, Any, SystemConfig, Optional[MemoryManager]]:\n",
    "    \"\"\"\n",
    "    Initialize all system components.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        enable_long_term_memory: Whether to enable long-term memory\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (nodes, compiled_workflow, config, memory_manager)\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"INITIALIZING UML GENERATION SYSTEM\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating LLM connection...\")\n",
    "        llm = create_llm(cfg)\n",
    "        \n",
    "        logger.info(\"Initializing PlantUML tool...\")\n",
    "        puml_tool = PlantUMLTool(cfg.plantuml_host)\n",
    "        \n",
    "        memory_mgr = None\n",
    "        if enable_long_term_memory:\n",
    "            logger.info(\"Initializing long-term memory...\")\n",
    "            memory_mgr = MemoryManager(\n",
    "                embedder=SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "                shots_json_path=cfg.shots_json_path  \n",
    "            )\n",
    "            logger.info(\"Long-term memory enabled\")\n",
    "        else:\n",
    "            logger.info(\"Long-term memory disabled\")\n",
    "        \n",
    "        # Build workflow\n",
    "        logger.info(\"Building LangGraph workflow...\")\n",
    "        nodes = UMLNodes(llm, puml_tool, memory_mgr, cfg)\n",
    "        app = create_uml_graph(nodes, cfg)\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"âœ“ SYSTEM INITIALIZED SUCCESSFULLY\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        return nodes, app, cfg, memory_mgr\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"System initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "config = SystemConfig(\n",
    "    max_iterations=6,\n",
    "    num_few_shots=3,\n",
    "    temperature_base=0.15,     \n",
    "    temperature_reflect=0.15    \n",
    ")\n",
    "\n",
    "nodes, app, config, memory_manager = initialize_system(config, enable_long_term_memory=True)\n",
    "print(\"\\nSystem ready for diagram generation\")\n",
    "print(f\"Long-term memory: {'ENABLED' if memory_manager else 'DISABLED'}\")\n",
    "print(f\"Temperature strategy: Base={config.temperature_base}, Reflect={config.temperature_reflect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9633429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:35:56,211 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:35:56,212 - __main__ - INFO - RUNNING: Exercise 3\n",
      "2026-01-04 22:35:56,213 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:35:56,213 - __main__ - INFO - Requirements preview: A library system manages books, members, and loans.\n",
      "Books have an ISBN, title, author, publisher, publication year, and availability status.\n",
      "Members h...\n",
      "2026-01-04 22:35:56,220 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 46.63it/s]\n",
      "2026-01-04 22:35:56,252 - __main__ - INFO - Retrieved 3 similar diagrams from memory\n",
      "2026-01-04 22:35:56,253 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-04 22:35:56,253 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-04 22:37:08,974 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:37:08,992 - __main__ - INFO - Decomposition completed\n",
      "2026-01-04 22:37:08,997 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n",
      "2026-01-04 22:37:38,855 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:37:38,894 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-04 22:39:33,060 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:39:33,089 - __main__ - INFO - Generation completed (iteration 1)\n",
      "2026-01-04 22:39:33,107 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-04 22:39:33,109 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-04 22:39:33,564 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-04 22:39:33,567 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/LLBBJiCm4BpdAomVA_N05N4e224XyP3eYQCJRnkB-A7rkX01_yvwcuRavFNip7Z7zYwJGIf-QBh1vApkOlnGturIfb0VaGkNsy1BAktWSWzugJj3BePtC1KXHmCqlvF9W-dAGECp-1PGt2maFiP38Dw0JqCS0Hxjly854EA1YriVYn2J6QjaJuPAdhbFqGJXTZrq7x7GlI6ePnIOAWGg66Hp4IrcCTOYvCoL5p3tBl4eIWNZgphrCS1BgItnEhfCA65NZc-G0K-2Yory9OVZFC7SN8dsL2md4a72U4JZNmyL71d8vwPSYxo3lj9gkrLwey-XhvLk8sBy1AjEpkX6hct3bDfkXBFGJ9bdLTRD1DtyC6NrIglEDEK5grxLafsNeTdt71FOUDbOy2K64myHLSkrRdOGB7-tFm==\n",
      "2026-01-04 22:39:33,569 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-04 22:40:12,327 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:40:12,352 - __main__ - INFO - Logic validation: FAILED (Weighted Score: 8.70)\n",
      "2026-01-04 22:40:12,352 - __main__ - INFO -   Requirements Coverage: 8.00/10\n",
      "2026-01-04 22:40:12,352 - __main__ - INFO -   Design Best Practices: 9.00/10\n",
      "2026-01-04 22:40:12,353 - __main__ - INFO -   Structural Integrity: 10.00/10\n",
      "2026-01-04 22:40:12,353 - __main__ - INFO - Found 3 errors\n",
      "2026-01-04 22:40:12,355 - __main__ - INFO - --- NODE: SUMMARIZE ---\n",
      "2026-01-04 22:40:26,809 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:40:26,824 - __main__ - INFO - Summary: The structural integrity has been fixed, but requirement coverage and design best practices still need attention.\n",
      "2026-01-04 22:40:26,826 - __main__ - INFO - --- NODE: REFLECT ---\n",
      "2026-01-04 22:40:26,827 - __main__ - INFO - Reflection attempt 1/3 (temp=0.15)\n",
      "2026-01-04 22:40:26,827 - __main__ - INFO - Connecting to LMStudio at http://localhost:1234/v1\n",
      "2026-01-04 22:40:26,828 - __main__ - INFO - Using model: mistralai/devstral-small-2-2512 (temp=0.15)\n",
      "2026-01-04 22:41:19,898 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:41:58,681 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:41:58,686 - __main__ - INFO - Attempt 1 Score: 9.65 (Previous: 8.70)\n",
      "2026-01-04 22:41:58,687 - __main__ - INFO - Improvement found! (9.65 >= 8.70)\n",
      "2026-01-04 22:41:58,688 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-04 22:41:58,689 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-04 22:41:58,781 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-04 22:41:58,782 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/NLBBJiCm4BpdAwmSA_N05N4e224XyP3eYUCctZPM_PAzBaJ0lxFUfYNXbF7ip7XtdKqcI5ISRNeBEQkx40xggr4A2WqXCJ2vy_o9fRCc3vZEk0SomRyZL8OCMQok8nWBdR66nYq1bTpyJCaFq1TBupEw3fDSeJ7otGuzyG5Tj654VDH_3kDHX3i6jouK4KOOg-LV-bC0Bzf-mFuG2jq3rOPqmGabf9Ay7CwcMI-WTSAS6JaXys0YjwAK1rVTSGWUNqejITRUP4goWKNY6sPCH-4b5Z-ZIUEbWqjnOTfIqJoH668A-mJkTLV9aObyAifQv77QgrQjrwfTjQUXhrNRXPJ21sfrDD0sihOLIsgv4StCCyrySUMscQYRRvOiNcbHcReySpMhHdBoV6ZEFOs973mlpFGo1Wjt8QcESTjiq6l-1ty1\n",
      "2026-01-04 22:41:58,784 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-04 22:42:35,419 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:42:35,429 - __main__ - INFO - Logic validation: PASSED (Weighted Score: 8.95)\n",
      "2026-01-04 22:42:35,431 - __main__ - INFO -   Requirements Coverage: 9.50/10\n",
      "2026-01-04 22:42:35,431 - __main__ - INFO -   Design Best Practices: 8.00/10\n",
      "2026-01-04 22:42:35,432 - __main__ - INFO -   Structural Integrity: 9.00/10\n",
      "2026-01-04 22:42:35,432 - __main__ - INFO - Storing first valid diagram as best\n",
      "2026-01-04 22:42:35,434 - __main__ - INFO - Diagram validated successfully\n",
      "2026-01-04 22:42:35,436 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:42:35,437 - __main__ - INFO - WORKFLOW COMPLETED\n",
      "2026-01-04 22:42:35,437 - __main__ - INFO - ============================================================\n",
      "2026-01-04 22:42:35,438 - __main__ - INFO - Iterations: 2\n",
      "2026-01-04 22:42:35,439 - __main__ - INFO - Syntax Valid: True\n",
      "2026-01-04 22:42:35,439 - __main__ - INFO - Logic Valid: True\n",
      "2026-01-04 22:42:35,443 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "Iterations: 2\n",
      "Syntax Valid: True\n",
      "Logic Valid: True\n",
      "\n",
      "Diagram URL: http://localhost:8080/png/NLBBJiCm4BpdAwmSA_N05N4e224XyP3eYUCctZPM_PAzBaJ0lxFUfYNXbF7ip7XtdKqcI5ISRNeBEQkx40xggr4A2WqXCJ2vy_o9fRCc3vZEk0SomRyZL8OCMQok8nWBdR66nYq1bTpyJCaFq1TBupEw3fDSeJ7otGuzyG5Tj654VDH_3kDHX3i6jouK4KOOg-LV-bC0Bzf-mFuG2jq3rOPqmGabf9Ay7CwcMI-WTSAS6JaXys0YjwAK1rVTSGWUNqejITRUP4goWKNY6sPCH-4b5Z-ZIUEbWqjnOTfIqJoH668A-mJkTLV9aObyAifQv77QgrQjrwfTjQUXhrNRXPJ21sfrDD0sihOLIsgv4StCCyrySUMscQYRRvOiNcbHcReySpMhHdBoV6ZEFOs973mlpFGo1Wjt8QcESTjiq6l-1ty1\n",
      "\n",
      "Generated Diagram:\n",
      "@startuml\n",
      "class Book {\n",
      "  author\n",
      "  isbn\n",
      "  publisher\n",
      "  publicationYear\n",
      "  title\n",
      "  availabilityStatus\n",
      "}\n",
      "class FacultyMember {\n",
      "  department\n",
      "  employeeId\n",
      "}\n",
      "class Fine {\n",
      "  fineAmount\n",
      "  paymentStatus\n",
      "}\n",
      "class Loan {\n",
      "  checkoutDate\n",
      "  dueDate\n",
      "  returnDate\n",
      "}\n",
      "class Member {\n",
      "  address\n",
      "  membershipId\n",
      "  name\n",
      "  phoneNumber\n",
      "  registrationDate\n",
      "}\n",
      "class Reservation {\n",
      "  expiryDate\n",
      "  reservationDate\n",
      "}\n",
      "class Student {\n",
      "  programOfStudy\n",
      "  studentId\n",
      "}\n",
      "Book \"1\" -- \"*\" Loan : \"borrowed via\"\n",
      "Fine *-- Loan\n",
      "Loan \"1\" -- \"*\" Member : \"borrows\"\n",
      "Member <|-- FacultyMember\n",
      "Member <|-- Student\n",
      "Member \"*\" -- \"1\" Reservation : \"reserves\"\n",
      "Reservation \"*\" -- \"1\" Book : \"for book\"\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "def run_single_test(\n",
    "    app: Any,\n",
    "    requirements: str,\n",
    "    exercise_name: str = \"Test Exercise\"\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    Run the workflow on a single exercise.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        requirements: Software requirements text\n",
    "        exercise_name: Name for logging purposes\n",
    "        \n",
    "    Returns:\n",
    "        Final workflow state\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"RUNNING: {exercise_name}\")\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"Requirements preview: {requirements[:150]}...\")\n",
    "    \n",
    "    initial_state = create_initial_state(requirements)\n",
    "    \n",
    "    try:\n",
    "        final_output = app.invoke(initial_state, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"WORKFLOW COMPLETED\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Iterations: {final_output['iterations']}\")\n",
    "        logger.info(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "        logger.info(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "        \n",
    "        if final_output.get('best_diagram') and not final_output['logic_valid']:\n",
    "            if final_output['best_diagram'] != final_output['current_diagram']:\n",
    "                logger.info(\"Using BEST diagram instead of final (prevented regression)\")\n",
    "                final_output['current_diagram'] = final_output['best_diagram']\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Workflow execution failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Select and run a test exercise\n",
    "test_idx = 2\n",
    "requirements = test_exercises[test_idx][\"requirements\"]\n",
    "\n",
    "final_output = run_single_test(\n",
    "    app, \n",
    "    requirements, \n",
    "    f\"Exercise {test_idx + 1}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Iterations: {final_output['iterations']}\")\n",
    "print(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "print(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "\n",
    "if final_output['current_diagram']:\n",
    "    puml_tool = PlantUMLTool(config.plantuml_host)\n",
    "    diagram_url = puml_tool.get_diagram_url(final_output['current_diagram'])\n",
    "    print(f\"\\nDiagram URL: {diagram_url}\")\n",
    "    \n",
    "    print(\"\\nGenerated Diagram:\")\n",
    "    print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"P={self.precision:.2f}, R={self.recall:.2f}, F1={self.f1:.2f}\"\n",
    "\n",
    "\n",
    "class PlantUMLParser:\n",
    "    \"\"\"\n",
    "    Parser for extracting structured information from PlantUML diagrams.\n",
    "    \n",
    "    Extracts classes, attributes, and relationships from PlantUML code\n",
    "    for evaluation purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plantuml_code: str):\n",
    "        \"\"\"\n",
    "        Initialize parser with PlantUML code.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "        \"\"\"\n",
    "        self.plantuml_code = plantuml_code\n",
    "        self.classes: Dict[str, Dict[str, List[str]]] = {}\n",
    "        self.relationships: List[Dict[str, Any]] = []\n",
    "        self.parse()\n",
    "    \n",
    "    def parse(self) -> None:\n",
    "        \"\"\"Parse the PlantUML code.\"\"\"\n",
    "        try:\n",
    "            self._extract_classes()\n",
    "            self._extract_relationships()\n",
    "            logger.debug(f\"Parsed {len(self.classes)} classes and {len(self.relationships)} relationships\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Parsing failed: {e}\")\n",
    "    \n",
    "    def _extract_classes(self) -> None:\n",
    "        \"\"\"Extract class definitions and their attributes.\"\"\"\n",
    "        class_pattern = r'class\\s+(\\w+)\\s*\\{([^}]*)\\}'\n",
    "        matches = re.finditer(class_pattern, self.plantuml_code, re.MULTILINE | re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            class_name = match.group(1)\n",
    "            class_body = match.group(2)\n",
    "            \n",
    "            attributes = []\n",
    "            for line in class_body.strip().split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('--'):\n",
    "                    attributes.append(line)\n",
    "            \n",
    "            self.classes[class_name] = {'attributes': attributes}\n",
    "    \n",
    "    def _extract_relationships(self) -> None:\n",
    "        \"\"\"Extract relationships between classes.\"\"\"\n",
    "        patterns = {\n",
    "            'generalization': r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<\\|--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)',\n",
    "            'composition': r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*\\*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)',\n",
    "            'aggregation': r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*o--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)',\n",
    "            'association': r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*-->\\s*(?:\"([^\"]*)\")?\\s*(\\w+)',\n",
    "        }\n",
    "        \n",
    "        for rel_type, pattern in patterns.items():\n",
    "            for match in re.finditer(pattern, self.plantuml_code):\n",
    "                self.relationships.append({\n",
    "                    'type': rel_type,\n",
    "                    'source': match.group(1),\n",
    "                    'target': match.group(4),\n",
    "                    'cardinality_source': match.group(2),\n",
    "                    'cardinality_target': match.group(3)\n",
    "                })\n",
    "\n",
    "\n",
    "class DiagramEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for comparing generated diagrams against gold standards.\n",
    "    \n",
    "    Computes precision, recall, and F1 scores for classes, attributes,\n",
    "    and relationships.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gold_plantuml: str, pred_plantuml: str):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with gold and predicted diagrams.\n",
    "        \n",
    "        Args:\n",
    "            gold_plantuml: Gold standard PlantUML code\n",
    "            pred_plantuml: Predicted PlantUML code\n",
    "        \"\"\"\n",
    "        self.gold_parser = PlantUMLParser(gold_plantuml)\n",
    "        self.pred_parser = PlantUMLParser(pred_plantuml)\n",
    "    \n",
    "    def _normalize_attr(self, attr_str: str) -> str:\n",
    "        \"\"\"Normalize attribute strings for comparison.\"\"\"\n",
    "        return attr_str.split(':')[0].strip().lower()\n",
    "    \n",
    "    def _normalize_rel_type(self, rel_type: str) -> str:\n",
    "        \"\"\"Normalize relationship types.\"\"\"\n",
    "        mapping = {\n",
    "            '<|--': 'INHERITANCE',\n",
    "            '*--': 'COMPOSITION',\n",
    "            'o--': 'AGGREGATION',\n",
    "            '--': 'ASSOCIATION',\n",
    "            '-->': 'ASSOCIATION'\n",
    "        }\n",
    "        return mapping.get(rel_type, 'ASSOCIATION')\n",
    "    \n",
    "    def _calculate_metrics(\n",
    "        self, \n",
    "        gold_set: set, \n",
    "        pred_set: set\n",
    "    ) -> EvaluationMetrics:\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1 scores.\n",
    "        \n",
    "        Args:\n",
    "            gold_set: Set of gold standard elements\n",
    "            pred_set: Set of predicted elements\n",
    "            \n",
    "        Returns:\n",
    "            EvaluationMetrics object\n",
    "        \"\"\"\n",
    "        tp = len(gold_set.intersection(pred_set))\n",
    "        fp = len(pred_set - gold_set)\n",
    "        fn = len(gold_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return EvaluationMetrics(\n",
    "            precision=round(precision, 2),\n",
    "            recall=round(recall, 2),\n",
    "            f1=round(f1, 2)\n",
    "        )\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, EvaluationMetrics]:\n",
    "        \"\"\"\n",
    "        Get all evaluation metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with metrics for classes, attributes, and relationships\n",
    "        \"\"\"\n",
    "        # Classes comparison\n",
    "        gold_classes = {c.lower() for c in self.gold_parser.classes.keys()}\n",
    "        pred_classes = {c.lower() for c in self.pred_parser.classes.keys()}\n",
    "        \n",
    "        # Attributes comparison\n",
    "        gold_attrs = set()\n",
    "        for cls, info in self.gold_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                gold_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        pred_attrs = set()\n",
    "        for cls, info in self.pred_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                pred_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        # Relationships comparison\n",
    "        gold_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.gold_parser.relationships\n",
    "        }\n",
    "        pred_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.pred_parser.relationships\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"classes\": self._calculate_metrics(gold_classes, pred_classes),\n",
    "            \"attributes\": self._calculate_metrics(gold_attrs, pred_attrs),\n",
    "            \"relationships\": self._calculate_metrics(gold_rels, pred_rels)\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_diagram(\n",
    "    gold_standard: str,\n",
    "    generated_diagram: str\n",
    ") -> Dict[str, EvaluationMetrics]:\n",
    "    \"\"\"\n",
    "    Evaluate a generated diagram against gold standard.\n",
    "    \n",
    "    Args:\n",
    "        gold_standard: Gold standard PlantUML code\n",
    "        generated_diagram: Generated PlantUML code\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    evaluator = DiagramEvaluator(gold_standard, generated_diagram)\n",
    "    return evaluator.get_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS\n",
      "============================================================\n",
      "\n",
      "Classes:       P=0.86, R=0.86, F1=0.86\n",
      "Attributes:    P=0.86, R=0.86, F1=0.86\n",
      "Relationships: P=0.33, R=0.50, F1=0.40\n",
      "\n",
      "============================================================\n",
      "OVERALL F1 SCORE: 0.71\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "gold_standard = test_exercises[test_idx][\"solution_plantuml\"]\n",
    "generated_diagram = final_output[\"current_diagram\"]\n",
    "\n",
    "metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nClasses:       {metrics['classes']}\")\n",
    "print(f\"Attributes:    {metrics['attributes']}\")\n",
    "print(f\"Relationships: {metrics['relationships']}\")\n",
    "\n",
    "avg_f1 = (\n",
    "    metrics['classes'].f1 + \n",
    "    metrics['attributes'].f1 + \n",
    "    metrics['relationships'].f1\n",
    ") / 3\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL F1 SCORE: {avg_f1:.2f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42196e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BatchResult:\n",
    "    \"\"\"Result from a single exercise in batch evaluation.\"\"\"\n",
    "    exercise_num: int\n",
    "    success: bool\n",
    "    iterations: int = 0\n",
    "    syntax_valid: bool = False\n",
    "    logic_valid: bool = False\n",
    "    metrics: Optional[Dict[str, EvaluationMetrics]] = None\n",
    "    diagram_url: Optional[str] = None\n",
    "    error: Optional[str] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for DataFrame creation.\"\"\"\n",
    "        if self.metrics:\n",
    "            return {\n",
    "                \"exercise\": self.exercise_num,\n",
    "                \"success\": self.success,\n",
    "                \"iterations\": self.iterations,\n",
    "                \"syntax_valid\": self.syntax_valid,\n",
    "                \"logic_valid\": self.logic_valid,\n",
    "                \"class_f1\": self.metrics['classes'].f1,\n",
    "                \"attr_f1\": self.metrics['attributes'].f1,\n",
    "                \"rel_f1\": self.metrics['relationships'].f1,\n",
    "                \"diagram_url\": self.diagram_url\n",
    "            }\n",
    "        return {\n",
    "            \"exercise\": self.exercise_num,\n",
    "            \"success\": self.success,\n",
    "            \"error\": self.error\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_batch(\n",
    "    app: Any,\n",
    "    test_exercises: List[Dict[str, Any]],\n",
    "    puml_tool: PlantUMLTool,\n",
    "    max_exercises: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run batch evaluation on multiple exercises.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        test_exercises: List of exercise dictionaries\n",
    "        puml_tool: PlantUML tool for URL generation\n",
    "        max_exercises: Optional limit on number of exercises\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with evaluation results\n",
    "    \"\"\"\n",
    "    exercises_to_test = test_exercises[:max_exercises] if max_exercises else test_exercises\n",
    "    results = []\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"BATCH EVALUATION: {len(exercises_to_test)} exercises\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    for i, exercise in enumerate(exercises_to_test):\n",
    "        logger.info(f\"\\n--- Exercise {i+1}/{len(exercises_to_test)} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Run workflow\n",
    "            requirements = exercise[\"requirements\"]\n",
    "            final_output = run_single_test(app, requirements, f\"Exercise {i+1}\")\n",
    "            \n",
    "            # Evaluate\n",
    "            gold_standard = exercise[\"solution_plantuml\"]\n",
    "            generated_diagram = final_output[\"current_diagram\"]\n",
    "            metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "            \n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=True,\n",
    "                iterations=final_output[\"iterations\"],\n",
    "                syntax_valid=final_output[\"syntax_valid\"],\n",
    "                logic_valid=final_output[\"logic_valid\"],\n",
    "                metrics=metrics,\n",
    "                diagram_url=puml_tool.get_diagram_url(generated_diagram)\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"âœ“ Exercise {i+1}: F1 = {metrics['classes'].f1:.2f} / \"\n",
    "                       f\"{metrics['attributes'].f1:.2f} / {metrics['relationships'].f1:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âœ— Exercise {i+1} failed: {e}\")\n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=False,\n",
    "                error=str(e)\n",
    "            )\n",
    "        \n",
    "        results.append(result.to_dict())\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    logger.info(\"\\n\" + \"=\"*60)\n",
    "    logger.info(\"BATCH EVALUATION COMPLETE\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example: Run on first 3 exercises (uncomment to execute)\n",
    "# df_results = evaluate_batch(app, test_exercises, puml_tool, max_exercises=3)\n",
    "# \n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"BATCH EVALUATION SUMMARY\")\n",
    "# print(\"=\"*60)\n",
    "# successful = df_results[df_results['success'] == True]\n",
    "# if not successful.empty:\n",
    "#     print(successful[['exercise', 'class_f1', 'attr_f1', 'rel_f1']].to_string(index=False))\n",
    "#     avg_f1 = successful[['class_f1', 'attr_f1', 'rel_f1']].mean().mean()\n",
    "#     print(f\"\\nAverage F1: {avg_f1:.2f}\")\n",
    "# else:\n",
    "#     print(\"No successful evaluations\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
