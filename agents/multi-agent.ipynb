{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "e903b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import requests\n",
    "import operator\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# sqlite-vec expects the standard library sqlite3 module.\n",
    "# Older versions of this notebook replaced sqlite3 with sqlean via sys.modules; undo that if present.\n",
    "if sys.modules.get(\"sqlite3\") is sys.modules.get(\"sqlean\"):\n",
    "    del sys.modules[\"sqlite3\"]\n",
    "import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Annotated, List, TypedDict, Optional, Dict, Any, Tuple, Literal\n",
    "from pydantic import BaseModel, Field, computed_field, field_validator, model_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import SQLiteVec\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from prompts import DECOMPOSER_SYSTEM, GENERATOR_SYSTEM, CRITIC_SYSTEM, REFLECTOR_SYSTEM, PLAN_AUDITOR_SYSTEM, STRUCTURE_REFINER_SYSTEM\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "6e7d7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNames(str, Enum):\n",
    "    \"\"\"Enum for node names to avoid string literals.\"\"\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    DECOMPOSE = \"decompose\"\n",
    "    GENERATE = \"generate\"\n",
    "    SYNTAX_CHECK = \"syntax_check\"\n",
    "    CRITIC = \"critic\"\n",
    "    REFLECTOR = \"reflector\"\n",
    "    PLAN_AUDIT = \"plan_audit\"\n",
    "    STRUCTURE_REFINER = \"structure_refiner\"\n",
    "\n",
    "\n",
    "class Attribute(BaseModel):\n",
    "    \"\"\"Model for a class attribute.\"\"\"\n",
    "    name: str = Field(description=\"Attribute name\")\n",
    "    type: str = Field(description=\"Attribute type\")\n",
    "\n",
    "\n",
    "class Class(BaseModel):\n",
    "    \"\"\"Model for a UML class.\"\"\"\n",
    "    name: str = Field(description=\"Class name\")\n",
    "    attributes: List[Attribute] = Field(default_factory=list, description=\"List of class attributes\")\n",
    "\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Model for a relationship between classes.\"\"\"\n",
    "    source: str = Field(description=\"Source class name\")\n",
    "    target: str = Field(description=\"Target class name\")\n",
    "    type: str = Field(description=\"Relationship type (e.g., association, composition, inheritance)\")\n",
    "    source_multiplicity: str = Field(description=\"Multiplicity at source end\")\n",
    "    target_multiplicity: str = Field(description=\"Multiplicity at target end\")\n",
    "\n",
    "\n",
    "class DecompositionResult(BaseModel):\n",
    "    \"\"\"Structured output from the DECOMPOSE node.\"\"\"\n",
    "    classes: List[Class] = Field(default_factory=list, description=\"List of identified classes\")\n",
    "    relationships: List[Relationship] = Field(default_factory=list, description=\"List of relationships between classes\")\n",
    "\n",
    "\n",
    "class PlanAudit(BaseModel):\n",
    "    critique: List[Literal[\n",
    "        \"Missing class\",\n",
    "        \"Missing relationship\",\n",
    "        \"Disconnected class\"\n",
    "    ]] = Field(default_factory=list, description=\"List of critique points found in the plan.\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Actionable steps to fix the plan.\")\n",
    "    \n",
    "    @computed_field\n",
    "    @property\n",
    "    def is_valid(self) -> bool:\n",
    "        return len(self.critique) == 0\n",
    "\n",
    "\n",
    "class SystemConfig(BaseModel):\n",
    "    \"\"\"System configuration for UML generation.\"\"\"\n",
    "    lmstudio_base_url: str = Field(default=\"http://localhost:1234/v1\", description=\"LMStudio API endpoint\")\n",
    "    model_name: str = Field(default=\"mistralai/devstral-small-2-2512\", description=\"Model to use\")\n",
    "    embedder_model: str = Field(default=\"BAAI/bge-large-en-v1.5\", description=\"Embedder model for semantic search\")\n",
    "    db_path: str = Field(default=\"./../data/uml_knowledge.db\", description=\"Path to SQLite database\")\n",
    "    shots_json_path: str = Field(default=\"./../data/complete_shots.json\", description=\"Path to few-shot examples\")\n",
    "    plantuml_host: str = Field(default=\"http://localhost:8080\", description=\"PlantUML server host\")\n",
    "    max_iterations: int = Field(default=6, ge=1, description=\"Maximum workflow iterations\")\n",
    "    max_tokens_decompose: int = Field(default=2048, description=\"Max tokens for decompose step\")\n",
    "    max_tokens_generate: int = Field(default=2048, description=\"Max tokens for generate step\")\n",
    "    max_tokens_critique: int = Field(default=2048, description=\"Max tokens for critique step\")\n",
    "    max_tokens_reflect: int = Field(default=2048, description=\"Max tokens for reflect step\")\n",
    "    max_tokens_refine: int = Field(default=2048, description=\"Max tokens for structure refine step\")\n",
    "    temperature: float = Field(default=0.15, ge=0.0, le=2.0, description=\"Base temperature for LLM\")\n",
    "    num_few_shots: int = Field(default=3, ge=0, description=\"Number of few-shot examples\")\n",
    "    request_timeout: int = Field(default=5, ge=1, description=\"Timeout for PlantUML server requests\")\n",
    "    llm_timeout: int = Field(default=600, ge=1, description=\"Timeout for LLM operations\")\n",
    "    # New fields for iteration metrics\n",
    "    plateau_window: int = Field(default=3, ge=2, description=\"Number of iterations to consider for plateau detection\")\n",
    "    plateau_threshold: float = Field(default=0.1, ge=0.0, description=\"Score delta threshold for plateau detection\")\n",
    "    max_stagnant_iterations: int = Field(default=2, ge=1, description=\"Max consecutive stagnant iterations before stopping\")\n",
    "\n",
    "\n",
    "class PlantUMLResult(BaseModel):\n",
    "    \"\"\"Result from PlantUML validation.\"\"\"\n",
    "    is_valid: bool = Field(description=\"Whether the PlantUML syntax is valid\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if validation failed\")\n",
    "    url: Optional[str] = Field(default=None, description=\"URL to view the diagram\")\n",
    "    svg_url: Optional[str] = Field(default=None, description=\"URL to view the diagram as SVG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "8b32b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm(config: Optional[SystemConfig] = None) -> ChatOpenAI:\n",
    "    \"\"\"\n",
    "    Create a ChatOpenAI instance configured for LMStudio.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Configured ChatOpenAI instance\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(f\"Connecting to LMStudio at {cfg.lmstudio_base_url}\")\n",
    "    logger.info(f\"Using model: {cfg.model_name} (temp={cfg.temperature})\")\n",
    "    \n",
    "    return ChatOpenAI(\n",
    "        base_url=cfg.lmstudio_base_url,\n",
    "        api_key=\"lm-studio\",  \n",
    "        model=cfg.model_name,\n",
    "        temperature=cfg.temperature,\n",
    "        timeout=cfg.llm_timeout \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "205fd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fixability(str, Enum):\n",
    "    render_only = \"render_only\"\n",
    "    structure_change = \"structure_change\"\n",
    "    unfixable = \"unfixable\"\n",
    "\n",
    "\n",
    "class Severity(str, Enum):\n",
    "    error = \"error\"\n",
    "    warning = \"warning\"\n",
    "\n",
    "\n",
    "class FindingCategory(str, Enum):\n",
    "    coverage = \"coverage\"         \n",
    "    structure = \"structure\"        \n",
    "    render = \"render\"              \n",
    "    syntax = \"syntax\"            \n",
    "\n",
    "\n",
    "class CritiqueFinding(BaseModel):\n",
    "    id: str = Field(default=None, description=\"Stable identifier for this finding\")\n",
    "    category: FindingCategory\n",
    "    severity: Severity = Field(default=Severity.error, description=\"Severity level of the finding\")\n",
    "    fixability: Fixability\n",
    "    affected_elements: List[str]\n",
    "    description: str\n",
    "    expected_correction: Optional[str] = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _slugify(text: str) -> str:\n",
    "        text = re.sub(r\"[^a-z0-9]+\", \"_\", (text or \"\").lower())\n",
    "        return re.sub(r\"_+\", \"_\", text).strip(\"_\") or \"issue\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _entities_from_affected(affected: List[str]) -> Tuple[str, str]:\n",
    "        entity, related = \"none\", \"none\"\n",
    "        for a in affected or []:\n",
    "            if a.startswith(\"class:\"):\n",
    "                entity = a.split(\":\", 1)[1].strip() or entity\n",
    "            elif a.startswith(\"attr:\"):\n",
    "                entity = (a.split(\":\", 1)[1].split(\".\", 1)[0].strip() or entity)\n",
    "            elif a.startswith(\"rel:\"):\n",
    "                rel = a.split(\":\", 1)[1]\n",
    "                parts = re.split(r\"<\\|--|--\\|>|<--|-->|--|\\*--|--\\*\", rel)\n",
    "                if len(parts) >= 2:\n",
    "                    entity = parts[0].strip() or entity\n",
    "                    related = parts[1].strip() or related\n",
    "        return entity or \"none\", related or \"none\"\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def ensure_canonical_id(self):\n",
    "        if self.id and self.id.count(\"::\") == 3 and all(p.strip() for p in self.id.split(\"::\")):\n",
    "            return self\n",
    "\n",
    "        entity, related = self._entities_from_affected(self.affected_elements)\n",
    "\n",
    "        raw = (self.id or \"\").strip()\n",
    "        tail = raw.split(\":\", 1)[1].strip() if \":\" in raw else raw\n",
    "\n",
    "        tail_slug = self._slugify(tail)\n",
    "        if \"missing_attribute\" in tail_slug:\n",
    "            issue_slug = \"missing_attribute\"\n",
    "        elif \"missing_class\" in tail_slug:\n",
    "            issue_slug = \"missing_class\"\n",
    "        elif \"duplicate_relationship\" in tail_slug:\n",
    "            issue_slug = \"duplicate_relationship\"\n",
    "        else:\n",
    "            seed = f\"{self.category.value}|{self.fixability.value}|{','.join(sorted(self.affected_elements or []))}|{self.description[:80]}\"\n",
    "            issue_slug = f\"auto_{hashlib.md5(seed.encode()).hexdigest()[:8]}\"\n",
    "\n",
    "        self.id = f\"{self.category.value}::{entity}::{related}::{issue_slug}\"\n",
    "        return self\n",
    "\n",
    "\n",
    "class CritiqueSummary(BaseModel):\n",
    "    total_findings: int = 0\n",
    "    render_only: int = 0\n",
    "    structure_change: int = 0\n",
    "    unfixable: int = 0\n",
    "    new_findings: int = 0\n",
    "    resolved_findings: int = 0\n",
    "\n",
    "\n",
    "class CritiqueReport(BaseModel):\n",
    "    findings: List[CritiqueFinding]\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def is_valid(self) -> bool:\n",
    "        return not any(f.severity == Severity.error for f in self.findings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "8bd84004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Shared state for the LangGraph workflow.\n",
    "    \"\"\"\n",
    "    requirements: str\n",
    "    plan: Optional[str]\n",
    "    examples: List[Dict[str, str]]\n",
    "    current_diagram: Optional[str]\n",
    "    best_diagram: Optional[str]  \n",
    "    summary: Optional[str]\n",
    "    syntax_valid: bool\n",
    "    logic_valid: bool\n",
    "    error_message: Optional[str]\n",
    "    plan_valid: bool \n",
    "    audit_feedback: Optional[List[str]]  # Feedback from auditor\n",
    "    plan_audit_attempts: int  # audit loop iterations\n",
    "    best_score: float\n",
    "    best_code: str\n",
    "    current_validation: Optional[CritiqueReport]\n",
    "    failed_attempts: Annotated[List[Dict[str, Any]], operator.add]\n",
    "    iterations: int\n",
    "    stagnant_count: int  # Track consecutive iterations without changes\n",
    "    critique_cache: Dict[str, Dict[str, Any]]  # Cache critiques by diagram hash\n",
    "    score_history: List[float]  # History of weighted scores for plateau detection\n",
    "    delta_score: float  # Score change from previous iteration\n",
    "    audit_suggestions: Optional[List[str]]  # Suggestions from plan auditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantUMLTool:\n",
    "    \"\"\"\n",
    "    Tool for validating and rendering PlantUML diagrams.\n",
    "    \n",
    "    This class interfaces with a PlantUML server to check syntax\n",
    "    and generate diagram URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host: str = \"http://localhost:8080\"):\n",
    "        \"\"\"\n",
    "        Initialize PlantUML tool.\n",
    "        \n",
    "        Args:\n",
    "            host: PlantUML server host URL\n",
    "        \"\"\"\n",
    "        self.host = host\n",
    "        logger.info(f\"PlantUML tool initialized with host: {host}\")\n",
    "\n",
    "    def extract_plantuml(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract PlantUML code from markdown blocks or raw text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text containing PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            Extracted PlantUML code or empty string\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Try to extract from ```plantuml ... ```\n",
    "        fence_match = re.search(r\"```\\s*plantuml\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if fence_match:\n",
    "            return fence_match.group(1).strip()\n",
    "        \n",
    "        # Try to extract from @startuml ... @enduml\n",
    "        tag_match = re.search(r\"@startuml.*?@enduml\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if tag_match:\n",
    "            return tag_match.group(0).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def _encode_plantuml(self, plantuml_code: str) -> str:\n",
    "        \"\"\"\n",
    "        Encode PlantUML code for URL.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: Raw PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            URL-safe encoded string\n",
    "        \"\"\"\n",
    "        code = plantuml_code.strip()\n",
    "        \n",
    "        if not code.startswith(\"@startuml\"): \n",
    "            code = f\"@startuml\\n{code}\"\n",
    "        if not code.endswith(\"@enduml\"): \n",
    "            code = f\"{code}\\n@enduml\"\n",
    "        \n",
    "        compressed = zlib.compress(code.encode('utf-8'))[2:-4]\n",
    "        encoded = base64.b64encode(compressed).translate(\n",
    "            bytes.maketrans(\n",
    "                b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\",\n",
    "                b\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_\"\n",
    "            )\n",
    "        ).decode('utf-8')\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "    def get_diagram_url(self, plantuml_code: str, format: str = \"png\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a viewable URL for the PlantUML diagram.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "            format: Output format (png, svg, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            URL to view the diagram\n",
    "        \"\"\"\n",
    "        diagram_code = self.extract_plantuml(plantuml_code)\n",
    "        encoded = self._encode_plantuml(diagram_code)\n",
    "        return f\"{self.host}/{format}/{encoded}\"\n",
    "        \n",
    "    def check_syntax(self, plantuml_code: str, timeout: int = 5) -> PlantUMLResult:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax with detailed error extraction.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML code to validate\n",
    "            timeout: Request timeout in seconds\n",
    "            \n",
    "        Returns:\n",
    "            PlantUMLResult with validation status and detailed error if applicable.\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating PlantUML syntax\")\n",
    "        \n",
    "        try:\n",
    "            diagram_code = self.extract_plantuml(plantuml_code)\n",
    "            encoded = self._encode_plantuml(diagram_code)\n",
    "            \n",
    "            url_png = f\"{self.host}/png/{encoded}\"\n",
    "            response = requests.get(url_png, timeout=timeout)\n",
    "            \n",
    "            if response.status_code == 200 and response.content[:4] == b'\\x89PNG':\n",
    "                logger.info(\"Syntax validation passed (PNG rendered)\")\n",
    "                return PlantUMLResult(\n",
    "                    is_valid=True,\n",
    "                    url=url_png,\n",
    "                    svg_url=f\"{self.host}/svg/{encoded}\"\n",
    "                )\n",
    "            \n",
    "            logger.warning(\"PNG rendering failed. Fetching detailed syntax error...\")\n",
    "            url_txt = f\"{self.host}/txt/{encoded}\"\n",
    "            error_response = requests.get(url_txt, timeout=timeout)\n",
    "            \n",
    "            detailed_error = error_response.text.strip()\n",
    "            \n",
    "            error_msg = f\"PlantUML Syntax Error:\\n{detailed_error[:1000]}\"\n",
    "            logger.error(f\"Syntax error detected: {error_msg}\")\n",
    "            \n",
    "            return PlantUMLResult(\n",
    "                is_valid=False,\n",
    "                error=error_msg\n",
    "            )\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"PlantUML Server Connection Error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected error during syntax check: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "2d633d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Manages long-term memory for UML diagram generation using LangChain's SQLiteVec.\n",
    "    \n",
    "    Supports semantic search to find similar past solutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedder: SentenceTransformer,\n",
    "        db_path: str = \"./../data/uml_knowledge.db\",\n",
    "        embedding_dims: int = 1024\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize memory manager with LangChain SQLiteVec.\n",
    "        \n",
    "        Args:\n",
    "            embedder: SentenceTransformer model for semantic search\n",
    "            db_path: Path to the SQLite database file\n",
    "            embedding_dims: Dimensions of the embeddings \n",
    "        \"\"\"\n",
    "        self.embedder = embedder\n",
    "        self.db_path = db_path\n",
    "        self.embedding_dims = embedding_dims\n",
    "        \n",
    "\n",
    "        self.embedding_function = HuggingFaceEmbeddings(\n",
    "            model_name=embedder.model_name if hasattr(embedder, 'model_name') else \"BAAI/bge-large-en-v1.5\",\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Create directory and connection\n",
    "        os.makedirs(os.path.dirname(self.db_path) if os.path.dirname(self.db_path) else \".\", exist_ok=True)\n",
    "        \n",
    "        # Create connection using sqlean instead of default sqlite3 (which lacks extension support on macOS)\n",
    "        try:\n",
    "            import sqlean\n",
    "            import sqlite_vec\n",
    "            \n",
    "            self.connection = sqlean.connect(self.db_path)\n",
    "            self.connection.row_factory = sqlean.Row\n",
    "            self.connection.enable_load_extension(True)\n",
    "            sqlite_vec.load(self.connection)\n",
    "            self.connection.enable_load_extension(False)\n",
    "            logger.info(\"Used sqlean for SQLite connection (extension support enabled)\")\n",
    "        except ImportError:\n",
    "            logger.warning(\"sqlean not found, falling back to SQLiteVec.create_connection (may fail on macOS)\")\n",
    "            self.connection = SQLiteVec.create_connection(db_file=self.db_path)\n",
    "        \n",
    "        # Initialize vector store with connection\n",
    "        self.vector_store = SQLiteVec(\n",
    "            table=\"uml_memories\",\n",
    "            connection=self.connection,\n",
    "            embedding=self.embedding_function\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"MemoryManager initialized with LangChain SQLiteVec at {db_path} (dims={embedding_dims})\")\n",
    "\n",
    "    def save_diagram(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        diagram: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Save a validated diagram to SQLite long-term memory.\n",
    "                \n",
    "        Args:\n",
    "            requirements: Original requirements text\n",
    "            diagram: PlantUML diagram code\n",
    "            metadata: Optional metadata\n",
    "            \n",
    "        Returns:\n",
    "            ID of the stored record\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        full_metadata = metadata or {}\n",
    "        full_metadata.update({\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "        \n",
    "\n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=full_metadata\n",
    "        )\n",
    "        \n",
    "        ids = self.vector_store.add_documents([doc])\n",
    "        \n",
    "        logger.info(\"Diagram saved to SQLite memory using LangChain SQLiteVec\")\n",
    "        return ids[0] if ids else 0\n",
    "    \n",
    "    def retrieve_similar_diagrams(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        limit: int = 2\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve similar diagrams from SQLite memory using vector search.\n",
    "        \n",
    "        Args:\n",
    "            requirements: Requirements text to search for\n",
    "            limit: Maximum number of results\n",
    "            \n",
    "        Returns:\n",
    "            List of similar diagram records\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.vector_store.similarity_search(requirements, k=limit)\n",
    "            \n",
    "            diagrams = []\n",
    "            for doc in results:\n",
    "                diagrams.append({\n",
    "                    \"requirements\": doc.page_content,\n",
    "                    \"diagram\": doc.metadata.get(\"diagram\", \"\"),\n",
    "                    \"timestamp\": doc.metadata.get(\"timestamp\", \"\"),\n",
    "                    \"metadata\": {k: v for k, v in doc.metadata.items() \n",
    "                                if k not in [\"diagram\", \"timestamp\"]}\n",
    "                })\n",
    "                \n",
    "            logger.info(f\"Retrieved {len(diagrams)} similar diagrams from SQLite\")\n",
    "            return diagrams\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Memory retrieval failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        try:\n",
    "            # Close existing connection\n",
    "            if hasattr(self, 'connection'):\n",
    "                self.connection.close()\n",
    "            \n",
    "            # Remove database file\n",
    "            if os.path.exists(self.db_path):\n",
    "                os.remove(self.db_path)\n",
    "            \n",
    "            # Recreate connection and vector store\n",
    "            import sqlean\n",
    "            import sqlite_vec\n",
    "            \n",
    "            self.connection = sqlean.connect(self.db_path)\n",
    "            self.connection.row_factory = sqlean.Row\n",
    "            self.connection.enable_load_extension(True)\n",
    "            sqlite_vec.load(self.connection)\n",
    "            self.connection.enable_load_extension(False)\n",
    "            \n",
    "            self.vector_store = SQLiteVec(\n",
    "                table=\"uml_memories\",\n",
    "                connection=self.connection,\n",
    "                embedding=self.embedding_function\n",
    "            )\n",
    "\n",
    "            logger.info(\"Memory cleared and reinitialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to clear memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "19a6486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_memory_from_shots(\n",
    "    memory_manager: MemoryManager,\n",
    "    shots_json_path: str = \"./../data/complete_shots.json\",\n",
    "    force_reseed: bool = False\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Seed the memory database with few-shot examples from JSON file.\n",
    "    Skips seeding if database already contains data (unless force_reseed=True).\n",
    "    \n",
    "    Args:\n",
    "        memory_manager: MemoryManager instance to seed\n",
    "        shots_json_path: Path to the complete_shots.json file\n",
    "        force_reseed: If True, clears existing data and reseeds\n",
    "        \n",
    "    Returns:\n",
    "        Number of shots seeded (0 if skipped)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"CHECKING MEMORY SEEDING STATUS\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    # Check if database already has data\n",
    "    try:\n",
    "        existing_docs = memory_manager.vector_store.similarity_search(\"test\", k=1)\n",
    "        if existing_docs and not force_reseed:\n",
    "            logger.info(f\"Database already contains data ({len(existing_docs)} docs found)\")\n",
    "            logger.info(\"Skipping seeding operation. Set force_reseed=True to override.\")\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Database appears empty or uninitialized: {e}\")\n",
    "    \n",
    "    if force_reseed:\n",
    "        logger.warning(\"Force reseed enabled - clearing existing memory\")\n",
    "        memory_manager.clear_memory()\n",
    "    \n",
    "\n",
    "    if not os.path.exists(shots_json_path):\n",
    "        logger.error(f\"Shots file not found at {shots_json_path}\")\n",
    "        return 0\n",
    "    \n",
    "    logger.info(f\"Loading shots from {shots_json_path}\")\n",
    "    with open(shots_json_path, 'r', encoding='utf-8') as f:\n",
    "        shots = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Found {len(shots)} shots to seed\")\n",
    "    \n",
    "    # Prepare documents\n",
    "    documents = []\n",
    "    for shot in shots:\n",
    "        requirements = shot[\"requirements\"]\n",
    "        diagram = shot[\"diagram\"]\n",
    "        \n",
    "        metadata = {\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"plan\": shot.get(\"plan\"),\n",
    "            \"is_static\": True,\n",
    "            \"title\": shot.get(\"title\", \"Untitled\")\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"  Processing: {metadata['title']}\")\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    if documents:\n",
    "        memory_manager.vector_store.add_documents(documents)\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"✓ Successfully seeded {len(documents)} shots to memory\")\n",
    "        logger.info(\"=\"*60)\n",
    "        return len(documents)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "7182a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMLNodes:\n",
    "    \"\"\"\n",
    "    Collection of agent nodes for the UML generation workflow.\n",
    "    \n",
    "    Each method represents a node in the LangGraph workflow and\n",
    "    follows the pattern of taking AgentState and returning a dict\n",
    "    with state updates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: ChatOpenAI,\n",
    "        plantuml_tool: PlantUMLTool,\n",
    "        memory_manager: Optional['MemoryManager'] = None,\n",
    "        config: Optional[SystemConfig] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize UML nodes with required dependencies.\n",
    "        \n",
    "        Args:\n",
    "            llm: LangChain ChatOpenAI instance\n",
    "            plantuml_tool: Tool for PlantUML validation\n",
    "            memory_manager: long-term memory manager\n",
    "            config: Optional system configuration\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.plantuml_tool = plantuml_tool\n",
    "        self.memory_manager = memory_manager\n",
    "        self.config = config or SystemConfig()\n",
    "        logger.info(\"UMLNodes initialized\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_diagram(diagram: str) -> str:\n",
    "        \"\"\"Normalize diagram for consistent hashing (remove whitespace variations).\"\"\"\n",
    "        lines = [line.strip() for line in diagram.strip().split('\\n') if line.strip()]\n",
    "        return '\\n'.join(sorted(lines))  # Sort for order-independent comparison\n",
    "    \n",
    "    @staticmethod\n",
    "    def _hash_diagram(diagram: str) -> str:\n",
    "        \"\"\"Create a hash of the diagram content for caching.\"\"\"\n",
    "        normalized = UMLNodes._normalize_diagram(diagram)\n",
    "        return hashlib.md5(normalized.encode()).hexdigest()\n",
    "\n",
    "    def _safe_invoke(self, runnable: Any, input_data: Any, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Invoke a runnable (LLM or chain) with retry logic.\n",
    "        \"\"\"\n",
    "        max_retries = 3\n",
    "        last_exception = None\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return runnable.invoke(input_data, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logger.warning(f\"LLM call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 * (attempt + 1))\n",
    "        \n",
    "        logger.error(f\"Max retries reached for LLM call: {last_exception}\")\n",
    "        raise last_exception\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_decomposition_plan(decomposition: DecompositionResult) -> str:\n",
    "        \"\"\"\n",
    "        Format a DecompositionResult into a readable plan string.\n",
    "        \n",
    "        Args:\n",
    "            decomposition: The decomposition result with classes and relationships\n",
    "            \n",
    "        Returns:\n",
    "            Formatted plan as a string\n",
    "        \"\"\"\n",
    "        lines = [\"## STRUCTURAL DECOMPOSITION\\n\"]\n",
    "        \n",
    "        # Format classes\n",
    "        if decomposition.classes:\n",
    "            lines.append(\"### Classes:\")\n",
    "            for cls in decomposition.classes:\n",
    "                attrs_str = \", \".join([f\"{attr.name}: {attr.type}\" for attr in cls.attributes])\n",
    "                lines.append(f\"- {cls.name}\" + (f\" ({attrs_str})\" if attrs_str else \"\"))\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Format relationships\n",
    "        if decomposition.relationships:\n",
    "            lines.append(\"### Relationships:\")\n",
    "            for rel in decomposition.relationships:\n",
    "                src_multiplicity_str = f\" [{rel.source_multiplicity}]\" if rel.source_multiplicity else \"\"\n",
    "                tgt_multiplicity_str = f\" [{rel.target_multiplicity}]\" if rel.target_multiplicity else \"\"\n",
    "                lines.append(f\"- {rel.source}{src_multiplicity_str} --{rel.type}--> {rel.target}{tgt_multiplicity_str}\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def retrieve(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant few-shot examples based on requirements.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'examples' key containing formatted shots\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.RETRIEVE.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            memories = self.memory_manager.retrieve_similar_diagrams(\n",
    "                state[\"requirements\"],\n",
    "                limit=self.config.num_few_shots\n",
    "            )\n",
    "            \n",
    "            formatted_shots = []\n",
    "            for mem in memories:\n",
    "                formatted_shots.append(\n",
    "                    HumanMessage(content=f\"Requirements:\\n{mem['requirements']}\")\n",
    "                )\n",
    "                \n",
    "                meta = mem.get(\"metadata\", {})\n",
    "                plan = meta.get(\"plan\", \"No plan available.\")\n",
    "                \n",
    "                assistant_content = (\n",
    "                    f\"1. DESIGN PLAN:\\n{plan}\\n\\n\"\n",
    "                    f\"2. PLANTUML DIAGRAM:\\n```plantuml\\n{mem['diagram']}\\n```\"\n",
    "                )\n",
    "                \n",
    "                formatted_shots.append(\n",
    "                    AIMessage(content=assistant_content)\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"Retrieved {len(memories)} relevant examples from unified memory\")\n",
    "            return {\"examples\": formatted_shots}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Retrieval failed: {e}\")\n",
    "            return {\"examples\": []}\n",
    "\n",
    "    def decompose(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Decompose requirements into structural building blocks.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'plan' update containing formatted decomposition\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.DECOMPOSE.upper()} ---\")\n",
    "\n",
    "        critique = state.get(\"audit_feedback\", []) or []\n",
    "        suggestions = state.get(\"audit_suggestions\", []) or []\n",
    "\n",
    "        critique_str = \"\\n\".join([f\"- {c}\" for c in critique]) if critique else \"None\"\n",
    "        suggestions_str = \"\\n\".join([f\"- {s}\" for s in suggestions]) if suggestions else \"None\"\n",
    "\n",
    "        system_prompt = DECOMPOSER_SYSTEM\n",
    "        if critique or suggestions:\n",
    "            system_prompt += (\n",
    "                \"\\n\\nIMPORTANT: You must REVISE the previous plan to address the audit.\"\n",
    "                \"\\n- Make the smallest changes needed.\"\n",
    "                \"\\n- Do not drop correct elements.\"\n",
    "                \"\\n\\nAUDIT CRITIQUE:\\n\"\n",
    "                f\"{critique_str}\"\n",
    "                \"\\n\\nAUDIT SUGGESTIONS:\\n\"\n",
    "                f\"{suggestions_str}\"\n",
    "            )\n",
    "        \n",
    "        messages = [SystemMessage(content=system_prompt)]\n",
    "        messages.append(HumanMessage(content=f\"REQUIREMENTS:\\n{state['requirements']}\"))\n",
    "\n",
    "        previous_plan = state.get(\"plan\")\n",
    "        if previous_plan:\n",
    "            messages.append(HumanMessage(content=f\"PREVIOUS PLAN (revise this):\\n{previous_plan}\"))\n",
    "        \n",
    "        try:\n",
    "            structured_llm = self.llm.bind(max_tokens=self.config.max_tokens_decompose).with_structured_output(DecompositionResult)\n",
    "            decomposition: DecompositionResult = self._safe_invoke(\n",
    "                structured_llm,\n",
    "                messages\n",
    "            )\n",
    "            logger.info(\"Decomposition completed\")\n",
    "            formatted_plan = self._format_decomposition_plan(decomposition)\n",
    "            \n",
    "            return {\"plan\": formatted_plan}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Decomposition failed: {e}\")\n",
    "            empty_decomposition = DecompositionResult(classes=[], relationships=[])\n",
    "            formatted_plan = self._format_decomposition_plan(empty_decomposition)\n",
    "            return {\"plan\": formatted_plan}\n",
    "        \n",
    "    def plan_auditor(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Audits the structural plan for logical consistency and requirement coverage.\n",
    "        \n",
    "        Uses PlanAudit Pydantic model for structured output validation.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'plan_valid' and 'audit_feedback' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.PLAN_AUDIT.upper()} ---\")\n",
    "        \n",
    "        # Check if we've exceeded max plan audit attempts\n",
    "        max_plan_audit_attempts = 3\n",
    "        current_attempts = state.get(\"plan_audit_attempts\", 0) + 1\n",
    "        \n",
    "        if current_attempts > max_plan_audit_attempts:\n",
    "            logger.warning(f\"Max plan audit attempts ({max_plan_audit_attempts}) reached. Forcing plan validation.\")\n",
    "            return {\n",
    "                \"plan_valid\": True,\n",
    "                \"audit_feedback\": [],\n",
    "                \"audit_suggestions\": [],\n",
    "                \"plan_audit_attempts\": current_attempts\n",
    "            }\n",
    "        \n",
    "        plan = state.get(\"plan\")\n",
    "        requirements = state.get(\"requirements\")\n",
    "        req_len = len(requirements) if isinstance(requirements, str) else 0\n",
    "        plan_len = len(plan) if isinstance(plan, str) else 0\n",
    "        logger.debug(f\"Plan audit inputs: requirements_len={req_len}, plan_len={plan_len}\")\n",
    "        logger.debug(f\"Plan audit prompt template chars={len(PLAN_AUDITOR_SYSTEM)}\")\n",
    "        if not requirements:\n",
    "            logger.warning(\"Plan audit received empty requirements\")\n",
    "        if not plan:\n",
    "            logger.warning(\"Plan audit received empty plan\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        REQUIREMENTS:\n",
    "        {requirements}\n",
    "        \n",
    "        PROPOSED PLAN:\n",
    "        {plan}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            messages = [\n",
    "                SystemMessage(content=PLAN_AUDITOR_SYSTEM),\n",
    "                HumanMessage(content=prompt)\n",
    "            ]\n",
    "            # Questa sezione di codice si può probabilmente semplificare\n",
    "            try:\n",
    "                structured_llm = self.llm.with_structured_output(PlanAudit, include_raw=True)\n",
    "                audit_payload = structured_llm.invoke(messages)\n",
    "                audit_result: Optional[PlanAudit] = audit_payload.get(\"parsed\")\n",
    "                raw_msg = audit_payload.get(\"raw\")\n",
    "                parsing_error = audit_payload.get(\"parsing_error\")\n",
    "                if raw_msg is not None and getattr(raw_msg, 'content', None) is not None:\n",
    "                    raw_text = str(raw_msg.content)\n",
    "                    raw_preview = raw_text[:2000] + (\"...\" if len(raw_text) > 2000 else \"\")\n",
    "                    logger.debug(f\"Plan audit raw response (preview): {raw_preview}\")\n",
    "                if parsing_error is not None:\n",
    "                    logger.warning(f\"Plan audit parsing_error: {parsing_error}\")\n",
    "                if audit_result is None:\n",
    "                    raise ValueError(\"Plan audit produced no parsed result\")\n",
    "            except TypeError:\n",
    "                audit_result = self.llm.with_structured_output(PlanAudit).invoke(messages)\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            logger.debug(f\"Plan audit invoke took {elapsed:.2f}s\")\n",
    "            \n",
    "            logger.info(f\"Plan audit completed: valid={audit_result.is_valid}\")\n",
    "            logger.debug(f\"Plan audit parsed: critique_count={len(audit_result.critique)}, suggestions_count={len(audit_result.suggestions)}\")\n",
    "            \n",
    "            logger.info(f\"Output from plan auditor: {audit_result.model_dump()}\")\n",
    "            \n",
    "            #if not audit_result.is_valid:\n",
    "            if audit_result.critique:\n",
    "                logger.info(f\"Audit issues (first 5): {', '.join(audit_result.critique[:5])}\")\n",
    "            if audit_result.suggestions:\n",
    "                logger.info(f\"Audit suggestions (first 5): {', '.join(audit_result.suggestions[:5])}\")\n",
    "            logger.debug(f\"Plan audit full result: {audit_result.model_dump()}\")\n",
    "            \n",
    "            return {\n",
    "                \"plan_valid\": audit_result.is_valid,\n",
    "                \"audit_feedback\": audit_result.critique,\n",
    "                \"audit_suggestions\": audit_result.suggestions,\n",
    "                \"plan_audit_attempts\": current_attempts\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Plan audit failed: {e}\")\n",
    "            return {\n",
    "                \"plan_valid\": False,\n",
    "                \"audit_feedback\": [f\"Audit error: {str(e)}\"],\n",
    "                \"audit_suggestions\": [],\n",
    "                \"plan_audit_attempts\": current_attempts  \n",
    "            }\n",
    "\n",
    "    def generate(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate PlantUML diagram using chain-of-thought reasoning.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.GENERATE.upper()} ---\")\n",
    "        \n",
    "        messages = [SystemMessage(content=GENERATOR_SYSTEM)]\n",
    "        \n",
    "        # Add few-shot examples if available\n",
    "        if state.get(\"examples\"):\n",
    "            messages.extend(state[\"examples\"])\n",
    "            logger.debug(f\"Added {len(state['examples'])} example messages\")\n",
    "            \n",
    "        user_content = f\"\"\"\n",
    "        # VALIDATED REQUIREMENTS\n",
    "        {state['requirements']}\n",
    "\n",
    "        # VALIDATED DESIGN PLAN\n",
    "        {state['plan']}\n",
    "\n",
    "        # TASK\n",
    "        Render the PlantUML class diagram exactly from the design plan.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add syntax error feedback if we're retrying after syntax check failure\n",
    "        if not state.get(\"syntax_valid\", True) and state.get(\"error_message\"):\n",
    "            user_content += f\"\"\"\n",
    "        \n",
    "        # PREVIOUS ATTEMPT HAD SYNTAX ERROR\n",
    "        {state['error_message']}\n",
    "        \n",
    "        Fix the syntax error and regenerate the diagram.\n",
    "        \"\"\"\n",
    "            logger.info(f\"Added syntax error feedback to generation prompt\")\n",
    "        \n",
    "        messages.append(HumanMessage(content=user_content))\n",
    "\n",
    "        logger.debug(f\"Generation prompt messages: {messages}\")\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_generate\n",
    "            )\n",
    "            diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "            \n",
    "            logger.info(f\"Generation completed (iteration {state['iterations'] + 1})\")\n",
    "            return {\n",
    "                \"current_diagram\": diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1,\n",
    "                \"stagnant_count\": 0  # Reset stagnation counter on new generation\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": f\"Error: {str(e)}\",\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "    def syntax_check(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax through server.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'syntax_valid' and optional 'error_message'\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SYNTAX_CHECK.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            result = self.plantuml_tool.check_syntax(\n",
    "                state[\"current_diagram\"],\n",
    "                timeout=self.config.request_timeout\n",
    "            )\n",
    "            \n",
    "            if result.is_valid:\n",
    "                logger.info(f\"Syntax valid. View at: {result.url}\")\n",
    "            else:\n",
    "                logger.warning(f\"Syntax error: {result.error}\")\n",
    "            \n",
    "            return {\n",
    "                \"syntax_valid\": result.is_valid,\n",
    "                \"error_message\": result.error if not result.is_valid else None,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Syntax check failed: {e}\")\n",
    "            return {\n",
    "                \"syntax_valid\": False,\n",
    "                \"error_message\": f\"Syntax check error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def critic(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Critic node: produces a formal CritiqueReport, tracks semantic progress,\n",
    "        and updates stagnation metrics.\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.CRITIC.upper()} ---\")\n",
    "\n",
    "        try:\n",
    "            requirements = state[\"requirements\"]\n",
    "            diagram = self.plantuml_tool.extract_plantuml(state[\"current_diagram\"])\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(content=CRITIC_SYSTEM),\n",
    "                HumanMessage(content=json.dumps({\n",
    "                    \"requirements\": requirements,\n",
    "                    \"diagram\": diagram\n",
    "                }))\n",
    "            ]\n",
    "\n",
    "            structured_llm = self.llm.bind(max_tokens=self.config.max_tokens_critique).with_structured_output(CritiqueReport)\n",
    "            report: CritiqueReport = self._safe_invoke(structured_llm, messages)\n",
    "\n",
    "            # ---- STAGNATION TRACKING ----\n",
    "            prev_ids = set(state.get(\"previous_finding_ids\", []))\n",
    "            curr_ids = {f.id for f in report.findings}\n",
    "\n",
    "            resolved = prev_ids - curr_ids\n",
    "            new = curr_ids - prev_ids\n",
    "\n",
    "            if not resolved and not new:\n",
    "                stagnant_count = state.get(\"stagnant_count\", 0) + 1\n",
    "            else:\n",
    "                stagnant_count = 0\n",
    "\n",
    "            # ---- UPDATE SUMMARY ----\n",
    "            summary: CritiqueSummary = CritiqueSummary(\n",
    "                total_findings=len(report.findings),\n",
    "                render_only=sum(1 for f in report.findings if f.fixability == Fixability.render_only),\n",
    "                structure_change=sum(1 for f in report.findings if f.fixability == Fixability.structure_change),\n",
    "                unfixable=sum(1 for f in report.findings if f.fixability == Fixability.unfixable),\n",
    "                new_findings=len(new),\n",
    "                resolved_findings=len(resolved)\n",
    "            )\n",
    "\n",
    "            logger.info(\n",
    "                f\"Critic findings: total={report.summary.total_findings}, \"\n",
    "                f\"render_only={summary.render_only}, \"\n",
    "                f\"structural={summary.structure_change}, \"\n",
    "                f\"unfixable={summary.unfixable}, \"\n",
    "                f\"new={summary.new_findings}, resolved={summary.resolved_findings}\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"current_validation\": report,\n",
    "                \"previous_finding_ids\": list(curr_ids),\n",
    "                \"stagnant_count\": stagnant_count,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critic node failed: {e}\")\n",
    "            return {\n",
    "                \"logic_valid\": False,\n",
    "                \"current_validation\": None,\n",
    "                \"error_message\": str(e)\n",
    "            }\n",
    "\n",
    "    def reflector(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Reflector node: fixes render-only issues in the current PlantUML diagram\n",
    "        based on structured critique findings.\n",
    "\n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "\n",
    "        Returns:\n",
    "            Dict with updated current_diagram and iterations\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.REFLECTOR.upper()} ---\")\n",
    "\n",
    "        try:\n",
    "            # Extract findings flagged as render-only from current_validation\n",
    "            current_validation = state.get(\"current_validation\")\n",
    "            findings = current_validation.findings if current_validation else []\n",
    "            renderable_findings = [\n",
    "                f for f in findings if f.fixability == Fixability.render_only\n",
    "            ]\n",
    "\n",
    "            # If no render-only findings, also check for errors to provide context\n",
    "            if not renderable_findings:\n",
    "                logger.info(\"No render-only issues to fix. Returning current diagram unchanged.\")\n",
    "                return {\n",
    "                    \"current_diagram\": state[\"current_diagram\"],\n",
    "                    \"iterations\": state[\"iterations\"] + 1,\n",
    "                }\n",
    "\n",
    "            reflector_input = {\n",
    "                \"diagram\": state[\"current_diagram\"],\n",
    "                \"findings\": [f.model_dump() for f in renderable_findings],\n",
    "            }\n",
    "\n",
    "            system_msg = SystemMessage(content=REFLECTOR_SYSTEM)\n",
    "            user_msg = HumanMessage(content=json.dumps(reflector_input))\n",
    "\n",
    "            reflected_diagram_response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                [system_msg, user_msg],\n",
    "                max_tokens=self.config.max_tokens_reflect\n",
    "            )\n",
    "\n",
    "            reflected_diagram = self.plantuml_tool.extract_plantuml(reflected_diagram_response.content)\n",
    "\n",
    "            logger.info(f\"Reflector applied fixes for {len(reflector_input['findings'])} issues.\")\n",
    "\n",
    "            return {\n",
    "                \"current_diagram\": reflected_diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Reflector node failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": state.get(\"current_diagram\"),\n",
    "                \"error_message\": str(e),\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "    \n",
    "    def structure_refiner(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Structure Refiner node: applies guided structural fixes using\n",
    "        expected_correction from critique findings.\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.STRUCTURE_REFINER.upper()} ---\")\n",
    "\n",
    "        try:\n",
    "            validation = state.get(\"current_validation\")\n",
    "            if not validation:\n",
    "                logger.warning(\"No validation report. Structure refiner is a no-op.\")\n",
    "                return {\"current_diagram\": state[\"current_diagram\"]}\n",
    "\n",
    "            findings = [\n",
    "                f for f in validation.findings\n",
    "                if f.fixability == Fixability.structure_change\n",
    "            ]\n",
    "\n",
    "            # Safety: every structural finding must have an expected correction\n",
    "            for f in findings:\n",
    "                if not f.expected_correction:\n",
    "                    logger.error(\n",
    "                        f\"Structural finding missing expected_correction: {f.id}\"\n",
    "                    )\n",
    "                    return {\n",
    "                        \"current_diagram\": state[\"current_diagram\"],\n",
    "                        \"error_message\": f\"Unfixable structural finding: {f.id}\"\n",
    "                    }\n",
    "\n",
    "            if not findings:\n",
    "                logger.info(\"No structural findings to apply.\")\n",
    "                return {\"current_diagram\": state[\"current_diagram\"]}\n",
    "\n",
    "            refiner_input = {\n",
    "                \"requirements\": state[\"requirements\"],\n",
    "                \"diagram\": state[\"current_diagram\"],\n",
    "                \"findings\": [f.model_dump() for f in findings]\n",
    "            }\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(content=STRUCTURE_REFINER_SYSTEM),\n",
    "                HumanMessage(content=json.dumps(refiner_input))\n",
    "            ]\n",
    "\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_refine\n",
    "            )\n",
    "\n",
    "            refined_diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "\n",
    "            logger.info(\n",
    "                f\"Structure refiner applied {len(findings)} guided corrections.\"\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                \"current_diagram\": refined_diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Structure refiner failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": state.get(\"current_diagram\"),\n",
    "                \"error_message\": str(e)\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "1fdc4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_iteration_metrics(state: AgentState, cfg: SystemConfig) -> None:\n",
    "    \"\"\"\n",
    "    Update iteration-based metrics for stopping conditions:\n",
    "    - Weighted score delta\n",
    "    - Plateau detection\n",
    "    - Stagnant iteration count\n",
    "    \n",
    "    Args:\n",
    "        state: Current workflow state\n",
    "        cfg: System configuration (plateau_window, plateau_threshold)\n",
    "    \"\"\"\n",
    "    current_validation = state.get(\"current_validation\")\n",
    "    if not current_validation:\n",
    "        state[\"delta_score\"] = 0.0\n",
    "        state[\"stagnant_count\"] = state.get(\"stagnant_count\", 0)\n",
    "        return\n",
    "\n",
    "    current_score = getattr(current_validation, \"weighted_score\", 0.0)\n",
    "    state.setdefault(\"score_history\", []).insert(0, current_score)  # newest first\n",
    "\n",
    "    # Limit history to plateau window\n",
    "    state[\"score_history\"] = state[\"score_history\"][:cfg.plateau_window]\n",
    "\n",
    "    # Compute delta from previous iteration\n",
    "    if len(state[\"score_history\"]) > 1:\n",
    "        delta = current_score - state[\"score_history\"][1]\n",
    "    else:\n",
    "        delta = current_score  # first iteration\n",
    "\n",
    "    state[\"delta_score\"] = delta\n",
    "\n",
    "    # Check for plateau\n",
    "    plateau_detected = False\n",
    "    if len(state[\"score_history\"]) >= cfg.plateau_window:\n",
    "        deltas = [\n",
    "            abs(state[\"score_history\"][i] - state[\"score_history\"][i+1])\n",
    "            for i in range(len(state[\"score_history\"]) - 1)\n",
    "        ]\n",
    "        if all(d < cfg.plateau_threshold for d in deltas):\n",
    "            plateau_detected = True\n",
    "\n",
    "    # Update stagnant count\n",
    "    if plateau_detected:\n",
    "        state[\"stagnant_count\"] = state.get(\"stagnant_count\", 0) + 1\n",
    "    else:\n",
    "        state[\"stagnant_count\"] = 0\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Iteration metrics updated: current_score={current_score:.2f}, \"\n",
    "        f\"delta_score={delta:.2f}, stagnant_count={state['stagnant_count']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "12124ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uml_graph(\n",
    "    nodes: UMLNodes, \n",
    "    config: Optional[SystemConfig] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Create the LangGraph workflow for UML diagram generation.\n",
    "    \n",
    "    Args:\n",
    "        nodes: UMLNodes instance with all agent methods\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Compiled LangGraph workflow\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"Creating UML generation workflow\")\n",
    "    \n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(NodeNames.RETRIEVE, nodes.retrieve)\n",
    "    workflow.add_node(NodeNames.PLAN_AUDIT, nodes.plan_auditor)\n",
    "    workflow.add_node(NodeNames.DECOMPOSE, nodes.decompose)\n",
    "    workflow.add_node(NodeNames.GENERATE, nodes.generate)\n",
    "    workflow.add_node(NodeNames.SYNTAX_CHECK, nodes.syntax_check)\n",
    "    workflow.add_node(NodeNames.CRITIC, nodes.critic)\n",
    "    workflow.add_node(NodeNames.REFLECTOR, nodes.reflector)\n",
    "    workflow.add_node(NodeNames.STRUCTURE_REFINER, nodes.structure_refiner)\n",
    "    \n",
    "    logger.debug(\"Added 8 nodes to workflow\")\n",
    "\n",
    "    # Define edges\n",
    "    workflow.add_edge(START, NodeNames.RETRIEVE)\n",
    "    workflow.add_edge(NodeNames.RETRIEVE, NodeNames.DECOMPOSE)\n",
    "    workflow.add_edge(NodeNames.DECOMPOSE, NodeNames.PLAN_AUDIT)\n",
    "\n",
    "    def route_after_plan_audit(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on plan audit results.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state.get(\"plan_valid\", False):\n",
    "            logger.debug(\"Routing: plan_audit -> generate\")\n",
    "            return NodeNames.GENERATE\n",
    "            \n",
    "        logger.debug(\"Routing: plan_audit -> decompose\")\n",
    "        return NodeNames.DECOMPOSE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.PLAN_AUDIT, \n",
    "        route_after_plan_audit,\n",
    "        {\n",
    "            NodeNames.DECOMPOSE: NodeNames.DECOMPOSE,\n",
    "            NodeNames.GENERATE: NodeNames.GENERATE\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(NodeNames.GENERATE, NodeNames.SYNTAX_CHECK)\n",
    "\n",
    "    def route_after_syntax_check(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on syntax validation results and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state.get(\"syntax_valid\", False):\n",
    "            logger.debug(\"Routing: syntax_check -> critic\")\n",
    "            return NodeNames.CRITIC\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached during syntax check\")\n",
    "            return END\n",
    "        \n",
    "        logger.debug(\"Routing: syntax_check -> generate (syntax error)\")\n",
    "        return NodeNames.GENERATE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.SYNTAX_CHECK, \n",
    "        route_after_syntax_check,\n",
    "        {\n",
    "            NodeNames.CRITIC: NodeNames.CRITIC,\n",
    "            NodeNames.GENERATE: NodeNames.GENERATE,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def route_after_critic(state: AgentState) -> str:\n",
    "        update_iteration_metrics(state, cfg)  # optional metric tracking\n",
    "\n",
    "        validation = state.get(\"current_validation\")\n",
    "        if not validation:\n",
    "            logger.error(\"No critic report; stopping workflow.\")\n",
    "            return END\n",
    "\n",
    "        summary = validation.summary\n",
    "\n",
    "        # Step 1: Fully valid diagram\n",
    "        if validation.is_valid:\n",
    "            logger.info(\"CRITIC passed: diagram is fully valid → END\")\n",
    "            return END\n",
    "\n",
    "        # Step 2: Check for unfixable structural issues\n",
    "        if summary.unfixable > 0:\n",
    "            logger.warning(\"CRITIC detected unfixable issues → END\")\n",
    "            return END\n",
    "\n",
    "        # Step 3: Check for stagnation\n",
    "        if state.get(\"stagnant_count\", 0) >= cfg.max_stagnant_iterations:\n",
    "            logger.warning(f\"Stagnation detected ({cfg.max_stagnant_iterations}) → END\")\n",
    "            return END\n",
    "\n",
    "        # Step 4: Structural corrections required\n",
    "        if summary.structure_change > 0:\n",
    "            logger.debug(\"Routing: CRITIC → STRUCTURE_REFINER (structural issues exist)\")\n",
    "            return NodeNames.STRUCTURE_REFINER\n",
    "\n",
    "        # Step 5: Render-only issues can be fixed\n",
    "        if summary.render_only > 0:\n",
    "            logger.debug(\"Routing: CRITIC → REFLECTOR (render-only issues exist)\")\n",
    "            return NodeNames.REFLECTOR\n",
    "\n",
    "        # Safety net\n",
    "        logger.warning(\"CRITIC findings not actionable; ending workflow\")\n",
    "        return END\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.CRITIC,\n",
    "        route_after_critic,\n",
    "        {\n",
    "            NodeNames.REFLECTOR: NodeNames.REFLECTOR,\n",
    "            NodeNames.STRUCTURE_REFINER: NodeNames.STRUCTURE_REFINER,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    def route_after_reflector(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route after reflection based on iteration limits and stagnation.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached after reflection\")\n",
    "            return END\n",
    "        logger.debug(\"Routing: reflect -> syntax_check\")\n",
    "        return NodeNames.SYNTAX_CHECK\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.REFLECTOR, \n",
    "        route_after_reflector,\n",
    "        {\n",
    "            NodeNames.SYNTAX_CHECK: NodeNames.SYNTAX_CHECK,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def route_after_structure_refiner(state: AgentState) -> str:\n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached after STRUCTURE_REFINER\")\n",
    "            return END\n",
    "\n",
    "        # After structural corrections, syntax check first\n",
    "        logger.debug(\"Routing: STRUCTURE_REFINER → SYNTAX_CHECK\")\n",
    "        return NodeNames.SYNTAX_CHECK\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.STRUCTURE_REFINER,\n",
    "        route_after_structure_refiner,\n",
    "        {\n",
    "            NodeNames.SYNTAX_CHECK: NodeNames.SYNTAX_CHECK, \n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "        \n",
    "    logger.info(\"Workflow graph created successfully\")\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def create_initial_state(requirements: str) -> AgentState:\n",
    "    \"\"\"\n",
    "    Create an initial state for the workflow.\n",
    "    \n",
    "    Args:\n",
    "        requirements: Software requirements text\n",
    "        \n",
    "    Returns:\n",
    "        Initial AgentState dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"requirements\": requirements,\n",
    "        \"plan\": None,\n",
    "        \"examples\": [],\n",
    "        \"current_diagram\": None,\n",
    "        \"best_diagram\": None,\n",
    "        \"summary\": None,\n",
    "        \"syntax_valid\": False,\n",
    "        \"logic_valid\": False,\n",
    "        \"iterations\": 0,\n",
    "        \"error_message\": None,\n",
    "        \"failed_attempts\": [],\n",
    "        \"stagnant_count\": 0,\n",
    "        \"critique_cache\": {},\n",
    "        # Additional required fields\n",
    "        \"plan_valid\": False,\n",
    "        \"audit_feedback\": None,\n",
    "        \"plan_audit_attempts\": 0,\n",
    "        \"best_score\": 0.0,\n",
    "        \"best_code\": \"\",\n",
    "        \"current_validation\": None,\n",
    "        \"score_history\": [],\n",
    "        \"delta_score\": 0.0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "c3657577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 10:10:05,144 - __main__ - INFO - Loading test exercises from ./../data/test_exercises.json\n",
      "2026-01-16 10:10:05,149 - __main__ - INFO - Loaded 8 test exercises\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 test exercises\n"
     ]
    }
   ],
   "source": [
    "def load_test_exercises(json_path: str = \"./../data/test_exercises.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load test exercises from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to test exercises JSON\n",
    "        \n",
    "    Returns:\n",
    "        List of exercise dictionaries\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        json.JSONDecodeError: If JSON is invalid\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading test exercises from {json_path}\")\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Test exercises file not found: {json_path}\")\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        exercises = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Loaded {len(exercises)} test exercises\")\n",
    "    return exercises\n",
    "\n",
    "try:\n",
    "    test_exercises = load_test_exercises()\n",
    "    print(f\"Loaded {len(test_exercises)} test exercises\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load test exercises: {e}\")\n",
    "    test_exercises = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "e53188a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 10:10:05,159 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:10:05,160 - __main__ - INFO - INITIALIZING UML GENERATION SYSTEM\n",
      "2026-01-16 10:10:05,161 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:10:05,161 - __main__ - INFO - Creating LLM connection...\n",
      "2026-01-16 10:10:05,161 - __main__ - INFO - Connecting to LMStudio at http://localhost:1234/v1\n",
      "2026-01-16 10:10:05,162 - __main__ - INFO - Using model: mistralai/devstral-small-2-2512 (temp=0.15)\n",
      "2026-01-16 10:10:05,174 - __main__ - INFO - Initializing PlantUML tool...\n",
      "2026-01-16 10:10:05,174 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n",
      "2026-01-16 10:10:05,174 - __main__ - INFO - Initializing long-term memory with BAAI/bge-large-en-v1.5...\n",
      "2026-01-16 10:10:05,192 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2026-01-16 10:10:05,192 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2026-01-16 10:10:05,897 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:05,948 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:07,081 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:07,125 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:07,660 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:07,740 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:08,138 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:08,219 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:08,711 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:08,780 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:09,820 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:09,906 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:10,554 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-16 10:10:10,745 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:10,805 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bac2b422766467a9369a8405d169494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: BAAI/bge-large-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "2026-01-16 10:10:11,334 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:11,377 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:11,578 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-16 10:10:11,781 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:18,929 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:10:19,021 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:10:19,224 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5 \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:19,551 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2026-01-16 10:11:19,987 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:20,063 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:20,317 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:20,392 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:20,630 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:20,699 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:20,950 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:21,022 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:21,944 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:22,018 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:22,228 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:22,304 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:23,131 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-16 10:11:23,663 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:23,757 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67364334466742579ca8e2ceebb2950c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: BAAI/bge-large-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "2026-01-16 10:11:24,484 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:24,542 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:24,786 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-16 10:11:24,998 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:25,745 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-16 10:11:25,824 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:26,026 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5 \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:11:26,268 - __main__ - INFO - Used sqlean for SQLite connection (extension support enabled)\n",
      "2026-01-16 10:11:30,348 - __main__ - INFO - MemoryManager initialized with LangChain SQLiteVec at ./../data/uml_knowledge.db (dims=1024)\n",
      "2026-01-16 10:11:30,351 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:30,352 - __main__ - INFO - CHECKING MEMORY SEEDING STATUS\n",
      "2026-01-16 10:11:30,352 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:30,505 - __main__ - WARNING - Force reseed enabled - clearing existing memory\n",
      "2026-01-16 10:11:30,603 - __main__ - INFO - Memory cleared and reinitialized\n",
      "2026-01-16 10:11:30,603 - __main__ - INFO - Loading shots from ./../data/complete_shots.json\n",
      "2026-01-16 10:11:30,605 - __main__ - INFO - Found 20 shots to seed\n",
      "2026-01-16 10:11:30,606 - __main__ - INFO -   Processing: Project Management System\n",
      "2026-01-16 10:11:30,606 - __main__ - INFO -   Processing: Hollywood Approach\n",
      "2026-01-16 10:11:30,606 - __main__ - INFO -   Processing: Word Processor\n",
      "2026-01-16 10:11:30,606 - __main__ - INFO -   Processing: Patient Record and Scheduling\n",
      "2026-01-16 10:11:30,607 - __main__ - INFO -   Processing: Movie-Shop\n",
      "2026-01-16 10:11:30,607 - __main__ - INFO -   Processing: Flights\n",
      "2026-01-16 10:11:30,608 - __main__ - INFO -   Processing: Bank System\n",
      "2026-01-16 10:11:30,608 - __main__ - INFO -   Processing: Veterinary Clinic\n",
      "2026-01-16 10:11:30,608 - __main__ - INFO -   Processing: Auto Repair\n",
      "2026-01-16 10:11:30,608 - __main__ - INFO -   Processing: Restaurant\n",
      "2026-01-16 10:11:30,608 - __main__ - INFO -   Processing: Deliveries\n",
      "2026-01-16 10:11:30,609 - __main__ - INFO -   Processing: Furniture Factory Management\n",
      "2026-01-16 10:11:30,609 - __main__ - INFO -   Processing: Industrial Factory Operations\n",
      "2026-01-16 10:11:30,609 - __main__ - INFO -   Processing: Bycicle Rental\n",
      "2026-01-16 10:11:30,609 - __main__ - INFO -   Processing: Car Park Access System\n",
      "2026-01-16 10:11:30,610 - __main__ - INFO -   Processing: Banking Organizational Structure\n",
      "2026-01-16 10:11:30,610 - __main__ - INFO -   Processing: Prepaid Cell Phone (Decorator Pattern)\n",
      "2026-01-16 10:11:30,610 - __main__ - INFO -   Processing: Library Management System\n",
      "2026-01-16 10:11:30,610 - __main__ - INFO -   Processing: MyDoctor Appointment Management\n",
      "2026-01-16 10:11:30,610 - __main__ - INFO -   Processing: Online Shopping System\n",
      "2026-01-16 10:11:36,477 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:36,479 - __main__ - INFO - ✓ Successfully seeded 20 shots to memory\n",
      "2026-01-16 10:11:36,479 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:36,484 - __main__ - INFO - Long-term memory (SQLite + sqlite-vec) enabled\n",
      "2026-01-16 10:11:36,485 - __main__ - INFO - Seeded 20 few-shot examples into memory\n",
      "2026-01-16 10:11:36,485 - __main__ - INFO - Building LangGraph workflow...\n",
      "2026-01-16 10:11:36,485 - __main__ - INFO - UMLNodes initialized\n",
      "2026-01-16 10:11:36,486 - __main__ - INFO - Creating UML generation workflow\n",
      "2026-01-16 10:11:36,584 - __main__ - INFO - Workflow graph created successfully\n",
      "2026-01-16 10:11:36,646 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:36,646 - __main__ - INFO - SYSTEM INITIALIZED SUCCESSFULLY\n",
      "2026-01-16 10:11:36,646 - __main__ - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready for diagram generation\n",
      "Long-term memory: ENABLED\n"
     ]
    }
   ],
   "source": [
    "def initialize_system(\n",
    "    config: Optional[SystemConfig] = None,\n",
    "    enable_long_term_memory: bool = True\n",
    ") -> Tuple[UMLNodes, Any, SystemConfig, Optional[MemoryManager]]:\n",
    "    \"\"\"\n",
    "    Initialize all system components.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        enable_long_term_memory: Whether to enable long-term memory\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (nodes, compiled_workflow, config, memory_manager)\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"INITIALIZING UML GENERATION SYSTEM\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating LLM connection...\")\n",
    "        llm = create_llm(cfg)\n",
    "        \n",
    "        logger.info(\"Initializing PlantUML tool...\")\n",
    "        puml_tool = PlantUMLTool(cfg.plantuml_host)\n",
    "        \n",
    "        memory_mgr = None\n",
    "        if enable_long_term_memory:\n",
    "            logger.info(f\"Initializing long-term memory with {cfg.embedder_model}...\")\n",
    "\n",
    "            dims = 1024 if \"large\" in cfg.embedder_model.lower() else 384\n",
    "            \n",
    "            memory_mgr = MemoryManager(\n",
    "                embedder=SentenceTransformer(cfg.embedder_model),\n",
    "                db_path=cfg.db_path,\n",
    "                embedding_dims=dims\n",
    "            )\n",
    "\n",
    "            seeded_count = seed_memory_from_shots(\n",
    "                memory_manager=memory_mgr,\n",
    "                shots_json_path=cfg.shots_json_path,\n",
    "                force_reseed=True \n",
    "            )\n",
    "\n",
    "            logger.info(\"Long-term memory (SQLite + sqlite-vec) enabled\")\n",
    "\n",
    "            if seeded_count > 0:\n",
    "                logger.info(f\"Seeded {seeded_count} few-shot examples into memory\")\n",
    "        else:\n",
    "            logger.info(\"Long-term memory disabled\")\n",
    "        \n",
    "\n",
    "        logger.info(\"Building LangGraph workflow...\")\n",
    "        nodes = UMLNodes(llm, puml_tool, memory_mgr, cfg)\n",
    "        app = create_uml_graph(nodes, cfg)\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"SYSTEM INITIALIZED SUCCESSFULLY\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        return nodes, app, cfg, memory_mgr\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"System initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "nodes, app, config, memory_manager = initialize_system(enable_long_term_memory=True)\n",
    "print(\"\\nSystem ready for diagram generation\")\n",
    "print(f\"Long-term memory: {'ENABLED' if memory_manager else 'DISABLED'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "99f339c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 10:11:36,765 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:36,765 - __main__ - INFO - RUNNING: Exercise 3\n",
      "2026-01-16 10:11:36,765 - __main__ - INFO - ============================================================\n",
      "2026-01-16 10:11:36,766 - __main__ - INFO - Requirements preview: A library system manages books, members, and loans.\n",
      "Books have an ISBN, title, author, publisher, publication year, and availability status.\n",
      "Members h...\n",
      "2026-01-16 10:11:36,786 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "2026-01-16 10:11:41,828 - __main__ - INFO - Retrieved 3 similar diagrams from SQLite\n",
      "2026-01-16 10:11:41,833 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-16 10:11:41,836 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-16 10:13:16,486 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:13:16,741 - __main__ - INFO - Decomposition completed\n",
      "2026-01-16 10:13:16,748 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n",
      "2026-01-16 10:13:31,348 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:13:31,391 - __main__ - INFO - Plan audit completed: valid=True\n",
      "2026-01-16 10:13:31,391 - __main__ - INFO - Output from plan auditor: {'critique': [], 'suggestions': [], 'is_valid': True}\n",
      "2026-01-16 10:13:31,393 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-16 10:14:35,038 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:14:35,048 - __main__ - INFO - Generation completed (iteration 1)\n",
      "2026-01-16 10:14:35,051 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-16 10:14:35,055 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-16 10:14:35,294 - __main__ - WARNING - PNG rendering failed. Fetching detailed syntax error...\n",
      "2026-01-16 10:14:35,336 - __main__ - ERROR - Syntax error detected: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:14:35,338 - __main__ - WARNING - Syntax error: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:14:35,340 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-16 10:14:35,340 - __main__ - INFO - Added syntax error feedback to generation prompt\n",
      "2026-01-16 10:15:09,104 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:15:09,113 - __main__ - INFO - Generation completed (iteration 2)\n",
      "2026-01-16 10:15:09,120 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-16 10:15:09,121 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-16 10:15:09,283 - __main__ - WARNING - PNG rendering failed. Fetching detailed syntax error...\n",
      "2026-01-16 10:15:09,307 - __main__ - ERROR - Syntax error detected: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:15:09,309 - __main__ - WARNING - Syntax error: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:15:09,310 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-16 10:15:09,312 - __main__ - INFO - Added syntax error feedback to generation prompt\n",
      "2026-01-16 10:15:33,734 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-16 10:15:33,738 - __main__ - INFO - Generation completed (iteration 3)\n",
      "2026-01-16 10:15:33,740 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-16 10:15:33,742 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-16 10:15:33,829 - __main__ - WARNING - PNG rendering failed. Fetching detailed syntax error...\n",
      "2026-01-16 10:15:33,837 - __main__ - ERROR - Syntax error detected: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:15:33,838 - __main__ - WARNING - Syntax error: PlantUML Syntax Error:\n",
      "Unknown server error\n",
      "2026-01-16 10:15:33,839 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-16 10:15:33,839 - __main__ - INFO - Added syntax error feedback to generation prompt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[634]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m test_idx = \u001b[32m2\u001b[39m\n\u001b[32m     48\u001b[39m requirements = test_exercises[test_idx][\u001b[33m\"\u001b[39m\u001b[33mrequirements\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m final_output = \u001b[43mrun_single_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExercise \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_idx\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     54\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFINAL RESULTS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[634]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_single_test\u001b[39m\u001b[34m(app, requirements, exercise_name)\u001b[39m\n\u001b[32m     22\u001b[39m initial_state = create_initial_state(requirements)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     final_output = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     28\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mWORKFLOW COMPLETED\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[629]\u001b[39m\u001b[32m, line 336\u001b[39m, in \u001b[36mUMLNodes.generate\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    333\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGeneration prompt messages: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessages\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_safe_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_tokens_generate\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m     diagram = \u001b[38;5;28mself\u001b[39m.plantuml_tool.extract_plantuml(response.content)\n\u001b[32m    343\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGeneration completed (iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33miterations\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[629]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mUMLNodes._safe_invoke\u001b[39m\u001b[34m(self, runnable, input_data, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     55\u001b[39m         last_exception = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/langchain_openai/chat_models/base.py:1375\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1369\u001b[39m             response,\n\u001b[32m   1370\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1371\u001b[39m             metadata=generation_info,\n\u001b[32m   1372\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1373\u001b[39m         )\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m         response = raw_response.parse()\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/labs_llm/lib/python3.14/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_single_test(\n",
    "    app: Any,\n",
    "    requirements: str,\n",
    "    exercise_name: str = \"Test Exercise\"\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    Run the workflow on a single exercise.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        requirements: Software requirements text\n",
    "        exercise_name: Name for logging purposes\n",
    "        \n",
    "    Returns:\n",
    "        Final workflow state\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"RUNNING: {exercise_name}\")\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"Requirements preview: {requirements[:150]}...\")\n",
    "    \n",
    "    initial_state = create_initial_state(requirements)\n",
    "    \n",
    "    try:\n",
    "        final_output = app.invoke(initial_state, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"WORKFLOW COMPLETED\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Iterations: {final_output['iterations']}\")\n",
    "        logger.info(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "        logger.info(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "        \n",
    "        if final_output.get('best_diagram') and not final_output['logic_valid']:\n",
    "            if final_output['best_diagram'] != final_output['current_diagram']:\n",
    "                logger.info(\"Using BEST diagram instead of final (prevented regression)\")\n",
    "                final_output['current_diagram'] = final_output['best_diagram']\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Workflow execution failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Select and run a test exercise\n",
    "test_idx = 2\n",
    "requirements = test_exercises[test_idx][\"requirements\"]\n",
    "\n",
    "final_output = run_single_test(\n",
    "    app, \n",
    "    requirements, \n",
    "    f\"Exercise {test_idx + 1}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Iterations: {final_output['iterations']}\")\n",
    "print(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "print(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "\n",
    "if final_output['current_diagram']:\n",
    "    puml_tool = PlantUMLTool(config.plantuml_host)\n",
    "    diagram_url = puml_tool.get_diagram_url(final_output['current_diagram'])\n",
    "    print(f\"\\nDiagram URL: {diagram_url}\")\n",
    "    \n",
    "    print(\"\\nGenerated Diagram:\")\n",
    "    print(final_output['current_diagram']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@startuml\n",
      "class Book {\n",
      "  ISBN\n",
      "  title\n",
      "  author\n",
      "  publisher\n",
      "  publication year\n",
      "  availability status\n",
      "}\n",
      "class Member {\n",
      "  membership ID\n",
      "  name\n",
      "  address\n",
      "  phone number\n",
      "  registration date\n",
      "}\n",
      "class Student {\n",
      "  student ID\n",
      "  program of study\n",
      "}\n",
      "class FacultyMember {\n",
      "  employee ID\n",
      "  department\n",
      "}\n",
      "class Loan {\n",
      "  checkout date\n",
      "  due date\n",
      "  return date\n",
      "}\n",
      "class Fine {\n",
      "  fine amount\n",
      "  payment status\n",
      "}\n",
      "Student \"1\" --|> Member \"1\"\n",
      "FacultyMember \"1\" --|> Member \"1\"\n",
      "Member \"*\" -- Loan \"*\"\n",
      "Book \"*\" -- Loan \"*\"\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40178ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics(BaseModel):\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    precision: float = Field(ge=0.0, le=1.0, description=\"Precision score\")\n",
    "    recall: float = Field(ge=0.0, le=1.0, description=\"Recall score\")\n",
    "    f1: float = Field(ge=0.0, le=1.0, description=\"F1 score\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"P={self.precision:.2f}, R={self.recall:.2f}, F1={self.f1:.2f}\"\n",
    "\n",
    "\n",
    "class PlantUMLParser:\n",
    "    \"\"\"\n",
    "    Parser for extracting structured information from PlantUML diagrams.\n",
    "    \n",
    "    Extracts classes, attributes, and relationships from PlantUML code\n",
    "    for evaluation purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plantuml_code: str):\n",
    "        \"\"\"\n",
    "        Initialize parser with PlantUML code.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "        \"\"\"\n",
    "        self.plantuml_code = plantuml_code\n",
    "        self.classes: Dict[str, Dict[str, List[str]]] = {}\n",
    "        self.relationships: List[Dict[str, Any]] = []\n",
    "        self.parse()\n",
    "    \n",
    "    def parse(self) -> None:\n",
    "        \"\"\"Parse the PlantUML code.\"\"\"\n",
    "        try:\n",
    "            self._extract_classes()\n",
    "            self._extract_relationships()\n",
    "            logger.debug(f\"Parsed {len(self.classes)} classes and {len(self.relationships)} relationships\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Parsing failed: {e}\")\n",
    "    \n",
    "    def _extract_classes(self) -> None:\n",
    "        \"\"\"Extract class definitions and their attributes.\"\"\"\n",
    "        class_pattern = r'class\\s+(\\w+)\\s*\\{([^}]*)\\}'\n",
    "        matches = re.finditer(class_pattern, self.plantuml_code, re.MULTILINE | re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            class_name = match.group(1)\n",
    "            class_body = match.group(2)\n",
    "            \n",
    "            attributes = []\n",
    "            for line in class_body.strip().split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('--'):\n",
    "                    attributes.append(line)\n",
    "            \n",
    "            self.classes[class_name] = {'attributes': attributes}\n",
    "    \n",
    "    def _extract_relationships(self) -> None:\n",
    "        \"\"\"Extract relationships between classes with cardinalities.\"\"\"\n",
    "        patterns = [\n",
    "            # Generalization (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<\\|--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--|>\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            \n",
    "            # Composition (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*\\*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\*\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            \n",
    "            # Aggregation (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*o--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--o\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            \n",
    "            # Directed Association (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*-->\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            \n",
    "            # Simple Association (no arrow)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, rel_type in patterns:\n",
    "            for match in re.finditer(pattern, self.plantuml_code):\n",
    "                source = match.group(1)\n",
    "                target = match.group(4)\n",
    "                \n",
    "                # Skip if source or target is None or empty\n",
    "                if not source or not target:\n",
    "                    continue\n",
    "                \n",
    "                self.relationships.append({\n",
    "                    'type': rel_type,\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'cardinality_source': match.group(2) if match.lastindex >= 2 else None,\n",
    "                    'cardinality_target': match.group(3) if match.lastindex >= 3 else None\n",
    "                })\n",
    "\n",
    "\n",
    "class DiagramEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for comparing generated diagrams against gold standards.\n",
    "    \n",
    "    Computes precision, recall, and F1 scores for classes, attributes,\n",
    "    and relationships.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gold_plantuml: str, pred_plantuml: str):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with gold and predicted diagrams.\n",
    "        \n",
    "        Args:\n",
    "            gold_plantuml: Gold standard PlantUML code\n",
    "            pred_plantuml: Predicted PlantUML code\n",
    "        \"\"\"\n",
    "        self.gold_parser = PlantUMLParser(gold_plantuml)\n",
    "        self.pred_parser = PlantUMLParser(pred_plantuml)\n",
    "    \n",
    "    def _normalize_attr(self, attr_str: str) -> str:\n",
    "        \"\"\"Normalize attribute strings for comparison.\"\"\"\n",
    "        return attr_str.split(':')[0].strip().lower()\n",
    "    \n",
    "    def _normalize_rel_type(self, rel_type: str) -> str:\n",
    "        \"\"\"Normalize relationship types.\"\"\"\n",
    "        mapping = {\n",
    "            '<|--': 'INHERITANCE',\n",
    "            '--|>': 'INHERITANCE',\n",
    "            '*--': 'COMPOSITION',\n",
    "            '--*': 'COMPOSITION',\n",
    "            'o--': 'AGGREGATION',\n",
    "            '--o': 'AGGREGATION',\n",
    "            '--': 'ASSOCIATION',\n",
    "            '<--': 'ASSOCIATION',\n",
    "            '-->': 'ASSOCIATION'\n",
    "        }\n",
    "        return mapping.get(rel_type, 'ASSOCIATION')\n",
    "    \n",
    "    def _calculate_metrics(\n",
    "        self, \n",
    "        gold_set: set, \n",
    "        pred_set: set\n",
    "    ) -> EvaluationMetrics:\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1 scores.\n",
    "        \n",
    "        Args:\n",
    "            gold_set: Set of gold standard elements\n",
    "            pred_set: Set of predicted elements\n",
    "            \n",
    "        Returns:\n",
    "            EvaluationMetrics object\n",
    "        \"\"\"\n",
    "        tp = len(gold_set.intersection(pred_set))\n",
    "        fp = len(pred_set - gold_set)\n",
    "        fn = len(gold_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return EvaluationMetrics(\n",
    "            precision=round(precision, 2),\n",
    "            recall=round(recall, 2),\n",
    "            f1=round(f1, 2)\n",
    "        )\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, EvaluationMetrics]:\n",
    "        \"\"\"\n",
    "        Get all evaluation metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with metrics for classes, attributes, and relationships\n",
    "        \"\"\"\n",
    "        # Classes \n",
    "        gold_classes = {c.lower() for c in self.gold_parser.classes.keys()}\n",
    "        pred_classes = {c.lower() for c in self.pred_parser.classes.keys()}\n",
    "        \n",
    "        # Attributes \n",
    "        gold_attrs = set()\n",
    "        for cls, info in self.gold_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                gold_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        pred_attrs = set()\n",
    "        for cls, info in self.pred_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                pred_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        # Relationships (type + direction only)\n",
    "        gold_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        # Cardinalities \n",
    "        gold_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            \"classes\": self._calculate_metrics(gold_classes, pred_classes),\n",
    "            \"attributes\": self._calculate_metrics(gold_attrs, pred_attrs),\n",
    "            \"relationships\": self._calculate_metrics(gold_rels, pred_rels),\n",
    "            \"cardinalities\": self._calculate_metrics(gold_rels_card, pred_rels_card)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "def evaluate_diagram(\n",
    "    gold_standard: str,\n",
    "    generated_diagram: str\n",
    ") -> Dict[str, EvaluationMetrics]:\n",
    "    \"\"\"\n",
    "    Evaluate a generated diagram against gold standard.\n",
    "    \n",
    "    Args:\n",
    "        gold_standard: Gold standard PlantUML code\n",
    "        generated_diagram: Generated PlantUML code\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    evaluator = DiagramEvaluator(gold_standard, generated_diagram)\n",
    "    return evaluator.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS\n",
      "============================================================\n",
      "\n",
      "Classes:       P=0.83, R=0.71, F1=0.77\n",
      "Attributes:    P=0.30, R=0.27, F1=0.29\n",
      "Relationships: P=1.00, R=0.29, F1=0.44\n",
      "Cardinalities: P=0.00, R=0.00, F1=0.00\n",
      "\n",
      "============================================================\n",
      "OVERALL F1 SCORE: 0.53\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "gold_standard = test_exercises[test_idx][\"solution_plantuml\"]\n",
    "generated_diagram = final_output[\"current_diagram\"]\n",
    "\n",
    "metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nClasses:       {metrics['classes']}\")\n",
    "print(f\"Attributes:    {metrics['attributes']}\")\n",
    "print(f\"Relationships: {metrics['relationships']}\")\n",
    "print(f\"Cardinalities: {metrics['cardinalities']}\")\n",
    "\n",
    "weighted_avg_f1 = (\n",
    "    metrics['classes'].f1 * 0.4 + \n",
    "    metrics['attributes'].f1 * 0.3 + \n",
    "    metrics['relationships'].f1 * 0.3\n",
    "    # metrics['cardinalities'].f1 * 0.2\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL F1 SCORE: {weighted_avg_f1:.2f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
