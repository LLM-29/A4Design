{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0865aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import requests\n",
    "import operator\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# macOS sqlite3 doesn't support extension loading\n",
    "try:\n",
    "    import sqlean as sqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules['sqlean']\n",
    "except ImportError:\n",
    "    import sqlite3\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Annotated, List, TypedDict, Optional, Dict, Any, Tuple\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import SQLiteVec\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from prompts import DECOMPOSER_SYSTEM, GENERATOR_SYSTEM, CRITIC_SYSTEM, SUMMARIZER_SYSTEM, REFLECTOR_SYSTEM\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97779ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNames(str, Enum):\n",
    "    \"\"\"Enum for node names to avoid string literals.\"\"\"\n",
    "    RETRIEVE = \"retrieve\"\n",
    "    DECOMPOSE = \"decompose\"\n",
    "    GENERATE = \"generate\"\n",
    "    SYNTAX_CHECK = \"syntax_check\"\n",
    "    CRITIC = \"critic\"\n",
    "    SUMMARIZE = \"summarize\"\n",
    "    REFLECT = \"reflect\"\n",
    "    PLAN_AUDIT = \"plan_audit\"\n",
    "\n",
    "\n",
    "class Scores(int, Enum):\n",
    "    AVERAGE_SCORE_THRESHOLD = 8.5\n",
    "    REQUIREMENT_COVERAGE_THRESHOLD = 9.0\n",
    "\n",
    "\n",
    "class CritiqueError(BaseModel):\n",
    "    \"\"\"Model for a single critique error.\"\"\"\n",
    "    type: str = Field(description=\"Type of error\")\n",
    "    description: str = Field(description=\"Detailed description of the error\")\n",
    "\n",
    "\n",
    "class CritiqueResponse(BaseModel):\n",
    "    \"\"\"Structured output from the CRITIC node.\"\"\"\n",
    "    requirement_coverage: float = Field(ge=0, le=10, description=\"Does it capture all classes and relationships from the text?\")\n",
    "    design_best_practices: float = Field(ge=0, le=10, description=\"Are relationships correct? (e.g., composition vs association)\")\n",
    "    structural_integrity: float = Field(ge=0, le=10, description=\"Are there redundant classes or missing attributes?\")\n",
    "    is_valid: bool = Field(description=f\"True only if total average score is > {Scores.AVERAGE_SCORE_THRESHOLD} AND 'requirement_coverage' is >= {Scores.REQUIREMENT_COVERAGE_THRESHOLD}\")\n",
    "    errors: List[CritiqueError] = Field(default_factory=list, description=\"List of errors found\")\n",
    "    warnings: List[str] = Field(default_factory=list, description=\"List of warnings\")\n",
    "    missing_concepts: List[str] = Field(default_factory=list, description=\"Concepts from requirements not in diagram\")\n",
    "    reasoning: str = Field(description=\"Brief explanation for the scores provided.\")\n",
    "\n",
    "    @property\n",
    "    def weighted_score(self) -> float:\n",
    "        return (self.requirement_coverage * 0.5) + \\\n",
    "               (self.design_best_practices * 0.3) + \\\n",
    "               (self.structural_integrity * 0.2)\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def compute_validity(self) -> 'CritiqueResponse':\n",
    "        self.is_valid = (self.weighted_score > Scores.AVERAGE_SCORE_THRESHOLD) and (self.requirement_coverage >= Scores.REQUIREMENT_COVERAGE_THRESHOLD)\n",
    "        return self\n",
    "\n",
    "\n",
    "class SummaryResponse(BaseModel):\n",
    "    \"\"\"Structured output from the SUMMARIZER node.\"\"\"\n",
    "    is_complete: bool = Field(description=\"Whether all issues are resolved\")\n",
    "    fixed: List[str] = Field(default_factory=list, description=\"Issues that were fixed\")\n",
    "    unresolved: List[str] = Field(default_factory=list, description=\"Issues still present\")\n",
    "    message: str = Field(description=\"Brief status summary\")\n",
    "\n",
    "\n",
    "class PlanAudit(BaseModel):\n",
    "    is_valid: bool = Field(description=\"True if the plan is logically sound and covers all requirements.\")\n",
    "    critique: List[str] = Field(default_factory=list, description=\"List of specific logical flaws (e.g., 'Missing relationship between User and Account').\")\n",
    "    suggestions: List[str] = Field(default_factory=list, description=\"Actionable steps to fix the plan.\")\n",
    "\n",
    "\n",
    "class SystemConfig(BaseModel):\n",
    "    \"\"\"System configuration for UML generation.\"\"\"\n",
    "    lmstudio_base_url: str = Field(default=\"http://localhost:1234/v1\", description=\"LMStudio API endpoint\")\n",
    "    model_name: str = Field(default=\"mistralai/devstral-small-2-2512\", description=\"Model to use\")\n",
    "    embedder_model: str = Field(default=\"BAAI/bge-large-en-v1.5\", description=\"Embedder model for semantic search\")\n",
    "    db_path: str = Field(default=\"./../data/uml_knowledge.db\", description=\"Path to SQLite database\")\n",
    "    shots_json_path: str = Field(default=\"./../data/complete_shots.json\", description=\"Path to few-shot examples\")\n",
    "    plantuml_host: str = Field(default=\"http://localhost:8080\", description=\"PlantUML server host\")\n",
    "    max_iterations: int = Field(default=6, ge=1, description=\"Maximum workflow iterations\")\n",
    "    max_tokens_decompose: int = Field(default=1024, description=\"Max tokens for decompose step\")\n",
    "    max_tokens_generate: int = Field(default=2048, description=\"Max tokens for generate step\")\n",
    "    max_tokens_critique: int = Field(default=2048, description=\"Max tokens for critique step\")\n",
    "    max_tokens_summarize: int = Field(default=1024, description=\"Max tokens for summarize step\")\n",
    "    max_tokens_reflect: int = Field(default=2048, description=\"Max tokens for reflect step\")\n",
    "    max_tokens_compare: int = Field(default=1024, description=\"Max tokens for compare step\")\n",
    "    temperature: float = Field(default=0.15, ge=0.0, le=2.0, description=\"Base temperature for LLM\")\n",
    "    num_few_shots: int = Field(default=3, ge=0, description=\"Number of few-shot examples\")\n",
    "    request_timeout: int = Field(default=5, ge=1, description=\"Timeout for PlantUML server requests\")\n",
    "    llm_timeout: int = Field(default=120, ge=1, description=\"Timeout for LLM operations\")\n",
    "\n",
    "\n",
    "class PlantUMLResult(BaseModel):\n",
    "    \"\"\"Result from PlantUML validation.\"\"\"\n",
    "    is_valid: bool = Field(description=\"Whether the PlantUML syntax is valid\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if validation failed\")\n",
    "    url: Optional[str] = Field(default=None, description=\"URL to view the diagram\")\n",
    "    svg_url: Optional[str] = Field(default=None, description=\"URL to view the diagram as SVG\")\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Shared state for the LangGraph workflow.\n",
    "    \"\"\"\n",
    "    requirements: str\n",
    "    plan: Optional[str]\n",
    "    examples: List[Dict[str, str]]\n",
    "    current_diagram: Optional[str]\n",
    "    best_diagram: Optional[str]  \n",
    "    history: Annotated[List[Dict[str, Any]], operator.add]\n",
    "    summary: Optional[str]\n",
    "    syntax_valid: bool\n",
    "    logic_valid: bool\n",
    "    error_message: Optional[str]\n",
    "    plan_valid: bool \n",
    "    best_score: float\n",
    "    best_code: str\n",
    "    current_validation: Optional[CritiqueResponse]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b32b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm(config: Optional[SystemConfig] = None) -> ChatOpenAI:\n",
    "    \"\"\"\n",
    "    Create a ChatOpenAI instance configured for LMStudio.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Configured ChatOpenAI instance\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(f\"Connecting to LMStudio at {cfg.lmstudio_base_url}\")\n",
    "    logger.info(f\"Using model: {cfg.model_name} (temp={cfg.temperature})\")\n",
    "    \n",
    "    return ChatOpenAI(\n",
    "        base_url=cfg.lmstudio_base_url,\n",
    "        api_key=\"lm-studio\",  \n",
    "        model=cfg.model_name,\n",
    "        temperature=cfg.temperature,\n",
    "        timeout=cfg.llm_timeout \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56dcf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantUMLTool:\n",
    "    \"\"\"\n",
    "    Tool for validating and rendering PlantUML diagrams.\n",
    "    \n",
    "    This class interfaces with a PlantUML server to check syntax\n",
    "    and generate diagram URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host: str = \"http://localhost:8080\"):\n",
    "        \"\"\"\n",
    "        Initialize PlantUML tool.\n",
    "        \n",
    "        Args:\n",
    "            host: PlantUML server host URL\n",
    "        \"\"\"\n",
    "        self.host = host\n",
    "        logger.info(f\"PlantUML tool initialized with host: {host}\")\n",
    "\n",
    "    def extract_plantuml(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract PlantUML code from markdown blocks or raw text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text containing PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            Extracted PlantUML code or empty string\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Try to extract from ```plantuml ... ```\n",
    "        fence_match = re.search(r\"```\\s*plantuml\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if fence_match:\n",
    "            return fence_match.group(1).strip()\n",
    "        \n",
    "        # Try to extract from @startuml ... @enduml\n",
    "        tag_match = re.search(r\"@startuml.*?@enduml\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if tag_match:\n",
    "            return tag_match.group(0).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def _encode_plantuml(self, plantuml_code: str) -> str:\n",
    "        \"\"\"\n",
    "        Encode PlantUML code for URL.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: Raw PlantUML code\n",
    "            \n",
    "        Returns:\n",
    "            URL-safe encoded string\n",
    "        \"\"\"\n",
    "        code = plantuml_code.strip()\n",
    "        \n",
    "        if not code.startswith(\"@startuml\"): \n",
    "            code = f\"@startuml\\n{code}\"\n",
    "        if not code.endswith(\"@enduml\"): \n",
    "            code = f\"{code}\\n@enduml\"\n",
    "        \n",
    "        compressed = zlib.compress(code.encode('utf-8'))[2:-4]\n",
    "        encoded = base64.b64encode(compressed).translate(\n",
    "            bytes.maketrans(\n",
    "                b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\",\n",
    "                b\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_\"\n",
    "            )\n",
    "        ).decode('utf-8')\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "    def get_diagram_url(self, plantuml_code: str, format: str = \"png\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a viewable URL for the PlantUML diagram.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "            format: Output format (png, svg, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            URL to view the diagram\n",
    "        \"\"\"\n",
    "        diagram_code = self.extract_plantuml(plantuml_code)\n",
    "        encoded = self._encode_plantuml(diagram_code)\n",
    "        return f\"{self.host}/{format}/{encoded}\"\n",
    "        \n",
    "    def check_syntax(self, plantuml_code: str, timeout: int = 5) -> PlantUMLResult:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax with detailed error extraction.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML code to validate\n",
    "            timeout: Request timeout in seconds\n",
    "            \n",
    "        Returns:\n",
    "            PlantUMLResult with validation status and detailed error if applicable.\n",
    "        \"\"\"\n",
    "        logger.info(\"Validating PlantUML syntax\")\n",
    "        \n",
    "        try:\n",
    "            diagram_code = self.extract_plantuml(plantuml_code)\n",
    "            encoded = self._encode_plantuml(diagram_code)\n",
    "            \n",
    "            url_png = f\"{self.host}/png/{encoded}\"\n",
    "            response = requests.get(url_png, timeout=timeout)\n",
    "            \n",
    "            if response.status_code == 200 and response.content[:4] == b'\\x89PNG':\n",
    "                logger.info(\"Syntax validation passed (PNG rendered)\")\n",
    "                return PlantUMLResult(\n",
    "                    is_valid=True,\n",
    "                    url=url_png,\n",
    "                    svg_url=f\"{self.host}/svg/{encoded}\"\n",
    "                )\n",
    "            \n",
    "            logger.warning(\"PNG rendering failed. Fetching detailed syntax error...\")\n",
    "            url_txt = f\"{self.host}/txt/{encoded}\"\n",
    "            error_response = requests.get(url_txt, timeout=timeout)\n",
    "            \n",
    "            detailed_error = error_response.text.strip() if error_response.status_code == 200 else \"Unknown server error\"\n",
    "            \n",
    "            error_msg = f\"PlantUML Syntax Error:\\n{detailed_error[:1000]}\"\n",
    "            logger.error(f\"Syntax error detected: {error_msg}\")\n",
    "            \n",
    "            return PlantUMLResult(\n",
    "                is_valid=False,\n",
    "                error=error_msg\n",
    "            )\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"PlantUML Server Connection Error: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected error during syntax check: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            return PlantUMLResult(is_valid=False, error=error_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d633d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Manages long-term memory for UML diagram generation using LangChain's SQLiteVec.\n",
    "    \n",
    "    Supports semantic search to find similar past solutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedder: SentenceTransformer,\n",
    "        db_path: str = \"./../data/uml_knowledge.db\",\n",
    "        embedding_dims: int = 1024\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize memory manager with LangChain SQLiteVec.\n",
    "        \n",
    "        Args:\n",
    "            embedder: SentenceTransformer model for semantic search\n",
    "            db_path: Path to the SQLite database file\n",
    "            embedding_dims: Dimensions of the embeddings \n",
    "        \"\"\"\n",
    "        self.embedder = embedder\n",
    "        self.db_path = db_path\n",
    "        self.embedding_dims = embedding_dims\n",
    "        \n",
    "\n",
    "        self.embedding_function = HuggingFaceEmbeddings(\n",
    "            model_name=embedder.model_name if hasattr(embedder, 'model_name') else \"BAAI/bge-large-en-v1.5\",\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Create directory and connection\n",
    "        os.makedirs(os.path.dirname(self.db_path) if os.path.dirname(self.db_path) else \".\", exist_ok=True)\n",
    "        \n",
    "        # Create connection using SQLiteVec's method\n",
    "        self.connection = SQLiteVec.create_connection(db_file=self.db_path)\n",
    "        \n",
    "        # Initialize vector store with connection\n",
    "        self.vector_store = SQLiteVec(\n",
    "            table=\"uml_memories\",\n",
    "            connection=self.connection,\n",
    "            embedding=self.embedding_function\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"MemoryManager initialized with LangChain SQLiteVec at {db_path} (dims={embedding_dims})\")\n",
    "\n",
    "    def save_diagram(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        diagram: str,\n",
    "        metadata: Optional[Dict[str, Any]] = None\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Save a validated diagram to SQLite long-term memory.\n",
    "                \n",
    "        Args:\n",
    "            requirements: Original requirements text\n",
    "            diagram: PlantUML diagram code\n",
    "            metadata: Optional metadata\n",
    "            \n",
    "        Returns:\n",
    "            ID of the stored record\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        full_metadata = metadata or {}\n",
    "        full_metadata.update({\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "        \n",
    "\n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=full_metadata\n",
    "        )\n",
    "        \n",
    "        ids = self.vector_store.add_documents([doc])\n",
    "        \n",
    "        logger.info(\"Diagram saved to SQLite memory using LangChain SQLiteVec\")\n",
    "        return ids[0] if ids else 0\n",
    "    \n",
    "    def retrieve_similar_diagrams(\n",
    "        self,\n",
    "        requirements: str,\n",
    "        limit: int = 2\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve similar diagrams from SQLite memory using vector search.\n",
    "        \n",
    "        Args:\n",
    "            requirements: Requirements text to search for\n",
    "            limit: Maximum number of results\n",
    "            \n",
    "        Returns:\n",
    "            List of similar diagram records\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.vector_store.similarity_search(requirements, k=limit)\n",
    "            \n",
    "            diagrams = []\n",
    "            for doc in results:\n",
    "                diagrams.append({\n",
    "                    \"requirements\": doc.page_content,\n",
    "                    \"diagram\": doc.metadata.get(\"diagram\", \"\"),\n",
    "                    \"timestamp\": doc.metadata.get(\"timestamp\", \"\"),\n",
    "                    \"metadata\": {k: v for k, v in doc.metadata.items() \n",
    "                                if k not in [\"diagram\", \"timestamp\"]}\n",
    "                })\n",
    "                \n",
    "            logger.info(f\"Retrieved {len(diagrams)} similar diagrams from SQLite\")\n",
    "            return diagrams\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Memory retrieval failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clear_memory(self) -> None:\n",
    "        try:\n",
    "            # Close existing connection\n",
    "            if hasattr(self, 'connection'):\n",
    "                self.connection.close()\n",
    "            \n",
    "            # Remove database file\n",
    "            if os.path.exists(self.db_path):\n",
    "                os.remove(self.db_path)\n",
    "            \n",
    "            # Recreate connection and vector store\n",
    "            self.connection = SQLiteVec.create_connection(db_file=self.db_path)\n",
    "            self.vector_store = SQLiteVec(\n",
    "                table=\"uml_memories\",\n",
    "                connection=self.connection,\n",
    "                embedding=self.embedding_function\n",
    "            )\n",
    "\n",
    "            logger.info(\"Memory cleared and reinitialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to clear memory: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "156ecfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_memory_from_shots(\n",
    "    memory_manager: MemoryManager,\n",
    "    shots_json_path: str = \"./../data/complete_shots.json\",\n",
    "    force_reseed: bool = False\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Seed the memory database with few-shot examples from JSON file.\n",
    "    Skips seeding if database already contains data (unless force_reseed=True).\n",
    "    \n",
    "    Args:\n",
    "        memory_manager: MemoryManager instance to seed\n",
    "        shots_json_path: Path to the complete_shots.json file\n",
    "        force_reseed: If True, clears existing data and reseeds\n",
    "        \n",
    "    Returns:\n",
    "        Number of shots seeded (0 if skipped)\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"CHECKING MEMORY SEEDING STATUS\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    # Check if database already has data\n",
    "    try:\n",
    "        existing_docs = memory_manager.vector_store.similarity_search(\"test\", k=1)\n",
    "        if existing_docs and not force_reseed:\n",
    "            logger.info(f\"Database already contains data ({len(existing_docs)} docs found)\")\n",
    "            logger.info(\"Skipping seeding operation. Set force_reseed=True to override.\")\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Database appears empty or uninitialized: {e}\")\n",
    "    \n",
    "    if force_reseed:\n",
    "        logger.warning(\"Force reseed enabled - clearing existing memory\")\n",
    "        memory_manager.clear_memory()\n",
    "    \n",
    "\n",
    "    if not os.path.exists(shots_json_path):\n",
    "        logger.error(f\"Shots file not found at {shots_json_path}\")\n",
    "        return 0\n",
    "    \n",
    "    logger.info(f\"Loading shots from {shots_json_path}\")\n",
    "    with open(shots_json_path, 'r', encoding='utf-8') as f:\n",
    "        shots = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Found {len(shots)} shots to seed\")\n",
    "    \n",
    "    # Prepare documents\n",
    "    documents = []\n",
    "    for shot in shots:\n",
    "        requirements = shot[\"requirements\"]\n",
    "        diagram = shot[\"solution_plantuml\"]\n",
    "        \n",
    "        metadata = {\n",
    "            \"diagram\": diagram,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"plan\": shot.get(\"subgoal_decomposition\"),\n",
    "            \"reasoning\": shot.get(\"chain_of_thought\"),\n",
    "            \"is_static\": True,\n",
    "            \"title\": shot.get(\"title\", \"Untitled\")\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"  Processing: {metadata['title']}\")\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=requirements,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    if documents:\n",
    "        memory_manager.vector_store.add_documents(documents)\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"âœ“ Successfully seeded {len(documents)} shots to memory\")\n",
    "        logger.info(\"=\"*60)\n",
    "        return len(documents)\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7182a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMLNodes:\n",
    "    \"\"\"\n",
    "    Collection of agent nodes for the UML generation workflow.\n",
    "    \n",
    "    Each method represents a node in the LangGraph workflow and\n",
    "    follows the pattern of taking AgentState and returning a dict\n",
    "    with state updates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: ChatOpenAI,\n",
    "        plantuml_tool: PlantUMLTool,\n",
    "        memory_manager: Optional['MemoryManager'] = None,\n",
    "        config: Optional[SystemConfig] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize UML nodes with required dependencies.\n",
    "        \n",
    "        Args:\n",
    "            llm: LangChain ChatOpenAI instance\n",
    "            plantuml_tool: Tool for PlantUML validation\n",
    "            memory_manager: long-term memory manager\n",
    "            config: Optional system configuration\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.plantuml_tool = plantuml_tool\n",
    "        self.memory_manager = memory_manager\n",
    "        self.config = config or SystemConfig()\n",
    "        logger.info(\"UMLNodes initialized\")\n",
    "\n",
    "    def _safe_invoke(self, runnable: Any, input_data: Any, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Invoke a runnable (LLM or chain) with retry logic.\n",
    "        \"\"\"\n",
    "        max_retries = 3\n",
    "        last_exception = None\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return runnable.invoke(input_data, **kwargs)\n",
    "            except Exception as e:\n",
    "                last_exception = e\n",
    "                logger.warning(f\"LLM call failed (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 * (attempt + 1))\n",
    "        \n",
    "        logger.error(f\"Max retries reached for LLM call: {last_exception}\")\n",
    "        raise last_exception\n",
    "\n",
    "    def retrieve(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant few-shot examples based on requirements.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'examples' key containing formatted shots\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.RETRIEVE.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            memories = self.memory_manager.retrieve_similar_diagrams(\n",
    "                state[\"requirements\"],\n",
    "                limit=self.config.num_few_shots\n",
    "            )\n",
    "            \n",
    "            formatted_shots = []\n",
    "            for mem in memories:\n",
    "                formatted_shots.append(\n",
    "                    HumanMessage(content=f\"Requirements:\\n{mem['requirements']}\")\n",
    "                )\n",
    "                \n",
    "                meta = mem.get(\"metadata\", {})\n",
    "                plan = meta.get(\"plan\", \"No plan available.\")\n",
    "                reasoning = meta.get(\"reasoning\", \"No reasoning available.\")\n",
    "                \n",
    "                assistant_content = (\n",
    "                    f\"1. DESIGN PLAN:\\n{plan}\\n\\n\"\n",
    "                    f\"2. DESIGN REASONING:\\n{reasoning}\\n\\n\"\n",
    "                    f\"3. PLANTUML DIAGRAM:\\n```plantuml\\n{mem['diagram']}\\n```\"\n",
    "                )\n",
    "                \n",
    "                formatted_shots.append(\n",
    "                    AIMessage(content=assistant_content)\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"Retrieved {len(memories)} relevant examples from unified memory\")\n",
    "            return {\"examples\": formatted_shots}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Retrieval failed: {e}\")\n",
    "            return {\"examples\": []}\n",
    "\n",
    "    def decompose(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Decompose requirements into structural building blocks.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'plan' key containing decomposition\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.DECOMPOSE.upper()} ---\")\n",
    "\n",
    "        feedback = state.get(\"audit_feedback\", [])\n",
    "        feedback_str = \"\\n\".join([f\"- {f}\" for f in feedback]) if feedback else \"None\"\n",
    "\n",
    "        system_prompt = DECOMPOSER_SYSTEM\n",
    "        if feedback:\n",
    "            system_prompt += f\"\\n\\nIMPORTANT: Your previous plan was rejected. Fix these issues:\\n{feedback_str}\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=f\"REQUIREMENTS:\\n{state['requirements']}\")\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_decompose\n",
    "            )\n",
    "            logger.info(\"Decomposition completed\")\n",
    "            return {\"plan\": response.content}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Decomposition failed: {e}\")\n",
    "            return {\"plan\": f\"Error: {str(e)}\"}\n",
    "\n",
    "    def logic_auditor(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Audits the structural plan for logical consistency and requirement coverage.\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.PLAN_AUDIT.upper()} ---\")\n",
    "        \n",
    "        plan = state.get(\"plan\")\n",
    "        requirements = state.get(\"requirements\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Senior Software Architect auditing a UML Class Diagram plan.\n",
    "        \n",
    "        REQUIREMENTS:\n",
    "        {requirements}\n",
    "        \n",
    "        PROPOSED PLAN (JSON):\n",
    "        {plan}\n",
    "        \n",
    "        YOUR TASK:\n",
    "        1. Check for 'Island Classes' (classes with no relationships).\n",
    "        2. Ensure all entities mentioned in the requirements exist in the plan.\n",
    "        3. Check for relationship directionality (e.g., should 'User' own 'Order'?).\n",
    "        4. Verify that attributes have appropriate types.\n",
    "        \n",
    "        If the plan is flawed, be specific about what is missing.\n",
    "        \"\"\"\n",
    "        \n",
    "        audit_result = self.llm.with_structured_output(PlanAudit).invoke([\n",
    "            SystemMessage(content=\"You are a Senior Software Architect auditing a UML Class Diagram plan.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"plan_valid\": audit_result.is_valid,\n",
    "            \"audit_feedback\": audit_result.critique + audit_result.suggestions,\n",
    "            \"iterations\": state[\"iterations\"] + (0 if audit_result.is_valid else 1)\n",
    "        }\n",
    "\n",
    "    def generate(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate PlantUML diagram using chain-of-thought reasoning.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.GENERATE.upper()} ---\")\n",
    "        \n",
    "        messages = [SystemMessage(content=GENERATOR_SYSTEM)]\n",
    "        \n",
    "        # Add few-shot examples if available\n",
    "        if state.get(\"examples\"):\n",
    "            messages.extend(state[\"examples\"])\n",
    "            logger.debug(f\"Added {len(state['examples'])} example messages\")\n",
    "            \n",
    "        user_content = f\"\"\"\n",
    "        # ORIGINAL REQUIREMENTS\n",
    "        {state['requirements']}\n",
    "\n",
    "        # DESIGN PLAN\n",
    "        {state['plan']}\n",
    "\n",
    "        # TASK\n",
    "        Follow the examples above exactly. Output your response in three parts:\n",
    "        1. DESIGN PLAN: (Briefly refine the plan for implementation)\n",
    "        2. DESIGN REASONING: (Explain your choice of relationships and cardinality)\n",
    "        3. PLANTUML DIAGRAM: (The code block)\n",
    "        \"\"\"\n",
    "        \n",
    "        messages.append(HumanMessage(content=user_content))\n",
    "        \n",
    "        try:\n",
    "            response = self._safe_invoke(\n",
    "                self.llm,\n",
    "                messages,\n",
    "                max_tokens=self.config.max_tokens_generate\n",
    "            )\n",
    "            diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "            \n",
    "            logger.info(f\"Generation completed (iteration {state['iterations'] + 1})\")\n",
    "            return {\n",
    "                \"current_diagram\": diagram,\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Generation failed: {e}\")\n",
    "            return {\n",
    "                \"current_diagram\": f\"Error: {str(e)}\",\n",
    "                \"iterations\": state[\"iterations\"] + 1\n",
    "            }\n",
    "\n",
    "    def syntax_check(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate PlantUML syntax through server.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'syntax_valid' and optional 'error_message'\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SYNTAX_CHECK.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            result = self.plantuml_tool.check_syntax(\n",
    "                state[\"current_diagram\"],\n",
    "                timeout=self.config.request_timeout\n",
    "            )\n",
    "            \n",
    "            if result.is_valid:\n",
    "                logger.info(f\"Syntax valid. View at: {result.url}\")\n",
    "            else:\n",
    "                logger.warning(f\"Syntax error: {result.error}\")\n",
    "            \n",
    "            return {\n",
    "                \"syntax_valid\": result.is_valid,\n",
    "                \"error_message\": result.error if not result.is_valid else None,\n",
    "                \"iterations\": state[\"iterations\"] + (0 if result.is_valid else 1)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Syntax check failed: {e}\")\n",
    "            return {\n",
    "                \"syntax_valid\": False,\n",
    "                \"error_message\": f\"Syntax check error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def _validate_diagram(self, requirements: str, diagram: str) -> CritiqueResponse:\n",
    "        \"\"\"\n",
    "        Helper method to validate a diagram and return the structured response.\n",
    "        Used by both critic node and reflect node (for rollback decision).\n",
    "        \"\"\"\n",
    "        plantuml_only = self.plantuml_tool.extract_plantuml(diagram)\n",
    "        user_msg = f\"\"\"\n",
    "        # REQUIREMENTS\n",
    "        {requirements}\n",
    "\n",
    "        # DIAGRAM\n",
    "        {plantuml_only}\n",
    "\n",
    "        Audit the diagram thoroughly and provide the scoring report.\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=CRITIC_SYSTEM),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "        \n",
    "        structured_llm = self.llm.with_structured_output(CritiqueResponse)\n",
    "        return self._safe_invoke(structured_llm, messages)\n",
    "\n",
    "    def critic(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform logical validation of the UML diagram.\n",
    "                \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'logic_valid' and 'history' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.CRITIC.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            critique_response = self._validate_diagram(state['requirements'], state[\"current_diagram\"])\n",
    "            \n",
    "            weighted = critique_response.weighted_score\n",
    "            \n",
    "            critique = {\n",
    "                \"is_valid\": critique_response.is_valid,\n",
    "                \"requirement_coverage\": critique_response.requirement_coverage,\n",
    "                \"design_best_practices\": critique_response.design_best_practices,\n",
    "                \"structural_integrity\": critique_response.structural_integrity,\n",
    "                \"weighted_score\": weighted,\n",
    "                \"errors\": [{\"type\": err.type, \"description\": err.description} \n",
    "                          for err in critique_response.errors],\n",
    "                \"warnings\": critique_response.warnings,\n",
    "                \"missing_concepts\": critique_response.missing_concepts,\n",
    "                \"reasoning\": critique_response.reasoning\n",
    "            }\n",
    "            \n",
    "            is_valid = critique_response.is_valid\n",
    "            logger.info(f\"Logic validation: {'PASSED' if is_valid else 'FAILED'} (Weighted Score: {weighted:.2f})\")\n",
    "            logger.info(f\"  Requirements Coverage: {critique_response.requirement_coverage:.2f}/10\")\n",
    "            logger.info(f\"  Design Best Practices: {critique_response.design_best_practices:.2f}/10\")\n",
    "            logger.info(f\"  Structural Integrity: {critique_response.structural_integrity:.2f}/10\")\n",
    "            \n",
    "            if not is_valid and critique_response.errors:\n",
    "                logger.info(f\"Found {len(critique_response.errors)} errors\")\n",
    "            \n",
    "            updates = {\n",
    "                \"logic_valid\": is_valid,\n",
    "                \"history\": [critique]  + state.get(\"history\", []),\n",
    "                \"current_validation\": critique_response\n",
    "            }\n",
    "            \n",
    "            if is_valid and not state.get(\"best_diagram\"):\n",
    "                logger.info(f\"Storing first valid diagram as best\")\n",
    "                updates[\"best_diagram\"] = state[\"current_diagram\"]\n",
    "            \n",
    "            return updates\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critic failed: {e}\")\n",
    "            return {\n",
    "                \"logic_valid\": False,\n",
    "                \"history\": [{\n",
    "                    \"is_valid\": False,\n",
    "                    \"requirement_coverage\": 0.0,\n",
    "                    \"design_best_practices\": 0.0,\n",
    "                    \"structural_integrity\": 0.0,\n",
    "                    \"weighted_score\": 0.0,\n",
    "                    \"errors\": [{\"type\": \"system\", \"description\": str(e)}],\n",
    "                    \"warnings\": [],\n",
    "                    \"missing_concepts\": [],\n",
    "                    \"reasoning\": \"System error during critique.\"\n",
    "                }]\n",
    "            }\n",
    "\n",
    "    def summarize_memory(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Summarize progress by comparing current and previous critiques.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'summary' key containing JSON string\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.SUMMARIZE.upper()} ---\")\n",
    "        \n",
    "        if not state.get(\"history\"):\n",
    "            logger.info(\"No history to summarize\")\n",
    "            return {\"summary\": json.dumps({\"is_complete\": False, \"message\": \"No history\"})}\n",
    "        \n",
    "        current_critique = state[\"history\"][-1]\n",
    "        \n",
    "        # Only look at the last 2 previous critiques to save tokens\n",
    "        # sending the full history causes context overflow in later iterations\n",
    "        previous_critiques = state[\"history\"][-3:-1] if len(state[\"history\"]) > 1 else []\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        CURRENT CRITIQUE (Issues in the latest diagram):\n",
    "        {json.dumps(current_critique)}\n",
    "        \n",
    "        PREVIOUS CRITIQUES (Recent history):\n",
    "        {json.dumps(previous_critiques)}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=SUMMARIZER_SYSTEM),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            structured_llm = self.llm.with_structured_output(SummaryResponse)\n",
    "            summary_response: SummaryResponse = self._safe_invoke(structured_llm, messages)\n",
    "            \n",
    "            summary = {\n",
    "                \"is_complete\": summary_response.is_complete,\n",
    "                \"fixed\": summary_response.fixed,\n",
    "                \"unresolved\": summary_response.unresolved,\n",
    "                \"message\": summary_response.message\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Summary: {summary_response.message}\")\n",
    "            return {\"summary\": json.dumps(summary)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Summarization failed: {e}\")\n",
    "            return {\"summary\": json.dumps({\n",
    "                \"is_complete\": False,\n",
    "                \"fixed\": [],\n",
    "                \"unresolved\": [],\n",
    "                \"message\": f\"Error: {str(e)}\"\n",
    "            })}\n",
    "\n",
    "    def reflect(self, state: AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fix diagram based on memory summary and error history.\n",
    "        Implements internal retry loop with dynamic temperature to escape local optima.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'current_diagram' and 'iterations' updates\n",
    "        \"\"\"\n",
    "        logger.info(f\"--- NODE: {NodeNames.REFLECT.upper()} ---\")\n",
    "\n",
    "        last_critique = state[\"history\"][-1]\n",
    "        prev_score = last_critique.get(\"weighted_score\", 0)\n",
    "        old_diagram = state['current_diagram']\n",
    "        \n",
    "        if prev_score < 7.0:\n",
    "            tone_instruction = (\n",
    "                \"The design is fundamentally wrong. You MUST:\\n\"\n",
    "                f\"1. Re-examine these missing concepts: {last_critique.get('missing_concepts')}\\n\"\n",
    "                \"2. Question your class boundaries\\n\"\n",
    "                \"3. Verify every relationship direction\\n\"\n",
    "            )\n",
    "        elif prev_score < 8.0:\n",
    "            tone_instruction = (\n",
    "                \"You're close but need targeted fixes:\\n\"\n",
    "                f\"1. Focus ONLY on: {summary_json.get('unresolved')[:3]}\\n\"\n",
    "                \"2. Don't touch working parts\\n\"\n",
    "            )\n",
    "\n",
    "        summary_json = json.loads(state[\"summary\"])\n",
    "        summary_text = (\n",
    "            f\"Message: {summary_json.get('message', '')}\\n\"\n",
    "            f\"Unresolved Issues: {', '.join(summary_json.get('unresolved', []))}\"\n",
    "        )\n",
    "\n",
    "        base_user_msg = f\"\"\"\n",
    "        {tone_instruction}\n",
    "        \n",
    "        [QUALITY SCORE]: {prev_score}/10\n",
    "        [ERRORS TO FIX]:\n",
    "        {summary_text}\n",
    "        \n",
    "        [MISSING CONCEPTS]: {last_critique.get('missing_concepts', [])}\n",
    "        \n",
    "        [CURRENT CODE]:\n",
    "        {old_diagram}\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=REFLECTOR_SYSTEM),\n",
    "            HumanMessage(content=base_user_msg)\n",
    "        ]\n",
    "\n",
    "        \n",
    "        max_retries = 2 \n",
    "        current_temp = self.config.temperature\n",
    "        \n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                logger.info(f\"Reflection attempt {attempt+1}/{max_retries+1} (temp={current_temp:.2f})\")\n",
    "                \n",
    "                response = self._safe_invoke(\n",
    "                    self.llm,\n",
    "                    messages,\n",
    "                    max_tokens=self.config.max_tokens_reflect\n",
    "                )\n",
    "                new_diagram = self.plantuml_tool.extract_plantuml(response.content)\n",
    "\n",
    "\n",
    "                if new_diagram.strip() == old_diagram.strip():\n",
    "                    logger.warning(\"Generated identical diagram.\")\n",
    "                    if attempt < max_retries:\n",
    "                        messages.append(HumanMessage(content=\"You returned the exact same diagram. You MUST change it to fix the errors. Try again.\"))\n",
    "                        current_temp = min(1.0, current_temp + 0.2)\n",
    "                        continue\n",
    "                    else:\n",
    "                        break \n",
    "\n",
    "                new_validation = self._validate_diagram(state['requirements'], new_diagram)\n",
    "                new_score = new_validation.weighted_score\n",
    "                \n",
    "                logger.info(f\"Attempt {attempt+1} Score: {new_score:.2f} (Previous: {prev_score:.2f})\")\n",
    "\n",
    "                if new_score >= prev_score:\n",
    "                    logger.info(f\"Improvement found! ({new_score:.2f} >= {prev_score:.2f})\")\n",
    "                    return {\n",
    "                        \"current_diagram\": new_diagram,\n",
    "                        \"iterations\": state[\"iterations\"] + 1,\n",
    "                    }\n",
    "                \n",
    "\n",
    "                logger.warning(f\"Score dropped to {new_score:.2f}. Retrying...\")\n",
    "                \n",
    "                if attempt < max_retries:\n",
    "                    messages.append(HumanMessage(content=f\"\"\"\n",
    "                    Your previous attempt resulted in a LOWER score ({new_score:.2f} < {prev_score:.2f}).\n",
    "                    The changes you made introduced new issues.\n",
    "                    Undo those bad changes and try a different approach to fix the original errors.\n",
    "                    \"\"\"))\n",
    "                    current_temp = min(1.0, current_temp + 0.1)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Reflection attempt {attempt+1} failed: {e}\")\n",
    "        \n",
    "        logger.warning(\"All reflection attempts failed to improve score. Rolling back to old diagram.\")\n",
    "        \n",
    "\n",
    "        recent_history = state.get(\"history\", [])[-4:]\n",
    "        if len(recent_history) >= 3:\n",
    "             last_scores = [h.get(\"weighted_score\", 0) for h in recent_history[-2:]]\n",
    "             if len(set(last_scores)) == 1:\n",
    "                 logger.warning(\"Score plateau detected. Stopping.\")\n",
    "                 return {\n",
    "                     \"current_diagram\": old_diagram,\n",
    "                     \"iterations\": self.config.max_iterations \n",
    "                 }\n",
    "\n",
    "        return {\n",
    "            \"current_diagram\": old_diagram,\n",
    "            \"iterations\": state[\"iterations\"] + 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12124ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uml_graph(\n",
    "    nodes: UMLNodes, \n",
    "    config: Optional[SystemConfig] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Create the LangGraph workflow for UML diagram generation.\n",
    "    \n",
    "    Args:\n",
    "        nodes: UMLNodes instance with all agent methods\n",
    "        config: Optional system configuration\n",
    "        \n",
    "    Returns:\n",
    "        Compiled LangGraph workflow\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"Creating UML generation workflow\")\n",
    "    \n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add all nodes\n",
    "    workflow.add_node(NodeNames.RETRIEVE, nodes.retrieve)\n",
    "    workflow.add_node(NodeNames.PLAN_AUDIT, nodes.logic_auditor)\n",
    "    workflow.add_node(NodeNames.DECOMPOSE, nodes.decompose)\n",
    "    workflow.add_node(NodeNames.GENERATE, nodes.generate)\n",
    "    workflow.add_node(NodeNames.SYNTAX_CHECK, nodes.syntax_check)\n",
    "    workflow.add_node(NodeNames.CRITIC, nodes.critic)\n",
    "    workflow.add_node(NodeNames.SUMMARIZE, nodes.summarize_memory)\n",
    "    workflow.add_node(NodeNames.REFLECT, nodes.reflect)\n",
    "    \n",
    "    logger.debug(\"Added 7 nodes to workflow\")\n",
    "\n",
    "    # Define edges\n",
    "    workflow.add_edge(START, NodeNames.RETRIEVE)\n",
    "    workflow.add_edge(NodeNames.RETRIEVE, NodeNames.DECOMPOSE)\n",
    "    workflow.add_edge(NodeNames.DECOMPOSE, NodeNames.PLAN_AUDIT)\n",
    "\n",
    "    def route_after_plan_audit(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on plan audit results.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"plan_valid\"]:\n",
    "            logger.debug(\"Routing: plan_audit -> generate\")\n",
    "            return NodeNames.GENERATE\n",
    "            \n",
    "        logger.debug(\"Routing: plan_audit -> decompose\")\n",
    "        return NodeNames.DECOMPOSE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.PLAN_AUDIT, \n",
    "        route_after_plan_audit,\n",
    "        {\n",
    "            NodeNames.DECOMPOSE: NodeNames.DECOMPOSE,\n",
    "            NodeNames.GENERATE: NodeNames.GENERATE\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(NodeNames.GENERATE, NodeNames.SYNTAX_CHECK)\n",
    "\n",
    "    def route_after_syntax_check(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on syntax validation results and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"syntax_valid\"]:\n",
    "            logger.debug(\"Routing: syntax_check -> critic\")\n",
    "            return NodeNames.CRITIC\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached during syntax check\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: syntax_check -> reflect\")\n",
    "        return NodeNames.REFLECT\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.SYNTAX_CHECK, \n",
    "        route_after_syntax_check,\n",
    "        {\n",
    "            NodeNames.CRITIC: NodeNames.CRITIC,\n",
    "            NodeNames.REFLECT: NodeNames.REFLECT,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def is_logic_valid(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route based on logic validation and iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name or END\n",
    "        \"\"\"\n",
    "        if state[\"logic_valid\"]:\n",
    "            logger.info(\"Diagram validated successfully\")\n",
    "            return END\n",
    "            \n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: critic -> summarize\")\n",
    "        return NodeNames.SUMMARIZE\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.CRITIC, \n",
    "        is_logic_valid,\n",
    "        {\n",
    "            END: END,\n",
    "            NodeNames.SUMMARIZE: NodeNames.SUMMARIZE\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(NodeNames.SUMMARIZE, NodeNames.REFLECT)\n",
    "\n",
    "    def route_after_reflect(state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Route after reflection based on iteration limits.\n",
    "        \n",
    "        Args:\n",
    "            state: Current workflow state\n",
    "            \n",
    "        Returns:\n",
    "            Next node name\n",
    "        \"\"\"\n",
    "        if state[\"iterations\"] >= cfg.max_iterations:\n",
    "            logger.warning(f\"Max iterations ({cfg.max_iterations}) reached after reflection\")\n",
    "            return END\n",
    "            \n",
    "        logger.debug(\"Routing: reflect -> syntax_check\")\n",
    "        return NodeNames.SYNTAX_CHECK\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        NodeNames.REFLECT, \n",
    "        route_after_reflect,\n",
    "        {\n",
    "            NodeNames.SYNTAX_CHECK: NodeNames.SYNTAX_CHECK,\n",
    "            END: END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Workflow graph created successfully\")\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def create_initial_state(requirements: str) -> AgentState:\n",
    "    \"\"\"\n",
    "    Create an initial state for the workflow.\n",
    "    \n",
    "    Args:\n",
    "        requirements: Software requirements text\n",
    "        \n",
    "    Returns:\n",
    "        Initial AgentState dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"requirements\": requirements,\n",
    "        \"plan\": None,\n",
    "        \"examples\": [],\n",
    "        \"current_diagram\": None,\n",
    "        \"best_diagram\": None,\n",
    "        \"history\": [],\n",
    "        \"summary\": None,\n",
    "        \"syntax_valid\": False,\n",
    "        \"logic_valid\": False,\n",
    "        \"iterations\": 0,\n",
    "        \"error_message\": None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549e0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 12:36:04,114 - __main__ - INFO - Loading test exercises from ./../data/test_exercises.json\n",
      "2026-01-10 12:36:04,115 - __main__ - INFO - Loaded 8 test exercises\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 test exercises\n"
     ]
    }
   ],
   "source": [
    "def load_test_exercises(json_path: str = \"./../data/test_exercises.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load test exercises from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to test exercises JSON\n",
    "        \n",
    "    Returns:\n",
    "        List of exercise dictionaries\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        json.JSONDecodeError: If JSON is invalid\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading test exercises from {json_path}\")\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Test exercises file not found: {json_path}\")\n",
    "    \n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        exercises = json.load(f)\n",
    "    \n",
    "    logger.info(f\"Loaded {len(exercises)} test exercises\")\n",
    "    return exercises\n",
    "\n",
    "try:\n",
    "    test_exercises = load_test_exercises()\n",
    "    print(f\"Loaded {len(test_exercises)} test exercises\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load test exercises: {e}\")\n",
    "    test_exercises = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e53188a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 12:36:04,130 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:04,131 - __main__ - INFO - INITIALIZING UML GENERATION SYSTEM\n",
      "2026-01-10 12:36:04,132 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:04,133 - __main__ - INFO - Creating LLM connection...\n",
      "2026-01-10 12:36:04,134 - __main__ - INFO - Connecting to LMStudio at http://localhost:1234/v1\n",
      "2026-01-10 12:36:04,134 - __main__ - INFO - Using model: mistralai/devstral-small-2-2512 (temp=0.15)\n",
      "2026-01-10 12:36:04,141 - __main__ - INFO - Initializing PlantUML tool...\n",
      "2026-01-10 12:36:04,141 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n",
      "2026-01-10 12:36:04,142 - __main__ - INFO - Initializing long-term memory with BAAI/bge-large-en-v1.5...\n",
      "2026-01-10 12:36:04,150 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "2026-01-10 12:36:04,150 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2026-01-10 12:36:04,488 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:04,553 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:04,706 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:04,794 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:04,954 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:04,994 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:05,161 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:05,194 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:05,353 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:05,393 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:05,561 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:05,620 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:05,798 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-10 12:36:05,954 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:06,000 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2fd976c1d049839ba2052e063ebbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: BAAI/bge-large-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "2026-01-10 12:36:06,462 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:06,519 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:06,911 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-10 12:36:07,084 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:07,334 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:07,373 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:07,558 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5 \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:14,162 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2026-01-10 12:36:14,592 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:14,632 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:14,793 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:14,833 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:14,991 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:15,033 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:15,199 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:15,241 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/README.md \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:15,431 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:15,482 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/modules.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:15,645 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:15,711 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:15,874 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-10 12:36:16,034 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:16,081 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5da5869228a40f4917f40836ecac01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: BAAI/bge-large-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "2026-01-10 12:36:16,549 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:16,602 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:16,799 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-01-10 12:36:16,957 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:17,225 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BAAI/bge-large-en-v1.5/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-01-10 12:36:17,283 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BAAI/bge-large-en-v1.5/d4aa6901d3a41ba39fb536a557fa166f842b0e09/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:17,483 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/BAAI/bge-large-en-v1.5 \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:36:21,391 - __main__ - INFO - MemoryManager initialized with LangChain SQLiteVec at ./../data/uml_knowledge.db (dims=1024)\n",
      "2026-01-10 12:36:21,393 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:21,393 - __main__ - INFO - CHECKING MEMORY SEEDING STATUS\n",
      "2026-01-10 12:36:21,393 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:21,541 - __main__ - WARNING - Force reseed enabled - clearing existing memory\n",
      "2026-01-10 12:36:21,624 - __main__ - INFO - Memory cleared and reinitialized\n",
      "2026-01-10 12:36:21,624 - __main__ - INFO - Loading shots from ./../data/complete_shots.json\n",
      "2026-01-10 12:36:21,625 - __main__ - INFO - Found 20 shots to seed\n",
      "2026-01-10 12:36:21,626 - __main__ - INFO -   Processing: Project Management System\n",
      "2026-01-10 12:36:21,626 - __main__ - INFO -   Processing: Hollywood Approach\n",
      "2026-01-10 12:36:21,626 - __main__ - INFO -   Processing: Word Processor\n",
      "2026-01-10 12:36:21,627 - __main__ - INFO -   Processing: Patient Record and Scheduling\n",
      "2026-01-10 12:36:21,627 - __main__ - INFO -   Processing: Movie-Shop\n",
      "2026-01-10 12:36:21,628 - __main__ - INFO -   Processing: Flights\n",
      "2026-01-10 12:36:21,628 - __main__ - INFO -   Processing: Bank System\n",
      "2026-01-10 12:36:21,628 - __main__ - INFO -   Processing: Veterinary Clinic\n",
      "2026-01-10 12:36:21,629 - __main__ - INFO -   Processing: Auto Repair\n",
      "2026-01-10 12:36:21,629 - __main__ - INFO -   Processing: Restaurant\n",
      "2026-01-10 12:36:21,630 - __main__ - INFO -   Processing: Deliveries\n",
      "2026-01-10 12:36:21,630 - __main__ - INFO -   Processing: Furniture Factory Management\n",
      "2026-01-10 12:36:21,630 - __main__ - INFO -   Processing: Industrial Factory Operations\n",
      "2026-01-10 12:36:21,631 - __main__ - INFO -   Processing: Bycicle Rental\n",
      "2026-01-10 12:36:21,631 - __main__ - INFO -   Processing: Car Park Access System\n",
      "2026-01-10 12:36:21,631 - __main__ - INFO -   Processing: Banking Organizational Structure\n",
      "2026-01-10 12:36:21,632 - __main__ - INFO -   Processing: Prepaid Cell Phone (Decorator Pattern)\n",
      "2026-01-10 12:36:21,632 - __main__ - INFO -   Processing: Library Management System\n",
      "2026-01-10 12:36:21,632 - __main__ - INFO -   Processing: MyDoctor Appointment Management\n",
      "2026-01-10 12:36:21,633 - __main__ - INFO -   Processing: Online Shopping System\n",
      "2026-01-10 12:36:27,819 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:27,821 - __main__ - INFO - âœ“ Successfully seeded 20 shots to memory\n",
      "2026-01-10 12:36:27,821 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:27,821 - __main__ - INFO - Long-term memory (SQLite + sqlite-vec) enabled\n",
      "2026-01-10 12:36:27,822 - __main__ - INFO - Seeded 20 few-shot examples into memory\n",
      "2026-01-10 12:36:27,822 - __main__ - INFO - Building LangGraph workflow...\n",
      "2026-01-10 12:36:27,822 - __main__ - INFO - UMLNodes initialized\n",
      "2026-01-10 12:36:27,822 - __main__ - INFO - Creating UML generation workflow\n",
      "2026-01-10 12:36:27,842 - __main__ - INFO - Workflow graph created successfully\n",
      "2026-01-10 12:36:27,858 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:27,858 - __main__ - INFO - SYSTEM INITIALIZED SUCCESSFULLY\n",
      "2026-01-10 12:36:27,859 - __main__ - INFO - ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready for diagram generation\n",
      "Long-term memory: ENABLED\n"
     ]
    }
   ],
   "source": [
    "def initialize_system(\n",
    "    config: Optional[SystemConfig] = None,\n",
    "    enable_long_term_memory: bool = True\n",
    ") -> Tuple[UMLNodes, Any, SystemConfig, Optional[MemoryManager]]:\n",
    "    \"\"\"\n",
    "    Initialize all system components.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional system configuration\n",
    "        enable_long_term_memory: Whether to enable long-term memory\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (nodes, compiled_workflow, config, memory_manager)\n",
    "    \"\"\"\n",
    "    cfg = config or SystemConfig()\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(\"INITIALIZING UML GENERATION SYSTEM\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Creating LLM connection...\")\n",
    "        llm = create_llm(cfg)\n",
    "        \n",
    "        logger.info(\"Initializing PlantUML tool...\")\n",
    "        puml_tool = PlantUMLTool(cfg.plantuml_host)\n",
    "        \n",
    "        memory_mgr = None\n",
    "        if enable_long_term_memory:\n",
    "            logger.info(f\"Initializing long-term memory with {cfg.embedder_model}...\")\n",
    "\n",
    "            dims = 1024 if \"large\" in cfg.embedder_model.lower() else 384\n",
    "            \n",
    "            memory_mgr = MemoryManager(\n",
    "                embedder=SentenceTransformer(cfg.embedder_model),\n",
    "                db_path=cfg.db_path,\n",
    "                embedding_dims=dims\n",
    "            )\n",
    "\n",
    "            seeded_count = seed_memory_from_shots(\n",
    "                memory_manager=memory_mgr,\n",
    "                shots_json_path=cfg.shots_json_path,\n",
    "                force_reseed=True \n",
    "            )\n",
    "\n",
    "            logger.info(\"Long-term memory (SQLite + sqlite-vec) enabled\")\n",
    "\n",
    "            if seeded_count > 0:\n",
    "                logger.info(f\"Seeded {seeded_count} few-shot examples into memory\")\n",
    "        else:\n",
    "            logger.info(\"Long-term memory disabled\")\n",
    "        \n",
    "\n",
    "        logger.info(\"Building LangGraph workflow...\")\n",
    "        nodes = UMLNodes(llm, puml_tool, memory_mgr, cfg)\n",
    "        app = create_uml_graph(nodes, cfg)\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"SYSTEM INITIALIZED SUCCESSFULLY\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        return nodes, app, cfg, memory_mgr\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"System initialization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "nodes, app, config, memory_manager = initialize_system(enable_long_term_memory=True)\n",
    "print(\"\\nSystem ready for diagram generation\")\n",
    "print(f\"Long-term memory: {'ENABLED' if memory_manager else 'DISABLED'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9633429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 12:36:27,892 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:27,893 - __main__ - INFO - RUNNING: Exercise 3\n",
      "2026-01-10 12:36:27,893 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:36:27,893 - __main__ - INFO - Requirements preview: A library system manages books, members, and loans.\n",
      "Books have an ISBN, title, author, publisher, publication year, and availability status.\n",
      "Members h...\n",
      "2026-01-10 12:36:27,905 - __main__ - INFO - --- NODE: RETRIEVE ---\n",
      "2026-01-10 12:36:28,356 - __main__ - INFO - Retrieved 3 similar diagrams from SQLite\n",
      "2026-01-10 12:36:28,359 - __main__ - INFO - Retrieved 3 relevant examples from unified memory\n",
      "2026-01-10 12:36:28,360 - __main__ - INFO - --- NODE: DECOMPOSE ---\n",
      "2026-01-10 12:37:41,940 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:37:41,956 - __main__ - INFO - Decomposition completed\n",
      "2026-01-10 12:37:41,961 - __main__ - INFO - --- NODE: PLAN_AUDIT ---\n",
      "2026-01-10 12:38:07,975 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:38:08,007 - __main__ - INFO - --- NODE: GENERATE ---\n",
      "2026-01-10 12:40:08,016 - openai._base_client - INFO - Retrying request to /chat/completions in 0.418172 seconds\n",
      "2026-01-10 12:41:49,967 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:41:49,973 - __main__ - INFO - Generation completed (iteration 1)\n",
      "2026-01-10 12:41:49,977 - __main__ - INFO - --- NODE: SYNTAX_CHECK ---\n",
      "2026-01-10 12:41:49,977 - __main__ - INFO - Validating PlantUML syntax\n",
      "2026-01-10 12:41:50,163 - __main__ - INFO - Syntax validation passed (PNG rendered)\n",
      "2026-01-10 12:41:50,165 - __main__ - INFO - Syntax valid. View at: http://localhost:8080/png/TLDBQyCm3BxxLvWS1othDGpMZJ8ex07hQQUY96fZwaUGvOwmxR_FSLyEtIwn94lVGqdcde4u62r4hS5x-UZSJdu9APMlR2bNJCfkOygADMOv16uTPOKkL5hv5gzgDR1ozWCXtYmjunPfcD-3qb0fhRXVCN3mvS2j4QpuEObvGLCX9JacXRvLtRB962oOaQgc8VG-bz0wYwzX6CwgX5lbcPAo1N2469uNuXM71YqdPd-8HxGTkIs1UTiCZVtvuZp_17NGt6VwqNJQzOWZc0Qxk7qJqQyXdXtOD5ctMEzSu4ndd0muoWavK6RbFjEYB2QWJGmUZ0i3sm9hPK0FLg0V1Fpx3jxH8-tJfX8ANVBnvevcxxudazF-HhNHJixjnMmwlIbal2_YaKoNid94xjEBz34Mjtzqw7XWisOdHAeKiqD7x8rHibnA0_swXJrUkCumkQlow0czoCkdxdWa7QNSE5fNCHHYZhQ9Fyql\n",
      "2026-01-10 12:41:50,167 - __main__ - INFO - --- NODE: CRITIC ---\n",
      "2026-01-10 12:42:47,310 - httpx - INFO - HTTP Request: POST http://localhost:1234/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-10 12:42:47,337 - __main__ - INFO - Logic validation: PASSED (Weighted Score: 9.65)\n",
      "2026-01-10 12:42:47,337 - __main__ - INFO -   Requirements Coverage: 9.50/10\n",
      "2026-01-10 12:42:47,338 - __main__ - INFO -   Design Best Practices: 10.00/10\n",
      "2026-01-10 12:42:47,338 - __main__ - INFO -   Structural Integrity: 9.50/10\n",
      "2026-01-10 12:42:47,338 - __main__ - INFO - Storing first valid diagram as best\n",
      "2026-01-10 12:42:47,338 - __main__ - INFO - Diagram validated successfully\n",
      "2026-01-10 12:42:47,340 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:42:47,340 - __main__ - INFO - WORKFLOW COMPLETED\n",
      "2026-01-10 12:42:47,340 - __main__ - INFO - ============================================================\n",
      "2026-01-10 12:42:47,340 - __main__ - INFO - Iterations: 1\n",
      "2026-01-10 12:42:47,341 - __main__ - INFO - Syntax Valid: True\n",
      "2026-01-10 12:42:47,341 - __main__ - INFO - Logic Valid: True\n",
      "2026-01-10 12:42:47,343 - __main__ - INFO - PlantUML tool initialized with host: http://localhost:8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "Iterations: 1\n",
      "Syntax Valid: True\n",
      "Logic Valid: True\n",
      "\n",
      "Diagram URL: http://localhost:8080/png/TLDBQyCm3BxxLvWS1othDGpMZJ8ex07hQQUY96fZwaUGvOwmxR_FSLyEtIwn94lVGqdcde4u62r4hS5x-UZSJdu9APMlR2bNJCfkOygADMOv16uTPOKkL5hv5gzgDR1ozWCXtYmjunPfcD-3qb0fhRXVCN3mvS2j4QpuEObvGLCX9JacXRvLtRB962oOaQgc8VG-bz0wYwzX6CwgX5lbcPAo1N2469uNuXM71YqdPd-8HxGTkIs1UTiCZVtvuZp_17NGt6VwqNJQzOWZc0Qxk7qJqQyXdXtOD5ctMEzSu4ndd0muoWavK6RbFjEYB2QWJGmUZ0i3sm9hPK0FLg0V1Fpx3jxH8-tJfX8ANVBnvevcxxudazF-HhNHJixjnMmwlIbal2_YaKoNid94xjEBz34Mjtzqw7XWisOdHAeKiqD7x8rHibnA0_swXJrUkCumkQlow0czoCkdxdWa7QNSE5fNCHHYZhQ9Fyql\n",
      "\n",
      "Generated Diagram:\n",
      "@startuml\n",
      "\n",
      "class Book {\n",
      "  isbn: String\n",
      "  title: String\n",
      "  author: String\n",
      "  publisher: String\n",
      "  publicationYear: Integer\n",
      "  availabilityStatus: Boolean\n",
      "}\n",
      "\n",
      "class Member {\n",
      "  membershipId: String\n",
      "  name: String\n",
      "  address: String\n",
      "  phoneNumber: String\n",
      "  registrationDate: Date\n",
      "}\n",
      "\n",
      "class Student {\n",
      "  studentId: String\n",
      "  programOfStudy: String\n",
      "}\n",
      "\n",
      "class FacultyMember {\n",
      "  employeeId: String\n",
      "  department: String\n",
      "}\n",
      "\n",
      "class Loan {\n",
      "  checkoutDate: Date\n",
      "  dueDate: Date\n",
      "  returnDate: Date?\n",
      "}\n",
      "\n",
      "class Fine {\n",
      "  fineAmount: Decimal\n",
      "  paymentStatus: Boolean\n",
      "}\n",
      "\n",
      "class Reservation {\n",
      "  reservationDate: Date\n",
      "}\n",
      "\n",
      "Member <|-- Student\n",
      "Member <|-- FacultyMember\n",
      "\n",
      "Member \"1..*\" -- \"*\" Loan : borrows\n",
      "Book \"0..*\" -- \"*\" Loan : loaned_to\n",
      "\n",
      "Loan \"1\" -- \"0..1\" Fine : may_have\n",
      "Member \"1\" -- \"*\" Reservation : reserves\n",
      "Reservation \"1\" -- \"1\" Book : for_book\n",
      "\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "def run_single_test(\n",
    "    app: Any,\n",
    "    requirements: str,\n",
    "    exercise_name: str = \"Test Exercise\"\n",
    ") -> AgentState:\n",
    "    \"\"\"\n",
    "    Run the workflow on a single exercise.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        requirements: Software requirements text\n",
    "        exercise_name: Name for logging purposes\n",
    "        \n",
    "    Returns:\n",
    "        Final workflow state\n",
    "    \"\"\"\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"RUNNING: {exercise_name}\")\n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"Requirements preview: {requirements[:150]}...\")\n",
    "    \n",
    "    initial_state = create_initial_state(requirements)\n",
    "    \n",
    "    try:\n",
    "        final_output = app.invoke(initial_state, config={\"recursion_limit\": 50})\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"WORKFLOW COMPLETED\")\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(f\"Iterations: {final_output['iterations']}\")\n",
    "        logger.info(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "        logger.info(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "        \n",
    "        if final_output.get('best_diagram') and not final_output['logic_valid']:\n",
    "            if final_output['best_diagram'] != final_output['current_diagram']:\n",
    "                logger.info(\"Using BEST diagram instead of final (prevented regression)\")\n",
    "                final_output['current_diagram'] = final_output['best_diagram']\n",
    "        \n",
    "        return final_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Workflow execution failed: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Select and run a test exercise\n",
    "test_idx = 2\n",
    "requirements = test_exercises[test_idx][\"requirements\"]\n",
    "\n",
    "final_output = run_single_test(\n",
    "    app, \n",
    "    requirements, \n",
    "    f\"Exercise {test_idx + 1}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Iterations: {final_output['iterations']}\")\n",
    "print(f\"Syntax Valid: {final_output['syntax_valid']}\")\n",
    "print(f\"Logic Valid: {final_output['logic_valid']}\")\n",
    "\n",
    "if final_output['current_diagram']:\n",
    "    puml_tool = PlantUMLTool(config.plantuml_host)\n",
    "    diagram_url = puml_tool.get_diagram_url(final_output['current_diagram'])\n",
    "    print(f\"\\nDiagram URL: {diagram_url}\")\n",
    "    \n",
    "    print(\"\\nGenerated Diagram:\")\n",
    "    print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e84c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@startuml\n",
      "\n",
      "class Book {\n",
      "  isbn: String\n",
      "  title: String\n",
      "  author: String\n",
      "  publisher: String\n",
      "  publicationYear: Integer\n",
      "  availabilityStatus: Boolean\n",
      "}\n",
      "\n",
      "class Member {\n",
      "  membershipId: String\n",
      "  name: String\n",
      "  address: String\n",
      "  phoneNumber: String\n",
      "  registrationDate: Date\n",
      "}\n",
      "\n",
      "class Student {\n",
      "  studentId: String\n",
      "  programOfStudy: String\n",
      "}\n",
      "\n",
      "class FacultyMember {\n",
      "  employeeId: String\n",
      "  department: String\n",
      "}\n",
      "\n",
      "class Loan {\n",
      "  checkoutDate: Date\n",
      "  dueDate: Date\n",
      "  returnDate: Date?\n",
      "}\n",
      "\n",
      "class Fine {\n",
      "  fineAmount: Decimal\n",
      "  paymentStatus: Boolean\n",
      "}\n",
      "\n",
      "class Reservation {\n",
      "  reservationDate: Date\n",
      "}\n",
      "\n",
      "Member <|-- Student\n",
      "Member <|-- FacultyMember\n",
      "\n",
      "Member \"1..*\" -- \"*\" Loan : borrows\n",
      "Book \"0..*\" -- \"*\" Loan : loaned_to\n",
      "\n",
      "Loan \"1\" -- \"0..1\" Fine : may_have\n",
      "Member \"1\" -- \"*\" Reservation : reserves\n",
      "Reservation \"1\" -- \"1\" Book : for_book\n",
      "\n",
      "@enduml\n"
     ]
    }
   ],
   "source": [
    "print(final_output['current_diagram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics(BaseModel):\n",
    "    \"\"\"Container for evaluation metrics.\"\"\"\n",
    "    precision: float = Field(ge=0.0, le=1.0, description=\"Precision score\")\n",
    "    recall: float = Field(ge=0.0, le=1.0, description=\"Recall score\")\n",
    "    f1: float = Field(ge=0.0, le=1.0, description=\"F1 score\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"P={self.precision:.2f}, R={self.recall:.2f}, F1={self.f1:.2f}\"\n",
    "\n",
    "\n",
    "class PlantUMLParser:\n",
    "    \"\"\"\n",
    "    Parser for extracting structured information from PlantUML diagrams.\n",
    "    \n",
    "    Extracts classes, attributes, and relationships from PlantUML code\n",
    "    for evaluation purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, plantuml_code: str):\n",
    "        \"\"\"\n",
    "        Initialize parser with PlantUML code.\n",
    "        \n",
    "        Args:\n",
    "            plantuml_code: PlantUML diagram code\n",
    "        \"\"\"\n",
    "        self.plantuml_code = plantuml_code\n",
    "        self.classes: Dict[str, Dict[str, List[str]]] = {}\n",
    "        self.relationships: List[Dict[str, Any]] = []\n",
    "        self.parse()\n",
    "    \n",
    "    def parse(self) -> None:\n",
    "        \"\"\"Parse the PlantUML code.\"\"\"\n",
    "        try:\n",
    "            self._extract_classes()\n",
    "            self._extract_relationships()\n",
    "            logger.debug(f\"Parsed {len(self.classes)} classes and {len(self.relationships)} relationships\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Parsing failed: {e}\")\n",
    "    \n",
    "    def _extract_classes(self) -> None:\n",
    "        \"\"\"Extract class definitions and their attributes.\"\"\"\n",
    "        class_pattern = r'class\\s+(\\w+)\\s*\\{([^}]*)\\}'\n",
    "        matches = re.finditer(class_pattern, self.plantuml_code, re.MULTILINE | re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            class_name = match.group(1)\n",
    "            class_body = match.group(2)\n",
    "            \n",
    "            attributes = []\n",
    "            for line in class_body.strip().split('\\n'):\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('--'):\n",
    "                    attributes.append(line)\n",
    "            \n",
    "            self.classes[class_name] = {'attributes': attributes}\n",
    "    \n",
    "    def _extract_relationships(self) -> None:\n",
    "        \"\"\"Extract relationships between classes with cardinalities.\"\"\"\n",
    "        patterns = [\n",
    "            # Generalization (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<\\|--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--|>\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'generalization'),\n",
    "            \n",
    "            # Composition (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*\\*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\*\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'composition'),\n",
    "            \n",
    "            # Aggregation (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*o--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--o\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'aggregation'),\n",
    "            \n",
    "            # Directed Association (either direction)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*-->\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*<--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "            \n",
    "            # Simple Association (no arrow)\n",
    "            (r'(\\w+)\\s*(?:\"([^\"]*)\")?\\s*--\\s*(?:\"([^\"]*)\")?\\s*(\\w+)', 'association'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, rel_type in patterns:\n",
    "            for match in re.finditer(pattern, self.plantuml_code):\n",
    "                source = match.group(1)\n",
    "                target = match.group(4)\n",
    "                \n",
    "                # Skip if source or target is None or empty\n",
    "                if not source or not target:\n",
    "                    continue\n",
    "                \n",
    "                self.relationships.append({\n",
    "                    'type': rel_type,\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'cardinality_source': match.group(2) if match.lastindex >= 2 else None,\n",
    "                    'cardinality_target': match.group(3) if match.lastindex >= 3 else None\n",
    "                })\n",
    "\n",
    "\n",
    "class DiagramEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for comparing generated diagrams against gold standards.\n",
    "    \n",
    "    Computes precision, recall, and F1 scores for classes, attributes,\n",
    "    and relationships.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gold_plantuml: str, pred_plantuml: str):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with gold and predicted diagrams.\n",
    "        \n",
    "        Args:\n",
    "            gold_plantuml: Gold standard PlantUML code\n",
    "            pred_plantuml: Predicted PlantUML code\n",
    "        \"\"\"\n",
    "        self.gold_parser = PlantUMLParser(gold_plantuml)\n",
    "        self.pred_parser = PlantUMLParser(pred_plantuml)\n",
    "    \n",
    "    def _normalize_attr(self, attr_str: str) -> str:\n",
    "        \"\"\"Normalize attribute strings for comparison.\"\"\"\n",
    "        return attr_str.split(':')[0].strip().lower()\n",
    "    \n",
    "    def _normalize_rel_type(self, rel_type: str) -> str:\n",
    "        \"\"\"Normalize relationship types.\"\"\"\n",
    "        mapping = {\n",
    "            '<|--': 'INHERITANCE',\n",
    "            '--|>': 'INHERITANCE',\n",
    "            '*--': 'COMPOSITION',\n",
    "            '--*': 'COMPOSITION',\n",
    "            'o--': 'AGGREGATION',\n",
    "            '--o': 'AGGREGATION',\n",
    "            '--': 'ASSOCIATION',\n",
    "            '<--': 'ASSOCIATION',\n",
    "            '-->': 'ASSOCIATION'\n",
    "        }\n",
    "        return mapping.get(rel_type, 'ASSOCIATION')\n",
    "    \n",
    "    def _calculate_metrics(\n",
    "        self, \n",
    "        gold_set: set, \n",
    "        pred_set: set\n",
    "    ) -> EvaluationMetrics:\n",
    "        \"\"\"\n",
    "        Calculate precision, recall, and F1 scores.\n",
    "        \n",
    "        Args:\n",
    "            gold_set: Set of gold standard elements\n",
    "            pred_set: Set of predicted elements\n",
    "            \n",
    "        Returns:\n",
    "            EvaluationMetrics object\n",
    "        \"\"\"\n",
    "        tp = len(gold_set.intersection(pred_set))\n",
    "        fp = len(pred_set - gold_set)\n",
    "        fn = len(gold_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return EvaluationMetrics(\n",
    "            precision=round(precision, 2),\n",
    "            recall=round(recall, 2),\n",
    "            f1=round(f1, 2)\n",
    "        )\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, EvaluationMetrics]:\n",
    "        \"\"\"\n",
    "        Get all evaluation metrics.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with metrics for classes, attributes, and relationships\n",
    "        \"\"\"\n",
    "        # Classes \n",
    "        gold_classes = {c.lower() for c in self.gold_parser.classes.keys()}\n",
    "        pred_classes = {c.lower() for c in self.pred_parser.classes.keys()}\n",
    "        \n",
    "        # Attributes \n",
    "        gold_attrs = set()\n",
    "        for cls, info in self.gold_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                gold_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        pred_attrs = set()\n",
    "        for cls, info in self.pred_parser.classes.items():\n",
    "            for attr in info['attributes']:\n",
    "                pred_attrs.add((cls.lower(), self._normalize_attr(attr)))\n",
    "        \n",
    "        # Relationships (type + direction only)\n",
    "        gold_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']))\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        # Cardinalities \n",
    "        gold_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.gold_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        pred_rels_card = {\n",
    "            (r['source'].lower(), r['target'].lower(), self._normalize_rel_type(r['type']),\n",
    "             (r['cardinality_source'] or '').strip(), (r['cardinality_target'] or '').strip())\n",
    "            for r in self.pred_parser.relationships\n",
    "            if r.get('source') and r.get('target')\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            \"classes\": self._calculate_metrics(gold_classes, pred_classes),\n",
    "            \"attributes\": self._calculate_metrics(gold_attrs, pred_attrs),\n",
    "            \"relationships\": self._calculate_metrics(gold_rels, pred_rels),\n",
    "            \"cardinalities\": self._calculate_metrics(gold_rels_card, pred_rels_card)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "def evaluate_diagram(\n",
    "    gold_standard: str,\n",
    "    generated_diagram: str\n",
    ") -> Dict[str, EvaluationMetrics]:\n",
    "    \"\"\"\n",
    "    Evaluate a generated diagram against gold standard.\n",
    "    \n",
    "    Args:\n",
    "        gold_standard: Gold standard PlantUML code\n",
    "        generated_diagram: Generated PlantUML code\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    evaluator = DiagramEvaluator(gold_standard, generated_diagram)\n",
    "    return evaluator.get_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION METRICS\n",
      "============================================================\n",
      "\n",
      "Classes:       P=0.86, R=0.86, F1=0.86\n",
      "Attributes:    P=0.90, R=0.86, F1=0.88\n",
      "Relationships: P=0.71, R=0.71, F1=0.71\n",
      "Cardinalities: P=0.29, R=0.29, F1=0.29\n",
      "\n",
      "============================================================\n",
      "OVERALL F1 SCORE: 0.71\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "gold_standard = test_exercises[test_idx][\"solution_plantuml\"]\n",
    "generated_diagram = final_output[\"current_diagram\"]\n",
    "\n",
    "metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nClasses:       {metrics['classes']}\")\n",
    "print(f\"Attributes:    {metrics['attributes']}\")\n",
    "print(f\"Relationships: {metrics['relationships']}\")\n",
    "print(f\"Cardinalities: {metrics['cardinalities']}\")\n",
    "\n",
    "weighted_avg_f1 = (\n",
    "    metrics['classes'].f1 * 0.3 + \n",
    "    metrics['attributes'].f1 * 0.2 + \n",
    "    metrics['relationships'].f1 * 0.3 +\n",
    "    metrics['cardinalities'].f1 * 0.2\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OVERALL F1 SCORE: {weighted_avg_f1:.2f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42196e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchResult(BaseModel):\n",
    "    \"\"\"Result from a single exercise in batch evaluation.\"\"\"\n",
    "    exercise_num: int = Field(description=\"Exercise number\")\n",
    "    success: bool = Field(description=\"Whether the exercise was successful\")\n",
    "    iterations: int = Field(default=0, ge=0, description=\"Number of iterations used\")\n",
    "    syntax_valid: bool = Field(default=False, description=\"Whether syntax validation passed\")\n",
    "    logic_valid: bool = Field(default=False, description=\"Whether logic validation passed\")\n",
    "    metrics: Optional[Dict[str, EvaluationMetrics]] = Field(default=None, description=\"Evaluation metrics\")\n",
    "    diagram_url: Optional[str] = Field(default=None, description=\"URL to view the diagram\")\n",
    "    error: Optional[str] = Field(default=None, description=\"Error message if failed\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for DataFrame creation.\"\"\"\n",
    "        if self.metrics:\n",
    "            return {\n",
    "                \"exercise\": self.exercise_num,\n",
    "                \"success\": self.success,\n",
    "                \"iterations\": self.iterations,\n",
    "                \"syntax_valid\": self.syntax_valid,\n",
    "                \"logic_valid\": self.logic_valid,\n",
    "                \"class_f1\": self.metrics['classes'].f1,\n",
    "                \"attr_f1\": self.metrics['attributes'].f1,\n",
    "                \"rel_f1\": self.metrics['relationships'].f1,\n",
    "                \"card_f1\": self.metrics['cardinalities'].f1,\n",
    "                \"diagram_url\": self.diagram_url\n",
    "            }\n",
    "        return {\n",
    "            \"exercise\": self.exercise_num,\n",
    "            \"success\": self.success,\n",
    "            \"error\": self.error\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_batch(\n",
    "    app: Any,\n",
    "    test_exercises: List[Dict[str, Any]],\n",
    "    puml_tool: PlantUMLTool,\n",
    "    max_exercises: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run batch evaluation on multiple exercises.\n",
    "    \n",
    "    Args:\n",
    "        app: Compiled LangGraph workflow\n",
    "        test_exercises: List of exercise dictionaries\n",
    "        puml_tool: PlantUML tool for URL generation\n",
    "        max_exercises: Optional limit on number of exercises\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with evaluation results\n",
    "    \"\"\"\n",
    "    exercises_to_test = test_exercises[:max_exercises] if max_exercises else test_exercises\n",
    "    results = []\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"BATCH EVALUATION: {len(exercises_to_test)} exercises\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    for i, exercise in enumerate(exercises_to_test):\n",
    "        logger.info(f\"\\n--- Exercise {i+1}/{len(exercises_to_test)} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Run workflow\n",
    "            requirements = exercise[\"requirements\"]\n",
    "            final_output = run_single_test(app, requirements, f\"Exercise {i+1}\")\n",
    "            \n",
    "            # Evaluate\n",
    "            gold_standard = exercise[\"solution_plantuml\"]\n",
    "            generated_diagram = final_output[\"current_diagram\"]\n",
    "            metrics = evaluate_diagram(gold_standard, generated_diagram)\n",
    "            \n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=True,\n",
    "                iterations=final_output[\"iterations\"],\n",
    "                syntax_valid=final_output[\"syntax_valid\"],\n",
    "                logic_valid=final_output[\"logic_valid\"],\n",
    "                metrics=metrics,\n",
    "                diagram_url=puml_tool.get_diagram_url(generated_diagram)\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Exercise {i+1}: F1 = Classes:{metrics['classes'].f1:.2f} | \"\n",
    "                       f\"Attrs:{metrics['attributes'].f1:.2f} | Rels:{metrics['relationships'].f1:.2f} | \"\n",
    "                       f\"Cards:{metrics['cardinalities'].f1:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âœ— Exercise {i+1} failed: {e}\")\n",
    "            result = BatchResult(\n",
    "                exercise_num=i + 1,\n",
    "                success=False,\n",
    "                error=str(e)\n",
    "            )\n",
    "        \n",
    "        results.append(result.to_dict())\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    logger.info(\"\\n\" + \"=\"*60)\n",
    "    logger.info(\"BATCH EVALUATION COMPLETE\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example: Run on first 3 exercises (uncomment to execute)\n",
    "# df_results = evaluate_batch(app, test_exercises, puml_tool, max_exercises=3)\n",
    "# \n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"BATCH EVALUATION SUMMARY\")\n",
    "# print(\"=\"*60)\n",
    "# successful = df_results[df_results['success'] == True]\n",
    "# if not successful.empty:\n",
    "#     print(successful[['exercise', 'class_f1', 'attr_f1', 'rel_f1']].to_string(index=False))\n",
    "#     avg_f1 = successful[['class_f1', 'attr_f1', 'rel_f1']].mean().mean()\n",
    "#     print(f\"\\nAverage F1: {avg_f1:.2f}\")\n",
    "# else:\n",
    "#     print(\"No successful evaluations\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
